{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7d33120-2e80-4521-b90e-6a3aa7e41f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('./boolODE/')\n",
    "\n",
    "import ast\n",
    "import yaml\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm \n",
    "from pathlib import Path\n",
    "import multiprocessing as mp\n",
    "from optparse import OptionParser\n",
    "\n",
    "from scipy.integrate import odeint\n",
    "from sklearn.cluster import KMeans\n",
    "from typing import Dict, List\n",
    "from importlib.machinery import SourceFileLoader\n",
    "from scipy.stats import rankdata\n",
    "import copy\n",
    "import re\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import parsing_fnc as fnc\n",
    "import gen_graph_util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "782c066e-af9b-4b5a-8cc9-3dbb5b2ac822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load initial graph (load long-linear, but change topology to 1:n regulation as initial graph)\n",
    "# Graph statistics (nodes = 18, edges = 18)\n",
    "path = \"./boolODE/\"\n",
    "grn_init = path + \"graph_LL_18\"\n",
    "\n",
    "df = pd.read_csv(grn_init + \".txt\", sep=\"\\t\", engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ead6be17-9d36-4ecf-b96f-9333efa7197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sample transripciton factors and build initail topology\n",
    "ntfs = 6\n",
    "tfs = np.random.choice(df.values[:,0], ntfs, replace = False)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    tf = tfs[int(i%ntfs)]\n",
    "    \n",
    "    if np.random.choice(2) == 0:\n",
    "        df.values[:,1][i] = \"( \" + tf + \" )\"\n",
    "    else:\n",
    "        df.values[:,1][i] = \"( not ( \" + tf + \" ) )\"\n",
    "        \n",
    "genes, all_regul, activate_dict, inactivate_dict = util.load_init_graph(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e791747a-43f7-41cc-9d0a-d134d123322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set kinetic parameters (use same parameters used in BEELINE)\n",
    "withRules = list(df['Gene'].values)\n",
    "allnodes = set()\n",
    "\n",
    "for ind, row in df.iterrows():\n",
    "    rhs = row['Rule']\n",
    "    rhs = rhs.replace('(',' ')\n",
    "    rhs = rhs.replace(')',' ')\n",
    "    tokens = rhs.split(' ')\n",
    "    reg = [t for t in tokens if t not in ['not','and','or','']]\n",
    "    allnodes.update(set(reg))\n",
    "    \n",
    "# filter gene which has no regulate rules\n",
    "withoutRules = list(allnodes.difference(set(withRules)))\n",
    "\n",
    "# if no rule, assign self-activation\n",
    "for n in withoutRules:\n",
    "    print(n, \"has no rule, adding self-activation.\")\n",
    "    df = df.append({'Gene':n,'Rule':n}, ignore_index=True)\n",
    "    withRules.append(n)\n",
    "    withoutRules.remove(n)\n",
    "    \n",
    "# Assume everything is a gene, so make the corresponding protein\n",
    "varspecs, genelist, inputs = dict(), list(), list()\n",
    "for node in withRules:\n",
    "    varspecs['x_' + node] = ''\n",
    "    varspecs['p_' + node] = ''\n",
    "    genelist.append(node)\n",
    "    \n",
    "kineticParameterDefaults = {'mRNATranscription':20.,'mRNADegradation':10.,'proteinTranslation':10.,'proteinDegradation':1.0,\n",
    "                            'heavisideSigma':10.,'signalingTimescale':5.0,'hillCoefficient':10.,'interactionStrength':1.0}\n",
    "\n",
    "# Max level checks\n",
    "x_max = kineticParameterDefaults['mRNATranscription']/kineticParameterDefaults['mRNADegradation']\n",
    "y_max = x_max*(kineticParameterDefaults['proteinTranslation']/kineticParameterDefaults['proteinDegradation'])\n",
    "\n",
    "hillThreshold = y_max/2\n",
    "heavisideOmega = 2./y_max\n",
    "\n",
    "kineticParameterDefaults['x_max'] = x_max\n",
    "kineticParameterDefaults['y_max'] = y_max\n",
    "kineticParameterDefaults['hillThreshold'] = hillThreshold\n",
    "kineticParameterDefaults['heavisideOmega'] = heavisideOmega\n",
    "\n",
    "parameterNamePrefixAndDefaultsAll = {'n_':kineticParameterDefaults['hillCoefficient'], 'k_':hillThreshold, \n",
    "                                     'sigmaH_':kineticParameterDefaults['heavisideSigma']}\n",
    "parameterNamePrefixAndDefaultsGenes = {'m_':kineticParameterDefaults['mRNATranscription'],'l_x_':kineticParameterDefaults['mRNADegradation'],\n",
    "                                       'r_':kineticParameterDefaults['proteinTranslation'],'l_p_':kineticParameterDefaults['proteinDegradation']}\n",
    "\n",
    "proteinlist, interactionStrengths = list(), dict()\n",
    "parameterSetDF, parameterInputsDF = pd.DataFrame(), pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b89be474-688b-4982-9027-028154bd4448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation Time Length:  7500\n",
      "Fixing rate parameters to defaults\n"
     ]
    }
   ],
   "source": [
    "# Setting experiments (activation function, timelength, cell number)\n",
    "\n",
    "settings = dict()\n",
    "settings['modeltype'] = 'hill'\n",
    "settings['num_cells'] = 3\n",
    "settings['simulation_time'] = 75\n",
    "settings['integration_step_size'] = 0.01\n",
    "settings['doParallel'] = False\n",
    "\n",
    "print(\"Simulation Time Length: \", int(settings['simulation_time']/settings['integration_step_size']))\n",
    "\n",
    "par = fnc.assignDefaultParameterValues(parameterNamePrefixAndDefaultsAll,parameterNamePrefixAndDefaultsGenes,withRules, genelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "698de99d-3d9f-4fb4-a4b9-c2f705099fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelSpecs, varmappers, parmappers, model_path = dict(), dict(), dict(), dict()\n",
    "time_length = int(settings['simulation_time']/settings['integration_step_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cadb3c4-07fa-4a23-a7a3-5b251d832216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Graphs: 5, Num Pert: 5\n"
     ]
    }
   ],
   "source": [
    "# Set perturb rulse for ground-truth graphs\n",
    "pert_method = \"swap\"\n",
    "\n",
    "btw_graphs = 1500\n",
    "num_graphs, num_pert = time_length//btw_graphs, 5\n",
    "\n",
    "print(\"Num Graphs: {}, Num Pert: {}\".format(num_graphs,num_pert))\n",
    "sub_path = path + pert_method + \"_time_\" + str(time_length) + \"_graphs_\" + str(num_graphs) + \"(\" + str(num_pert) + \")_1to2/\"\n",
    "\n",
    "simgraphpath = Path(sub_path + \"./graphs/\")\n",
    "if not os.path.exists(simgraphpath):\n",
    "    os.makedirs(simgraphpath)\n",
    "    \n",
    "simmodelpath = Path(sub_path + \"./models/\")\n",
    "if not os.path.exists(simmodelpath):\n",
    "    os.makedirs(simmodelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a91684c-aa7b-40d8-ab23-43ab7677ac31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./boolODE/swap_time_7500_graphs_5(5)_1to2/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9242f124-28a8-4405-ae3c-ff6e5cd225f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gen ground-truth graphs\n",
    "for grn_num in range(num_graphs):\n",
    "\n",
    "    if grn_num == 0: # initial graph_0\n",
    "        df.to_csv(sub_path + \"graphs/graph_\"+str(grn_num)+\".txt\",header=True, index=False, sep=\"\\t\")\n",
    "\n",
    "    if grn_num > 0:\n",
    "        rows = np.random.choice(genes, num_pert*2, replace = False) - 1\n",
    "        df.values[:,1][rows] = df.values[:,1][rows[::-1]]\n",
    "        df.to_csv(sub_path + \"graphs/graph_\"+str(grn_num)+\".txt\",header=True, index=False, sep=\"\\t\")\n",
    "\n",
    "    ModelSpec, varmapper, parmapper = util.model_generate(df, settings, withRules, inputs, par, genelist, proteinlist, varspecs)\n",
    "\n",
    "    ModelSpecs[grn_num]=copy.deepcopy(ModelSpec)\n",
    "    varmappers[grn_num]=copy.deepcopy(varmapper)\n",
    "    parmappers[grn_num]=copy.deepcopy(parmapper)\n",
    "\n",
    "    model_path[grn_num] = fnc.writeModelToFile(grn_num, ModelSpec, varmapper, path = sub_path + \"models/\")\n",
    "    fnc.generateInputFiles(df, withoutRules, grn_num, path = sub_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "476b8027-58b7-42ed-b34d-3a06698446e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Expression data - using first Graph (graph_0)\n",
    "init_Model = ModelSpecs[0]\n",
    "init_varmap = varmappers[0]\n",
    "init_parmap = parmappers[0]\n",
    "\n",
    "####################\n",
    "rnaIndex = [i for i in range(len(init_varmap.keys())) if 'x_' in init_varmap[i]]\n",
    "revvarmapper = {v:k for k,v in init_varmap.items()}\n",
    "proteinIndex = [i for i in range(len(init_varmap.keys())) if 'p_' in init_varmap[i]]\n",
    "\n",
    "y0 = [ModelSpec['ics'][init_varmap[i]] for i in range(len(init_varmap.keys()))]\n",
    "ss = np.zeros(len(init_varmap.keys()))\n",
    "\n",
    "for i,k in init_varmap.items():\n",
    "    if 'x_' in k:\n",
    "        ss[i] = 1.0\n",
    "    elif 'p_' in k:\n",
    "        if k.replace('p_','') in proteinlist:\n",
    "            ss[i] = 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa457910-6015-4aa8-9120-3e21defa1c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax = settings['simulation_time']\n",
    "integration_step_size = settings['integration_step_size']\n",
    "tspan = np.linspace(0,tmax,int(tmax/integration_step_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f844c1e-2554-4538-b556-cd65e249a33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load initial expression values\n",
    "init_exp = {\"Genes\":[\"['g1']\"], \"Values\":\"[1]\"}\n",
    "icsDF = pd.DataFrame(data=init_exp)\n",
    "\n",
    "if not icsDF.empty:\n",
    "    icsspec = icsDF.loc[0]\n",
    "    genes = ast.literal_eval(icsspec['Genes'])\n",
    "    values = ast.literal_eval(icsspec['Values'])\n",
    "    icsmap = {g:v for g,v in zip(genes,values)}\n",
    "    for i,k in init_varmap.items():\n",
    "        for g in genelist:\n",
    "            if g in icsmap.keys():\n",
    "                ss[revvarmapper['x_'+g]] = icsmap[g]\n",
    "            else:\n",
    "                ss[revvarmapper['x_'+g]] = 0.01\n",
    "\n",
    "result = pd.DataFrame(index=pd.Index([varmapper[i] for i in rnaIndex]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "040ded53-4784-404e-9950-bab49498c34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of every possible time point. Sample from this list\n",
    "startat = 0\n",
    "timeIndex = [i for i in range(startat, len(tspan))]\n",
    "\n",
    "groupedDict = {}\n",
    "\n",
    "simfilepath = Path(sub_path + \"./simulations/\")\n",
    "if not os.path.exists(simfilepath):\n",
    "    os.makedirs(simfilepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "257164f2-d42e-4346-8c38-6a56aeeaf048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c792f1dddafd4ee1872939fb8f8eb297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize\n",
    "new_ics = [0 for _ in range(len(varmapper.keys()))]\n",
    "\n",
    "# Set the mRNA ics\n",
    "for ind in rnaIndex:\n",
    "    if ss[ind] < 0:\n",
    "        ss[ind] = 0.0\n",
    "    new_ics[ind] =  ss[ind]\n",
    "    if new_ics[ind] < 0:\n",
    "        new_ics[ind] = 0\n",
    "for p in proteinlist:\n",
    "    ind = revvarmapper['p_'+p]\n",
    "    if ss[ind] < 0:\n",
    "        ss[ind] = 0.0\n",
    "    new_ics[ind] =  ss[ind]\n",
    "    if new_ics[ind] < 0:\n",
    "        new_ics[ind] = 0\n",
    "        \n",
    "# Calculate the Protein ics based on mRNA levels\n",
    "for genename in genelist:\n",
    "    pss = ((ModelSpec['pars']['r_' + genename])/(ModelSpec['pars']['l_p_' + genename]))*new_ics[revvarmapper['x_' + genename]]\n",
    "    new_ics[revvarmapper['p_' + genename.replace('_','')]] = pss\n",
    "    \n",
    "argdict = {}\n",
    "argdict['Model'] = model_path\n",
    "argdict['tspan'] = tspan\n",
    "argdict['varmapper'] = init_varmap\n",
    "argdict['timeIndex'] = timeIndex\n",
    "argdict['genelist'] = genelist\n",
    "argdict['proteinlist'] = proteinlist\n",
    "argdict['ss'] = ss\n",
    "argdict['ModelSpecs'] = ModelSpecs\n",
    "argdict['parmappers'] = parmappers\n",
    "argdict['rnaIndex'] = rnaIndex\n",
    "argdict['proteinIndex'] = proteinIndex\n",
    "argdict['revvarmapper'] = revvarmapper\n",
    "argdict['x_max'] = kineticParameterDefaults['x_max']\n",
    "\n",
    "if settings['doParallel']:\n",
    "    with mp.Pool() as pool:\n",
    "        jobs = []\n",
    "        for cellid in range(settings['num_cells']):\n",
    "            cell_args = dict(argdict, seed=cellid, cellid=cellid)\n",
    "            job = pool.apply_async(fnc.simulateAndSample, args=(cell_args,new_ics))\n",
    "            jobs.append(job)\n",
    "\n",
    "        for job in jobs:\n",
    "            job.wait()\n",
    "# not doing it in a parallel manner\n",
    "else:\n",
    "    # for each cellid, give a new experiment with new seed.\n",
    "    for cellid in tqdm(range(settings['num_cells'])):\n",
    "        argdict['seed'] = cellid\n",
    "        argdict['cellid'] = cellid\n",
    "        fnc.simulateAndSample(argdict, new_ics, path = sub_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f7a3b5e-a5ab-41bb-926a-aa1995173066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # after running the simulation, sample cells, print expression and pseudotime\n",
    "# frames = []\n",
    "# print('starting to concat files')\n",
    "# for cellid in tqdm(range(settings['num_cells'])):\n",
    "#     # cellid correspond to the cellid-th experiment, read in the gene expression simulation for the cellid-th experiment\n",
    "#     df = pd.read_csv(sub_path + './simulations/E'+str(cellid) + '.csv',index_col=0)\n",
    "#     # df of the form genes by times\n",
    "#     df = df.sort_index()\n",
    "#     # times by genes\n",
    "#     frames.append(df.T)\n",
    "    \n",
    "# # experiment * times by genes, \n",
    "# result = pd.concat(frames,axis=0)\n",
    "# result = result.T\n",
    "\n",
    "# # indices are gene names\n",
    "# indices = result.index\n",
    "# newindices = [i.replace('x_','') for i in indices]\n",
    "# result.index = pd.Index(newindices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2ba6260-42ad-475e-ac6d-1c61a81af7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-organizing generated simulation data: 1. cell expression data 2. ground-truth adjacent matrix\n",
    "# consider the first single cell trajectory\n",
    "\n",
    "exp_data = pd.read_csv(sub_path + \"simulations/E0.csv\", index_col = 0) \n",
    "\n",
    "_, ntime_1 = exp_data.shape\n",
    "time_len = ntime_1 + 1\n",
    "\n",
    "if exp_data.shape[1] != time_len:\n",
    "    (cell, time) = exp_data.columns[-1].split('_')\n",
    "    exp_data[cell+'_'+str(int(time)+1)]=exp_data[cell+'_'+time]\n",
    "    \n",
    "# Sort based on time - order\n",
    "sorted_exp = np.array(exp_data)[:,np.argsort([int(col.split(\"_\")[1]) for col in exp_data.columns])]\n",
    "\n",
    "temp = re.compile(\"([a-zA-Z]+)([0-9]+)\")\n",
    "\n",
    "gene_dict = dict()\n",
    "gene_list = [int(gene.split(\"g\")[1]) for gene in exp_data.index]\n",
    "ngenes = len(gene_list)\n",
    "gene_rank = rankdata(gene_list, method=\"min\")\n",
    "\n",
    "for gene, rank in zip(gene_list, gene_rank):\n",
    "    gene_dict[gene] = rank\n",
    "\n",
    "ref_net = dict()\n",
    "n_graphs = len(os.listdir(sub_path + \"ground_truth\"))\n",
    "\n",
    "gt_adj = np.zeros((n_graphs,ngenes,ngenes))\n",
    "for i in range(n_graphs):\n",
    "    ref_net = pd.read_csv(sub_path + \"ground_truth/refNetwork_\" +str(i) + \".csv\", index_col = 0)\n",
    "    target = list(ref_net.index)\n",
    "    regula = list(ref_net.values[:,0])\n",
    "\n",
    "    target = [int(temp.match(idx).groups()[1]) for idx in target]\n",
    "    regula = [int(temp.match(idx).groups()[1]) for idx in regula]\n",
    "    \n",
    "    target = [gene_dict[i] for i in target]\n",
    "    regula = [gene_dict[i] for i in regula]\n",
    "    start_idx = min(gene_rank)\n",
    "    \n",
    "    for rule in range(len(target)):\n",
    "        node0, node1 = target[rule], regula[rule]\n",
    "        gt_adj[i, node0 - start_idx, node1 - start_idx] += 1\n",
    "\n",
    "gt_adj_time = np.repeat(gt_adj,btw_graphs,axis = 0)\n",
    "\n",
    "if btw_graphs > 10:\n",
    "    freq = \"discrete_\"\n",
    "else:\n",
    "    freq = \"continue_\"\n",
    "\n",
    "outpath = \"../data/boolODE_Sep13/\"\n",
    "    \n",
    "np.save(freq+\"sorted_exp_1to2.npy\",sorted_exp) #(ngenes,ntimes)\n",
    "np.save(freq+\"gt_adj_1to2.npy\",gt_adj_time) #(ntimes,ngenes,ngenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3a5f9e-35c7-479b-9496-027fc273fbb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
