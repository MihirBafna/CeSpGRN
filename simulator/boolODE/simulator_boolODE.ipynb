{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys, os\n",
    "sys.path.append('./boolODE/')\n",
    "\n",
    "import ast\n",
    "import yaml\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm \n",
    "from pathlib import Path\n",
    "import multiprocessing as mp\n",
    "from optparse import OptionParser\n",
    "\n",
    "from scipy.integrate import odeint\n",
    "from sklearn.cluster import KMeans\n",
    "from typing import Dict, List\n",
    "from importlib.machinery import SourceFileLoader\n",
    "from scipy.stats import rankdata\n",
    "import copy\n",
    "import re\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import parsing_fnc as fnc\n",
    "import gen_graph_util as util"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Load initial graph (load long-linear, but change topology to 1:n regulation as initial graph)\n",
    "# Graph statistics (nodes = 18, edges = 18)\n",
    "\n",
    "path = \"./\"\n",
    "\n",
    "# Manually load\n",
    "# grn_init = path + \"graph_LL_18\"\n",
    "# df = pd.read_csv(grn_init + \".txt\", sep=\"\\t\", engine=\"python\")\n",
    "\n",
    "node_size = 18\n",
    "genes = {\"Gene\":[\"g\"+str(g) for g in np.arange(node_size)], \"Rule\":[\"g\"+str(g) for g in np.arange(node_size)]}\n",
    "df = pd.DataFrame(data = genes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Random sample transripciton factors and build initail topology\n",
    "ntfs = 6\n",
    "# select the tfs\n",
    "tfs = np.random.choice(df.values[:,0], ntfs, replace = False)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # choose the TF for gene i\n",
    "    tf = tfs[int(i%ntfs)]\n",
    "    \n",
    "    if np.random.choice(2) == 0:\n",
    "        df.values[:,1][i] = \"( \" + tf + \" )\"\n",
    "    else:\n",
    "        df.values[:,1][i] = \"( not ( \" + tf + \" ) )\"\n",
    "\n",
    "# df is the dataframe for bool grn        \n",
    "genes, all_regul, activate_dict, inactivate_dict = util.load_init_graph(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Set kinetic parameters (use same parameters used in BEELINE)\n",
    "withRules = list(df['Gene'].values)\n",
    "allnodes = set()\n",
    "\n",
    "# allnodes stores all tfs used\n",
    "for ind, row in df.iterrows():\n",
    "    rhs = row['Rule']\n",
    "    rhs = rhs.replace('(',' ')\n",
    "    rhs = rhs.replace(')',' ')\n",
    "    tokens = rhs.split(' ')\n",
    "    reg = [t for t in tokens if t not in ['not','and','or','']]\n",
    "    allnodes.update(set(reg))\n",
    "    \n",
    "# filter gene which has no regulate rules\n",
    "withoutRules = list(allnodes.difference(set(withRules)))\n",
    "\n",
    "# if no rule, assign self-activation, make sure withoutRules is empty\n",
    "for n in withoutRules:\n",
    "    print(n, \"has no rule, adding self-activation.\")\n",
    "    df = df.append({'Gene':n,'Rule':n}, ignore_index=True)\n",
    "    withRules.append(n)\n",
    "    withoutRules.remove(n)\n",
    "    \n",
    "# Assume everything is a gene, so make the corresponding protein\n",
    "varspecs, genelist, inputs = dict(), list(), list()\n",
    "for node in withRules:\n",
    "    varspecs['x_' + node] = ''\n",
    "    varspecs['p_' + node] = ''\n",
    "    genelist.append(node)\n",
    "\n",
    "kineticParameterDefaults = {'mRNATranscription':20.,'mRNADegradation':10.,'proteinTranslation':10.,'proteinDegradation':1.0,\n",
    "                            'heavisideSigma':10.,'signalingTimescale':5.0,'hillCoefficient':10.,'interactionStrength':1.0}\n",
    "\n",
    "# Max level checks, \n",
    "# the maximum gene expression level, this is achieved by dx/dt = M * 1 - D * x, where the solution is M/D * (1 - e^-t)\n",
    "x_max = kineticParameterDefaults['mRNATranscription']/kineticParameterDefaults['mRNADegradation']\n",
    "y_max = x_max*(kineticParameterDefaults['proteinTranslation']/kineticParameterDefaults['proteinDegradation'])\n",
    "\n",
    "# set hill threshold to be a half of the maximum expression of protein\n",
    "hillThreshold = y_max/2\n",
    "heavisideOmega = 2./y_max\n",
    "\n",
    "kineticParameterDefaults['x_max'] = x_max\n",
    "kineticParameterDefaults['y_max'] = y_max\n",
    "kineticParameterDefaults['hillThreshold'] = hillThreshold\n",
    "kineticParameterDefaults['heavisideOmega'] = heavisideOmega\n",
    "\n",
    "# for all genes, the hill coefficient (n_) = 10 (kineticParameterDefaults), the hill threshold (k_) = y_max/2\n",
    "parameterNamePrefixAndDefaultsAll = {'n_':kineticParameterDefaults['hillCoefficient'], 'k_':hillThreshold, \n",
    "                                     'sigmaH_':kineticParameterDefaults['heavisideSigma']}\n",
    "# for all genes, set the mRNA transcription rate (m_) to be 20, degradation rate (l_x_) to be 10, etc\n",
    "parameterNamePrefixAndDefaultsGenes = {'m_':kineticParameterDefaults['mRNATranscription'],'l_x_':kineticParameterDefaults['mRNADegradation'],\n",
    "                                       'r_':kineticParameterDefaults['proteinTranslation'],'l_p_':kineticParameterDefaults['proteinDegradation']}\n",
    "\n",
    "proteinlist, interactionStrengths = list(), dict()\n",
    "parameterSetDF, parameterInputsDF = pd.DataFrame(), pd.DataFrame()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Setting experiments (activation function, timelength, cell number)\n",
    "\n",
    "settings = dict()\n",
    "settings['modeltype'] = 'hill'\n",
    "settings['num_cells'] = 3\n",
    "settings['simulation_time'] = 75\n",
    "settings['integration_step_size'] = 0.01\n",
    "settings['doParallel'] = False\n",
    "\n",
    "print(\"Simulation Time Length: \", int(settings['simulation_time']/settings['integration_step_size']))\n",
    "\n",
    "# par include the parameter of hill function (m, n, k, l) of all genes\n",
    "# TODO: par (k_) should be different and should be related between genes\n",
    "par = fnc.assignDefaultParameterValues(parameterNamePrefixAndDefaultsAll,parameterNamePrefixAndDefaultsGenes,withRules, genelist)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Simulation Time Length:  7500\n",
      "Fixing rate parameters to defaults\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "par"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'n_g0': 10.0,\n",
       " 'n_g1': 10.0,\n",
       " 'n_g2': 10.0,\n",
       " 'n_g3': 10.0,\n",
       " 'n_g4': 10.0,\n",
       " 'n_g5': 10.0,\n",
       " 'n_g6': 10.0,\n",
       " 'n_g7': 10.0,\n",
       " 'n_g8': 10.0,\n",
       " 'n_g9': 10.0,\n",
       " 'n_g10': 10.0,\n",
       " 'n_g11': 10.0,\n",
       " 'n_g12': 10.0,\n",
       " 'n_g13': 10.0,\n",
       " 'n_g14': 10.0,\n",
       " 'n_g15': 10.0,\n",
       " 'n_g16': 10.0,\n",
       " 'n_g17': 10.0,\n",
       " 'k_g0': 10.0,\n",
       " 'k_g1': 10.0,\n",
       " 'k_g2': 10.0,\n",
       " 'k_g3': 10.0,\n",
       " 'k_g4': 10.0,\n",
       " 'k_g5': 10.0,\n",
       " 'k_g6': 10.0,\n",
       " 'k_g7': 10.0,\n",
       " 'k_g8': 10.0,\n",
       " 'k_g9': 10.0,\n",
       " 'k_g10': 10.0,\n",
       " 'k_g11': 10.0,\n",
       " 'k_g12': 10.0,\n",
       " 'k_g13': 10.0,\n",
       " 'k_g14': 10.0,\n",
       " 'k_g15': 10.0,\n",
       " 'k_g16': 10.0,\n",
       " 'k_g17': 10.0,\n",
       " 'sigmaH_g0': 10.0,\n",
       " 'sigmaH_g1': 10.0,\n",
       " 'sigmaH_g2': 10.0,\n",
       " 'sigmaH_g3': 10.0,\n",
       " 'sigmaH_g4': 10.0,\n",
       " 'sigmaH_g5': 10.0,\n",
       " 'sigmaH_g6': 10.0,\n",
       " 'sigmaH_g7': 10.0,\n",
       " 'sigmaH_g8': 10.0,\n",
       " 'sigmaH_g9': 10.0,\n",
       " 'sigmaH_g10': 10.0,\n",
       " 'sigmaH_g11': 10.0,\n",
       " 'sigmaH_g12': 10.0,\n",
       " 'sigmaH_g13': 10.0,\n",
       " 'sigmaH_g14': 10.0,\n",
       " 'sigmaH_g15': 10.0,\n",
       " 'sigmaH_g16': 10.0,\n",
       " 'sigmaH_g17': 10.0,\n",
       " 'm_g0': 20.0,\n",
       " 'm_g1': 20.0,\n",
       " 'm_g2': 20.0,\n",
       " 'm_g3': 20.0,\n",
       " 'm_g4': 20.0,\n",
       " 'm_g5': 20.0,\n",
       " 'm_g6': 20.0,\n",
       " 'm_g7': 20.0,\n",
       " 'm_g8': 20.0,\n",
       " 'm_g9': 20.0,\n",
       " 'm_g10': 20.0,\n",
       " 'm_g11': 20.0,\n",
       " 'm_g12': 20.0,\n",
       " 'm_g13': 20.0,\n",
       " 'm_g14': 20.0,\n",
       " 'm_g15': 20.0,\n",
       " 'm_g16': 20.0,\n",
       " 'm_g17': 20.0,\n",
       " 'l_x_g0': 10.0,\n",
       " 'l_x_g1': 10.0,\n",
       " 'l_x_g2': 10.0,\n",
       " 'l_x_g3': 10.0,\n",
       " 'l_x_g4': 10.0,\n",
       " 'l_x_g5': 10.0,\n",
       " 'l_x_g6': 10.0,\n",
       " 'l_x_g7': 10.0,\n",
       " 'l_x_g8': 10.0,\n",
       " 'l_x_g9': 10.0,\n",
       " 'l_x_g10': 10.0,\n",
       " 'l_x_g11': 10.0,\n",
       " 'l_x_g12': 10.0,\n",
       " 'l_x_g13': 10.0,\n",
       " 'l_x_g14': 10.0,\n",
       " 'l_x_g15': 10.0,\n",
       " 'l_x_g16': 10.0,\n",
       " 'l_x_g17': 10.0,\n",
       " 'r_g0': 10.0,\n",
       " 'r_g1': 10.0,\n",
       " 'r_g2': 10.0,\n",
       " 'r_g3': 10.0,\n",
       " 'r_g4': 10.0,\n",
       " 'r_g5': 10.0,\n",
       " 'r_g6': 10.0,\n",
       " 'r_g7': 10.0,\n",
       " 'r_g8': 10.0,\n",
       " 'r_g9': 10.0,\n",
       " 'r_g10': 10.0,\n",
       " 'r_g11': 10.0,\n",
       " 'r_g12': 10.0,\n",
       " 'r_g13': 10.0,\n",
       " 'r_g14': 10.0,\n",
       " 'r_g15': 10.0,\n",
       " 'r_g16': 10.0,\n",
       " 'r_g17': 10.0,\n",
       " 'l_p_g0': 1.0,\n",
       " 'l_p_g1': 1.0,\n",
       " 'l_p_g2': 1.0,\n",
       " 'l_p_g3': 1.0,\n",
       " 'l_p_g4': 1.0,\n",
       " 'l_p_g5': 1.0,\n",
       " 'l_p_g6': 1.0,\n",
       " 'l_p_g7': 1.0,\n",
       " 'l_p_g8': 1.0,\n",
       " 'l_p_g9': 1.0,\n",
       " 'l_p_g10': 1.0,\n",
       " 'l_p_g11': 1.0,\n",
       " 'l_p_g12': 1.0,\n",
       " 'l_p_g13': 1.0,\n",
       " 'l_p_g14': 1.0,\n",
       " 'l_p_g15': 1.0,\n",
       " 'l_p_g16': 1.0,\n",
       " 'l_p_g17': 1.0}"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "ModelSpecs, varmappers, parmappers, model_path = dict(), dict(), dict(), dict()\n",
    "time_length = int(settings['simulation_time']/settings['integration_step_size'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Set perturb rulse for ground-truth graphs\n",
    "pert_method = \"swap\"\n",
    "\n",
    "btw_graphs = 1500\n",
    "num_graphs, num_pert = time_length//btw_graphs, 5\n",
    "\n",
    "print(\"Num Graphs: {}, Num Pert: {}\".format(num_graphs,num_pert))\n",
    "sub_path = path + pert_method + \"_time_\" + str(time_length) + \"_graphs_\" + str(num_graphs) + \"(\" + str(num_pert) + \")_1to2/\"\n",
    "\n",
    "simgraphpath = Path(sub_path + \"./graphs/\")\n",
    "if not os.path.exists(simgraphpath):\n",
    "    os.makedirs(simgraphpath)\n",
    "    \n",
    "simmodelpath = Path(sub_path + \"./models/\")\n",
    "if not os.path.exists(simmodelpath):\n",
    "    os.makedirs(simmodelpath)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num Graphs: 5, Num Pert: 5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import importlib\n",
    "importlib.reload()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Gen ground-truth graphs\n",
    "for grn_num in range(num_graphs):\n",
    "\n",
    "    # df saves the binary regulation rules (boolean network) gene\\t bool regulation\n",
    "    if grn_num == 0: # initial graph_0\n",
    "        df.to_csv(sub_path + \"graphs/graph_\"+str(grn_num)+\".txt\",header=True, index=False, sep=\"\\t\")\n",
    "\n",
    "    if grn_num > 0:\n",
    "        rows = np.random.choice(genes, num_pert*2, replace = False) - 1\n",
    "        df.values[:,1][rows] = df.values[:,1][rows[::-1]]\n",
    "        df.to_csv(sub_path + \"graphs/graph_\"+str(grn_num)+\".txt\",header=True, index=False, sep=\"\\t\")\n",
    "\n",
    "    # df stores the regulation relationship, setting is the generall setting of the simulator, inputs?? par is the parameter for hill function, genelist and proteinlist\n",
    "    # varspecs is the disctionary of regulation relationship, empty for each gene and protein \n",
    "    ModelSpec, varmapper, parmapper = util.model_generate(df, settings, withRules, inputs, par, genelist, proteinlist, varspecs)\n",
    "\n",
    "    ModelSpecs[grn_num]=copy.deepcopy(ModelSpec)\n",
    "    varmappers[grn_num]=copy.deepcopy(varmapper)\n",
    "    parmappers[grn_num]=copy.deepcopy(parmapper)\n",
    "\n",
    "    model_path[grn_num] = fnc.writeModelToFile(grn_num, ModelSpec, varmapper, path = sub_path + \"models/\")\n",
    "    fnc.generateInputFiles(df, withoutRules, grn_num, path = sub_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "varmapper"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: 'x_g0',\n",
       " 1: 'p_g0',\n",
       " 2: 'x_g1',\n",
       " 3: 'p_g1',\n",
       " 4: 'x_g2',\n",
       " 5: 'p_g2',\n",
       " 6: 'x_g3',\n",
       " 7: 'p_g3',\n",
       " 8: 'x_g4',\n",
       " 9: 'p_g4',\n",
       " 10: 'x_g5',\n",
       " 11: 'p_g5',\n",
       " 12: 'x_g6',\n",
       " 13: 'p_g6',\n",
       " 14: 'x_g7',\n",
       " 15: 'p_g7',\n",
       " 16: 'x_g8',\n",
       " 17: 'p_g8',\n",
       " 18: 'x_g9',\n",
       " 19: 'p_g9',\n",
       " 20: 'x_g10',\n",
       " 21: 'p_g10',\n",
       " 22: 'x_g11',\n",
       " 23: 'p_g11',\n",
       " 24: 'x_g12',\n",
       " 25: 'p_g12',\n",
       " 26: 'x_g13',\n",
       " 27: 'p_g13',\n",
       " 28: 'x_g14',\n",
       " 29: 'p_g14',\n",
       " 30: 'x_g15',\n",
       " 31: 'p_g15',\n",
       " 32: 'x_g16',\n",
       " 33: 'p_g16',\n",
       " 34: 'x_g17',\n",
       " 35: 'p_g17'}"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "ModelSpec"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'varspecs': {'x_g0': 'm_g0*(( alpha_g0 + a_g0_g16*(p_g16/k_g16)^n_g16 )/( 1 +(p_g16/k_g16)^n_g16 ))-l_x_g0*x_g0',\n",
       "  'p_g0': 'r_g0*x_g0- l_p_g0*p_g0',\n",
       "  'x_g1': 'm_g1*(( alpha_g1 + a_g1_g11*(p_g11/k_g11)^n_g11 )/( 1 +(p_g11/k_g11)^n_g11 ))-l_x_g1*x_g1',\n",
       "  'p_g1': 'r_g1*x_g1- l_p_g1*p_g1',\n",
       "  'x_g2': 'm_g2*(( alpha_g2 + a_g2_g4*(p_g4/k_g4)^n_g4 )/( 1 +(p_g4/k_g4)^n_g4 ))-l_x_g2*x_g2',\n",
       "  'p_g2': 'r_g2*x_g2- l_p_g2*p_g2',\n",
       "  'x_g3': 'm_g3*(( alpha_g3 + a_g3_g4*(p_g4/k_g4)^n_g4 )/( 1 +(p_g4/k_g4)^n_g4 ))-l_x_g3*x_g3',\n",
       "  'p_g3': 'r_g3*x_g3- l_p_g3*p_g3',\n",
       "  'x_g4': 'm_g4*(( alpha_g4 + a_g4_g2*(p_g2/k_g2)^n_g2 )/( 1 +(p_g2/k_g2)^n_g2 ))-l_x_g4*x_g4',\n",
       "  'p_g4': 'r_g4*x_g4- l_p_g4*p_g4',\n",
       "  'x_g5': 'm_g5*(( alpha_g5 + a_g5_g11*(p_g11/k_g11)^n_g11 )/( 1 +(p_g11/k_g11)^n_g11 ))-l_x_g5*x_g5',\n",
       "  'p_g5': 'r_g5*x_g5- l_p_g5*p_g5',\n",
       "  'x_g6': 'm_g6*(( alpha_g6 + a_g6_g16*(p_g16/k_g16)^n_g16 )/( 1 +(p_g16/k_g16)^n_g16 ))-l_x_g6*x_g6',\n",
       "  'p_g6': 'r_g6*x_g6- l_p_g6*p_g6',\n",
       "  'x_g7': 'm_g7*(( alpha_g7 + a_g7_g3*(p_g3/k_g3)^n_g3 )/( 1 +(p_g3/k_g3)^n_g3 ))-l_x_g7*x_g7',\n",
       "  'p_g7': 'r_g7*x_g7- l_p_g7*p_g7',\n",
       "  'x_g8': 'm_g8*(( alpha_g8 + a_g8_g16*(p_g16/k_g16)^n_g16 )/( 1 +(p_g16/k_g16)^n_g16 ))-l_x_g8*x_g8',\n",
       "  'p_g8': 'r_g8*x_g8- l_p_g8*p_g8',\n",
       "  'x_g9': 'm_g9*(( alpha_g9 + a_g9_g15*(p_g15/k_g15)^n_g15 )/( 1 +(p_g15/k_g15)^n_g15 ))-l_x_g9*x_g9',\n",
       "  'p_g9': 'r_g9*x_g9- l_p_g9*p_g9',\n",
       "  'x_g10': 'm_g10*(( alpha_g10 + a_g10_g2*(p_g2/k_g2)^n_g2 )/( 1 +(p_g2/k_g2)^n_g2 ))-l_x_g10*x_g10',\n",
       "  'p_g10': 'r_g10*x_g10- l_p_g10*p_g10',\n",
       "  'x_g11': 'm_g11*(( alpha_g11 + a_g11_g4*(p_g4/k_g4)^n_g4 )/( 1 +(p_g4/k_g4)^n_g4 ))-l_x_g11*x_g11',\n",
       "  'p_g11': 'r_g11*x_g11- l_p_g11*p_g11',\n",
       "  'x_g12': 'm_g12*(( alpha_g12 + a_g12_g11*(p_g11/k_g11)^n_g11 )/( 1 +(p_g11/k_g11)^n_g11 ))-l_x_g12*x_g12',\n",
       "  'p_g12': 'r_g12*x_g12- l_p_g12*p_g12',\n",
       "  'x_g13': 'm_g13*(( alpha_g13 + a_g13_g15*(p_g15/k_g15)^n_g15 )/( 1 +(p_g15/k_g15)^n_g15 ))-l_x_g13*x_g13',\n",
       "  'p_g13': 'r_g13*x_g13- l_p_g13*p_g13',\n",
       "  'x_g14': 'm_g14*(( alpha_g14 + a_g14_g3*(p_g3/k_g3)^n_g3 )/( 1 +(p_g3/k_g3)^n_g3 ))-l_x_g14*x_g14',\n",
       "  'p_g14': 'r_g14*x_g14- l_p_g14*p_g14',\n",
       "  'x_g15': 'm_g15*(( alpha_g15 + a_g15_g2*(p_g2/k_g2)^n_g2 )/( 1 +(p_g2/k_g2)^n_g2 ))-l_x_g15*x_g15',\n",
       "  'p_g15': 'r_g15*x_g15- l_p_g15*p_g15',\n",
       "  'x_g16': 'm_g16*(( alpha_g16 + a_g16_g3*(p_g3/k_g3)^n_g3 )/( 1 +(p_g3/k_g3)^n_g3 ))-l_x_g16*x_g16',\n",
       "  'p_g16': 'r_g16*x_g16- l_p_g16*p_g16',\n",
       "  'x_g17': 'm_g17*(( alpha_g17 + a_g17_g15*(p_g15/k_g15)^n_g15 )/( 1 +(p_g15/k_g15)^n_g15 ))-l_x_g17*x_g17',\n",
       "  'p_g17': 'r_g17*x_g17- l_p_g17*p_g17'},\n",
       " 'pars': {'n_g0': 10.0,\n",
       "  'n_g1': 10.0,\n",
       "  'n_g2': 10.0,\n",
       "  'n_g3': 10.0,\n",
       "  'n_g4': 10.0,\n",
       "  'n_g5': 10.0,\n",
       "  'n_g6': 10.0,\n",
       "  'n_g7': 10.0,\n",
       "  'n_g8': 10.0,\n",
       "  'n_g9': 10.0,\n",
       "  'n_g10': 10.0,\n",
       "  'n_g11': 10.0,\n",
       "  'n_g12': 10.0,\n",
       "  'n_g13': 10.0,\n",
       "  'n_g14': 10.0,\n",
       "  'n_g15': 10.0,\n",
       "  'n_g16': 10.0,\n",
       "  'n_g17': 10.0,\n",
       "  'k_g0': 10.0,\n",
       "  'k_g1': 10.0,\n",
       "  'k_g2': 10.0,\n",
       "  'k_g3': 10.0,\n",
       "  'k_g4': 10.0,\n",
       "  'k_g5': 10.0,\n",
       "  'k_g6': 10.0,\n",
       "  'k_g7': 10.0,\n",
       "  'k_g8': 10.0,\n",
       "  'k_g9': 10.0,\n",
       "  'k_g10': 10.0,\n",
       "  'k_g11': 10.0,\n",
       "  'k_g12': 10.0,\n",
       "  'k_g13': 10.0,\n",
       "  'k_g14': 10.0,\n",
       "  'k_g15': 10.0,\n",
       "  'k_g16': 10.0,\n",
       "  'k_g17': 10.0,\n",
       "  'sigmaH_g0': 10.0,\n",
       "  'sigmaH_g1': 10.0,\n",
       "  'sigmaH_g2': 10.0,\n",
       "  'sigmaH_g3': 10.0,\n",
       "  'sigmaH_g4': 10.0,\n",
       "  'sigmaH_g5': 10.0,\n",
       "  'sigmaH_g6': 10.0,\n",
       "  'sigmaH_g7': 10.0,\n",
       "  'sigmaH_g8': 10.0,\n",
       "  'sigmaH_g9': 10.0,\n",
       "  'sigmaH_g10': 10.0,\n",
       "  'sigmaH_g11': 10.0,\n",
       "  'sigmaH_g12': 10.0,\n",
       "  'sigmaH_g13': 10.0,\n",
       "  'sigmaH_g14': 10.0,\n",
       "  'sigmaH_g15': 10.0,\n",
       "  'sigmaH_g16': 10.0,\n",
       "  'sigmaH_g17': 10.0,\n",
       "  'm_g0': 20.0,\n",
       "  'm_g1': 20.0,\n",
       "  'm_g2': 20.0,\n",
       "  'm_g3': 20.0,\n",
       "  'm_g4': 20.0,\n",
       "  'm_g5': 20.0,\n",
       "  'm_g6': 20.0,\n",
       "  'm_g7': 20.0,\n",
       "  'm_g8': 20.0,\n",
       "  'm_g9': 20.0,\n",
       "  'm_g10': 20.0,\n",
       "  'm_g11': 20.0,\n",
       "  'm_g12': 20.0,\n",
       "  'm_g13': 20.0,\n",
       "  'm_g14': 20.0,\n",
       "  'm_g15': 20.0,\n",
       "  'm_g16': 20.0,\n",
       "  'm_g17': 20.0,\n",
       "  'l_x_g0': 10.0,\n",
       "  'l_x_g1': 10.0,\n",
       "  'l_x_g2': 10.0,\n",
       "  'l_x_g3': 10.0,\n",
       "  'l_x_g4': 10.0,\n",
       "  'l_x_g5': 10.0,\n",
       "  'l_x_g6': 10.0,\n",
       "  'l_x_g7': 10.0,\n",
       "  'l_x_g8': 10.0,\n",
       "  'l_x_g9': 10.0,\n",
       "  'l_x_g10': 10.0,\n",
       "  'l_x_g11': 10.0,\n",
       "  'l_x_g12': 10.0,\n",
       "  'l_x_g13': 10.0,\n",
       "  'l_x_g14': 10.0,\n",
       "  'l_x_g15': 10.0,\n",
       "  'l_x_g16': 10.0,\n",
       "  'l_x_g17': 10.0,\n",
       "  'r_g0': 10.0,\n",
       "  'r_g1': 10.0,\n",
       "  'r_g2': 10.0,\n",
       "  'r_g3': 10.0,\n",
       "  'r_g4': 10.0,\n",
       "  'r_g5': 10.0,\n",
       "  'r_g6': 10.0,\n",
       "  'r_g7': 10.0,\n",
       "  'r_g8': 10.0,\n",
       "  'r_g9': 10.0,\n",
       "  'r_g10': 10.0,\n",
       "  'r_g11': 10.0,\n",
       "  'r_g12': 10.0,\n",
       "  'r_g13': 10.0,\n",
       "  'r_g14': 10.0,\n",
       "  'r_g15': 10.0,\n",
       "  'r_g16': 10.0,\n",
       "  'r_g17': 10.0,\n",
       "  'l_p_g0': 1.0,\n",
       "  'l_p_g1': 1.0,\n",
       "  'l_p_g2': 1.0,\n",
       "  'l_p_g3': 1.0,\n",
       "  'l_p_g4': 1.0,\n",
       "  'l_p_g5': 1.0,\n",
       "  'l_p_g6': 1.0,\n",
       "  'l_p_g7': 1.0,\n",
       "  'l_p_g8': 1.0,\n",
       "  'l_p_g9': 1.0,\n",
       "  'l_p_g10': 1.0,\n",
       "  'l_p_g11': 1.0,\n",
       "  'l_p_g12': 1.0,\n",
       "  'l_p_g13': 1.0,\n",
       "  'l_p_g14': 1.0,\n",
       "  'l_p_g15': 1.0,\n",
       "  'l_p_g16': 1.0,\n",
       "  'l_p_g17': 1.0,\n",
       "  'alpha_g0': 0,\n",
       "  'alpha_g1': 1,\n",
       "  'alpha_g2': 0,\n",
       "  'alpha_g3': 1,\n",
       "  'alpha_g4': 0,\n",
       "  'alpha_g5': 1,\n",
       "  'alpha_g6': 0,\n",
       "  'alpha_g7': 0,\n",
       "  'alpha_g8': 0,\n",
       "  'alpha_g9': 0,\n",
       "  'alpha_g10': 1,\n",
       "  'alpha_g11': 1,\n",
       "  'alpha_g12': 0,\n",
       "  'alpha_g13': 0,\n",
       "  'alpha_g14': 1,\n",
       "  'alpha_g15': 1,\n",
       "  'alpha_g16': 1,\n",
       "  'alpha_g17': 0,\n",
       "  'a_g0_g16': 1,\n",
       "  'a_g1_g11': 0,\n",
       "  'a_g2_g4': 1,\n",
       "  'a_g3_g4': 0,\n",
       "  'a_g4_g2': 1,\n",
       "  'a_g5_g11': 0,\n",
       "  'a_g6_g16': 1,\n",
       "  'a_g7_g3': 1,\n",
       "  'a_g8_g16': 1,\n",
       "  'a_g9_g15': 1,\n",
       "  'a_g10_g2': 0,\n",
       "  'a_g11_g4': 0,\n",
       "  'a_g12_g11': 1,\n",
       "  'a_g13_g15': 1,\n",
       "  'a_g14_g3': 0,\n",
       "  'a_g15_g2': 0,\n",
       "  'a_g16_g3': 0,\n",
       "  'a_g17_g15': 1},\n",
       " 'ics': {'x_g0': 1.0,\n",
       "  'p_g0': 0,\n",
       "  'x_g1': 1.0,\n",
       "  'p_g1': 0,\n",
       "  'x_g2': 1.0,\n",
       "  'p_g2': 0,\n",
       "  'x_g3': 1.0,\n",
       "  'p_g3': 0,\n",
       "  'x_g4': 1.0,\n",
       "  'p_g4': 0,\n",
       "  'x_g5': 1.0,\n",
       "  'p_g5': 0,\n",
       "  'x_g6': 1.0,\n",
       "  'p_g6': 0,\n",
       "  'x_g7': 1.0,\n",
       "  'p_g7': 0,\n",
       "  'x_g8': 1.0,\n",
       "  'p_g8': 0,\n",
       "  'x_g9': 1.0,\n",
       "  'p_g9': 0,\n",
       "  'x_g10': 1.0,\n",
       "  'p_g10': 0,\n",
       "  'x_g11': 1.0,\n",
       "  'p_g11': 0,\n",
       "  'x_g12': 1.0,\n",
       "  'p_g12': 0,\n",
       "  'x_g13': 1.0,\n",
       "  'p_g13': 0,\n",
       "  'x_g14': 1.0,\n",
       "  'p_g14': 0,\n",
       "  'x_g15': 1.0,\n",
       "  'p_g15': 0,\n",
       "  'x_g16': 1.0,\n",
       "  'p_g16': 0,\n",
       "  'x_g17': 1.0,\n",
       "  'p_g17': 0}}"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Initialize Expression data - using first Graph (graph_0)\n",
    "init_Model = ModelSpecs[0]\n",
    "init_varmap = varmappers[0]\n",
    "init_parmap = parmappers[0]\n",
    "\n",
    "####################\n",
    "rnaIndex = [i for i in range(len(init_varmap.keys())) if 'x_' in init_varmap[i]]\n",
    "revvarmapper = {v:k for k,v in init_varmap.items()}\n",
    "proteinIndex = [i for i in range(len(init_varmap.keys())) if 'p_' in init_varmap[i]]\n",
    "\n",
    "y0 = [ModelSpec['ics'][init_varmap[i]] for i in range(len(init_varmap.keys()))]\n",
    "ss = np.zeros(len(init_varmap.keys()))\n",
    "\n",
    "for i,k in init_varmap.items():\n",
    "    if 'x_' in k:\n",
    "        ss[i] = 1.0\n",
    "    elif 'p_' in k:\n",
    "        if k.replace('p_','') in proteinlist:\n",
    "            ss[i] = 20."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "tmax = settings['simulation_time']\n",
    "integration_step_size = settings['integration_step_size']\n",
    "tspan = np.linspace(0,tmax,int(tmax/integration_step_size))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#Load initial expression values\n",
    "init_exp = {\"Genes\":[\"['g1']\"], \"Values\":\"[1]\"}\n",
    "icsDF = pd.DataFrame(data=init_exp)\n",
    "\n",
    "if not icsDF.empty:\n",
    "    icsspec = icsDF.loc[0]\n",
    "    genes = ast.literal_eval(icsspec['Genes'])\n",
    "    values = ast.literal_eval(icsspec['Values'])\n",
    "    icsmap = {g:v for g,v in zip(genes,values)}\n",
    "    for i,k in init_varmap.items():\n",
    "        for g in genelist:\n",
    "            if g in icsmap.keys():\n",
    "                ss[revvarmapper['x_'+g]] = icsmap[g]\n",
    "            else:\n",
    "                ss[revvarmapper['x_'+g]] = 0.01\n",
    "\n",
    "result = pd.DataFrame(index=pd.Index([varmapper[i] for i in rnaIndex]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Index of every possible time point. Sample from this list\n",
    "startat = 0\n",
    "timeIndex = [i for i in range(startat, len(tspan))]\n",
    "\n",
    "groupedDict = {}\n",
    "\n",
    "simfilepath = Path(sub_path + \"./simulations/\")\n",
    "if not os.path.exists(simfilepath):\n",
    "    os.makedirs(simfilepath)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Initialize\n",
    "new_ics = [0 for _ in range(len(varmapper.keys()))]\n",
    "\n",
    "# Set the mRNA ics\n",
    "for ind in rnaIndex:\n",
    "    if ss[ind] < 0:\n",
    "        ss[ind] = 0.0\n",
    "    new_ics[ind] =  ss[ind]\n",
    "    if new_ics[ind] < 0:\n",
    "        new_ics[ind] = 0\n",
    "for p in proteinlist:\n",
    "    ind = revvarmapper['p_'+p]\n",
    "    if ss[ind] < 0:\n",
    "        ss[ind] = 0.0\n",
    "    new_ics[ind] =  ss[ind]\n",
    "    if new_ics[ind] < 0:\n",
    "        new_ics[ind] = 0\n",
    "        \n",
    "# Calculate the Protein ics based on mRNA levels\n",
    "for genename in genelist:\n",
    "    pss = ((ModelSpec['pars']['r_' + genename])/(ModelSpec['pars']['l_p_' + genename]))*new_ics[revvarmapper['x_' + genename]]\n",
    "    new_ics[revvarmapper['p_' + genename.replace('_','')]] = pss\n",
    "    \n",
    "argdict = {}\n",
    "argdict['Model'] = model_path\n",
    "argdict['tspan'] = tspan\n",
    "argdict['varmapper'] = init_varmap\n",
    "argdict['timeIndex'] = timeIndex\n",
    "argdict['genelist'] = genelist\n",
    "argdict['proteinlist'] = proteinlist\n",
    "argdict['ss'] = ss\n",
    "argdict['ModelSpecs'] = ModelSpecs\n",
    "argdict['parmappers'] = parmappers\n",
    "argdict['rnaIndex'] = rnaIndex\n",
    "argdict['proteinIndex'] = proteinIndex\n",
    "argdict['revvarmapper'] = revvarmapper\n",
    "argdict['x_max'] = kineticParameterDefaults['x_max']\n",
    "\n",
    "if settings['doParallel']:\n",
    "    with mp.Pool() as pool:\n",
    "        jobs = []\n",
    "        for cellid in range(settings['num_cells']):\n",
    "            cell_args = dict(argdict, seed=cellid, cellid=cellid)\n",
    "            job = pool.apply_async(fnc.simulateAndSample, args=(cell_args,new_ics))\n",
    "            jobs.append(job)\n",
    "\n",
    "        for job in jobs:\n",
    "            job.wait()\n",
    "# not doing it in a parallel manner\n",
    "else:\n",
    "    # for each cellid, give a new experiment with new seed.\n",
    "    for cellid in tqdm(range(settings['num_cells'])):\n",
    "        argdict['seed'] = cellid\n",
    "        argdict['cellid'] = cellid\n",
    "        fnc.simulateAndSample(argdict, new_ics, path = sub_path)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.61s/it]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# # after running the simulation, sample cells, print expression and pseudotime\n",
    "# frames = []\n",
    "# print('starting to concat files')\n",
    "# for cellid in tqdm(range(settings['num_cells'])):\n",
    "#     # cellid correspond to the cellid-th experiment, read in the gene expression simulation for the cellid-th experiment\n",
    "#     df = pd.read_csv(sub_path + './simulations/E'+str(cellid) + '.csv',index_col=0)\n",
    "#     # df of the form genes by times\n",
    "#     df = df.sort_index()\n",
    "#     # times by genes\n",
    "#     frames.append(df.T)\n",
    "    \n",
    "# # experiment * times by genes, \n",
    "# result = pd.concat(frames,axis=0)\n",
    "# result = result.T\n",
    "\n",
    "# # indices are gene names\n",
    "# indices = result.index\n",
    "# newindices = [i.replace('x_','') for i in indices]\n",
    "# result.index = pd.Index(newindices)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Re-organizing generated simulation data: 1. cell expression data 2. ground-truth adjacent matrix\n",
    "# consider the first single cell trajectory\n",
    "\n",
    "exp_data = pd.read_csv(sub_path + \"simulations/E0.csv\", index_col = 0) \n",
    "\n",
    "_, ntime_1 = exp_data.shape\n",
    "time_len = ntime_1 + 1\n",
    "\n",
    "if exp_data.shape[1] != time_len:\n",
    "    (cell, time) = exp_data.columns[-1].split('_')\n",
    "    exp_data[cell+'_'+str(int(time)+1)]=exp_data[cell+'_'+time]\n",
    "    \n",
    "# Sort based on time - order\n",
    "sorted_exp = np.array(exp_data)[:,np.argsort([int(col.split(\"_\")[1]) for col in exp_data.columns])]\n",
    "\n",
    "temp = re.compile(\"([a-zA-Z]+)([0-9]+)\")\n",
    "\n",
    "gene_dict = dict()\n",
    "gene_list = [int(gene.split(\"g\")[1]) for gene in exp_data.index]\n",
    "ngenes = len(gene_list)\n",
    "gene_rank = rankdata(gene_list, method=\"min\")\n",
    "\n",
    "for gene, rank in zip(gene_list, gene_rank):\n",
    "    gene_dict[gene] = rank\n",
    "\n",
    "ref_net = dict()\n",
    "n_graphs = len(os.listdir(sub_path + \"ground_truth\"))\n",
    "\n",
    "gt_adj = np.zeros((n_graphs,ngenes,ngenes))\n",
    "for i in range(n_graphs):\n",
    "    ref_net = pd.read_csv(sub_path + \"ground_truth/refNetwork_\" +str(i) + \".csv\", index_col = 0)\n",
    "    target = list(ref_net.index)\n",
    "    regula = list(ref_net.values[:,0])\n",
    "\n",
    "    target = [int(temp.match(idx).groups()[1]) for idx in target]\n",
    "    regula = [int(temp.match(idx).groups()[1]) for idx in regula]\n",
    "    \n",
    "    target = [gene_dict[i] for i in target]\n",
    "    regula = [gene_dict[i] for i in regula]\n",
    "    start_idx = min(gene_rank)\n",
    "    \n",
    "    for rule in range(len(target)):\n",
    "        node0, node1 = target[rule], regula[rule]\n",
    "        gt_adj[i, node0 - start_idx, node1 - start_idx] += 1\n",
    "\n",
    "gt_adj_time = np.repeat(gt_adj,btw_graphs,axis = 0)\n",
    "\n",
    "if btw_graphs > 10:\n",
    "    freq = \"discrete_\"\n",
    "else:\n",
    "    freq = \"continue_\"\n",
    "\n",
    "outpath = \"../../data/boolODE_Sep13/\"\n",
    "    \n",
    "np.save(outpath+freq+\"sorted_exp_1to2.npy\",sorted_exp) #(ngenes,ntimes)\n",
    "np.save(outpath+freq+\"gt_adj_1to2.npy\",gt_adj_time) #(ntimes,ngenes,ngenes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('bioinf': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "interpreter": {
   "hash": "aedeb3d55b404d0a6eda26e22090d40e5203794bacb169c59b205bf78d5b079a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}