{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys, os\n",
    "sys.path.append('../../src/')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "import bmk_beeline as bmk\n",
    "import genie3, g_admm\n",
    "import kernel\n",
    "import time\n",
    "import gc\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "import os\n",
    "\n",
    "def get_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct  8 13:28:19 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:3B:00.0 Off |                    0 |\r\n",
      "| N/A   31C    P0    39W / 300W |      3MiB / 32510MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32507]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw TimePoints: 1000, no.Genes: 100\n",
      "test without TF information\n",
      "final number of nearest neighbor (make connected): 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/home/ziqi/.conda/envs/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:88: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time calculating the kernel function: 4.16 sec\n",
      "start running batch 0\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 10, duality gap: 1.0731e-02, primal residual: 1.2042e-01, dual residual: 2.401700e+00\n",
      "n_iter: 20, duality gap: 1.3822e-03, primal residual: 3.9413e-02, dual residual: 1.388673e+00\n",
      "n_iter: 30, duality gap: 6.6235e-04, primal residual: 2.0869e-02, dual residual: 9.760806e-01\n",
      "n_iter: 40, duality gap: 3.0169e-04, primal residual: 1.4262e-02, dual residual: 7.426220e-01\n",
      "n_iter: 50, duality gap: 2.4671e-04, primal residual: 1.1412e-02, dual residual: 5.908180e-01\n",
      "n_iter: 60, duality gap: 2.6895e-04, primal residual: 9.4825e-03, dual residual: 4.837289e-01\n",
      "n_iter: 70, duality gap: 1.7489e-04, primal residual: 7.6330e-03, dual residual: 4.036063e-01\n",
      "n_iter: 80, duality gap: 1.4460e-04, primal residual: 6.3247e-03, dual residual: 3.418597e-01\n",
      "n_iter: 90, duality gap: 1.2067e-04, primal residual: 5.1701e-03, dual residual: 2.930677e-01\n",
      "n_iter: 100, duality gap: 1.3348e-04, primal residual: 4.9522e-03, dual residual: 2.531371e-01\n",
      "n_iter: 110, duality gap: 1.3201e-04, primal residual: 3.8720e-03, dual residual: 2.201824e-01\n",
      "n_iter: 120, duality gap: 1.0275e-04, primal residual: 3.2596e-03, dual residual: 1.928488e-01\n",
      "n_iter: 130, duality gap: 1.1061e-04, primal residual: 2.7712e-03, dual residual: 1.697564e-01\n",
      "n_iter: 140, duality gap: 7.6141e-05, primal residual: 2.5229e-03, dual residual: 1.500796e-01\n",
      "n_iter: 150, duality gap: 6.4342e-05, primal residual: 2.2209e-03, dual residual: 1.331955e-01\n",
      "n_iter: 160, duality gap: 7.2618e-05, primal residual: 2.2796e-03, dual residual: 1.184232e-01\n",
      "n_iter: 170, duality gap: 4.7571e-05, primal residual: 1.9139e-03, dual residual: 1.056489e-01\n",
      "n_iter: 180, duality gap: 4.2542e-05, primal residual: 1.7592e-03, dual residual: 9.451304e-02\n",
      "n_iter: 190, duality gap: 3.7186e-05, primal residual: 1.4371e-03, dual residual: 8.470111e-02\n",
      "n_iter: 200, duality gap: 3.7117e-05, primal residual: 1.3644e-03, dual residual: 7.606862e-02\n",
      "n_iter: 210, duality gap: 2.5781e-05, primal residual: 1.2328e-03, dual residual: 6.841862e-02\n",
      "n_iter: 220, duality gap: 3.3061e-05, primal residual: 1.2117e-03, dual residual: 6.162635e-02\n",
      "n_iter: 230, duality gap: 2.5498e-05, primal residual: 1.1579e-03, dual residual: 5.560120e-02\n",
      "n_iter: 240, duality gap: 2.6686e-05, primal residual: 1.0620e-03, dual residual: 5.022793e-02\n",
      "n_iter: 250, duality gap: 2.9921e-05, primal residual: 9.9302e-04, dual residual: 4.542445e-02\n",
      "n_iter: 260, duality gap: 2.1227e-05, primal residual: 9.7643e-04, dual residual: 4.114028e-02\n",
      "n_iter: 270, duality gap: 2.4700e-05, primal residual: 9.8587e-04, dual residual: 3.727027e-02\n",
      "n_iter: 280, duality gap: 2.1962e-05, primal residual: 9.0938e-04, dual residual: 3.378449e-02\n",
      "n_iter: 290, duality gap: 2.3459e-05, primal residual: 8.9884e-04, dual residual: 3.066853e-02\n",
      "n_iter: 300, duality gap: 2.0022e-05, primal residual: 8.9830e-04, dual residual: 2.786607e-02\n",
      "n_iter: 310, duality gap: 1.8931e-05, primal residual: 8.7939e-04, dual residual: 2.532088e-02\n",
      "n_iter: 320, duality gap: 1.8664e-05, primal residual: 8.6982e-04, dual residual: 2.302730e-02\n",
      "n_iter: 330, duality gap: 1.9135e-05, primal residual: 8.5512e-04, dual residual: 2.094918e-02\n",
      "n_iter: 340, duality gap: 2.1620e-05, primal residual: 8.6666e-04, dual residual: 1.908814e-02\n",
      "n_iter: 350, duality gap: 2.2950e-05, primal residual: 8.7842e-04, dual residual: 1.738025e-02\n",
      "n_iter: 360, duality gap: 1.7160e-05, primal residual: 8.9409e-04, dual residual: 1.585271e-02\n",
      "n_iter: 370, duality gap: 1.4134e-05, primal residual: 9.6778e-04, dual residual: 1.445534e-02\n",
      "n_iter: 380, duality gap: 1.5446e-05, primal residual: 9.0192e-04, dual residual: 1.319791e-02\n",
      "n_iter: 390, duality gap: 1.5291e-05, primal residual: 9.2624e-04, dual residual: 1.204373e-02\n",
      "n_iter: 400, duality gap: 1.9854e-05, primal residual: 9.2259e-04, dual residual: 1.100524e-02\n",
      "n_iter: 410, duality gap: 1.4700e-05, primal residual: 9.1655e-04, dual residual: 1.004205e-02\n",
      "n_iter: 420, duality gap: 1.5522e-05, primal residual: 9.4161e-04, dual residual: 9.192089e-03\n",
      "n_iter: 430, duality gap: 1.6291e-05, primal residual: 8.8531e-04, dual residual: 8.406282e-03\n",
      "n_iter: 440, duality gap: 1.7754e-05, primal residual: 8.8704e-04, dual residual: 7.689109e-03\n",
      "n_iter: 450, duality gap: 1.2839e-05, primal residual: 8.8020e-04, dual residual: 7.031403e-03\n",
      "n_iter: 460, duality gap: 1.6936e-05, primal residual: 8.4475e-04, dual residual: 6.441390e-03\n",
      "n_iter: 470, duality gap: 1.8987e-05, primal residual: 8.7545e-04, dual residual: 5.886285e-03\n",
      "n_iter: 480, duality gap: 2.3606e-05, primal residual: 8.7210e-04, dual residual: 5.405972e-03\n",
      "n_iter: 490, duality gap: 1.4871e-05, primal residual: 8.8189e-04, dual residual: 4.952429e-03\n",
      "n_iter: 500, duality gap: 1.4042e-05, primal residual: 9.1367e-04, dual residual: 4.546722e-03\n",
      "Batch loss: loss1: -5768.33350, loss2: 305076.75000, loss3: 0.00000\n",
      "Finished running batch 0.\n",
      "start running batch 1\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 10, duality gap: 9.9029e-03, primal residual: 1.1575e-01, dual residual: 2.222627e+00\n",
      "n_iter: 20, duality gap: 7.7026e-04, primal residual: 3.4402e-02, dual residual: 1.239489e+00\n",
      "n_iter: 30, duality gap: 3.2652e-04, primal residual: 1.6502e-02, dual residual: 8.469835e-01\n",
      "n_iter: 40, duality gap: 2.8769e-04, primal residual: 1.0466e-02, dual residual: 6.281040e-01\n",
      "n_iter: 50, duality gap: 2.3300e-04, primal residual: 7.4637e-03, dual residual: 4.875713e-01\n",
      "n_iter: 60, duality gap: 1.9316e-04, primal residual: 6.0048e-03, dual residual: 3.895424e-01\n",
      "n_iter: 70, duality gap: 1.9829e-04, primal residual: 5.3693e-03, dual residual: 3.173483e-01\n",
      "n_iter: 80, duality gap: 1.5274e-04, primal residual: 4.1140e-03, dual residual: 2.628021e-01\n",
      "n_iter: 90, duality gap: 1.3570e-04, primal residual: 3.2776e-03, dual residual: 2.201477e-01\n",
      "n_iter: 100, duality gap: 9.0044e-05, primal residual: 2.7687e-03, dual residual: 1.861479e-01\n",
      "n_iter: 110, duality gap: 9.7135e-05, primal residual: 2.2670e-03, dual residual: 1.586255e-01\n",
      "n_iter: 120, duality gap: 6.0965e-05, primal residual: 1.9151e-03, dual residual: 1.359084e-01\n",
      "n_iter: 130, duality gap: 5.8474e-05, primal residual: 1.6774e-03, dual residual: 1.170380e-01\n",
      "n_iter: 140, duality gap: 6.0095e-05, primal residual: 1.4524e-03, dual residual: 1.012610e-01\n",
      "n_iter: 150, duality gap: 4.9970e-05, primal residual: 1.2091e-03, dual residual: 8.783706e-02\n",
      "n_iter: 160, duality gap: 3.8315e-05, primal residual: 1.0704e-03, dual residual: 7.642014e-02\n",
      "n_iter: 170, duality gap: 3.4573e-05, primal residual: 9.5444e-04, dual residual: 6.667937e-02\n",
      "n_iter: 180, duality gap: 2.7586e-05, primal residual: 9.0586e-04, dual residual: 5.833811e-02\n",
      "n_iter: 190, duality gap: 2.2986e-05, primal residual: 7.9327e-04, dual residual: 5.115679e-02\n",
      "n_iter: 200, duality gap: 1.8729e-05, primal residual: 6.7592e-04, dual residual: 4.495994e-02\n",
      "n_iter: 210, duality gap: 1.6909e-05, primal residual: 6.5974e-04, dual residual: 3.954010e-02\n",
      "n_iter: 220, duality gap: 2.0624e-05, primal residual: 5.8156e-04, dual residual: 3.478851e-02\n",
      "n_iter: 230, duality gap: 1.4236e-05, primal residual: 5.1929e-04, dual residual: 3.069096e-02\n",
      "n_iter: 240, duality gap: 1.4862e-05, primal residual: 5.3736e-04, dual residual: 2.711411e-02\n",
      "n_iter: 250, duality gap: 1.3839e-05, primal residual: 5.1930e-04, dual residual: 2.395752e-02\n",
      "n_iter: 260, duality gap: 1.2706e-05, primal residual: 4.8765e-04, dual residual: 2.117669e-02\n",
      "n_iter: 270, duality gap: 1.1115e-05, primal residual: 4.8033e-04, dual residual: 1.876214e-02\n",
      "n_iter: 280, duality gap: 1.3285e-05, primal residual: 4.9239e-04, dual residual: 1.661473e-02\n",
      "n_iter: 290, duality gap: 1.1798e-05, primal residual: 4.8303e-04, dual residual: 1.473086e-02\n",
      "n_iter: 300, duality gap: 1.0605e-05, primal residual: 4.7803e-04, dual residual: 1.307743e-02\n",
      "n_iter: 310, duality gap: 8.1054e-06, primal residual: 4.7452e-04, dual residual: 1.161048e-02\n",
      "n_iter: 320, duality gap: 7.5583e-06, primal residual: 4.9669e-04, dual residual: 1.032156e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter: 330, duality gap: 9.5756e-06, primal residual: 4.9188e-04, dual residual: 9.177831e-03\n",
      "n_iter: 340, duality gap: 9.0694e-06, primal residual: 4.6964e-04, dual residual: 8.163795e-03\n",
      "n_iter: 350, duality gap: 8.4953e-06, primal residual: 4.7546e-04, dual residual: 7.273026e-03\n",
      "n_iter: 360, duality gap: 8.2060e-06, primal residual: 4.8642e-04, dual residual: 6.474083e-03\n",
      "n_iter: 370, duality gap: 9.0253e-06, primal residual: 5.0458e-04, dual residual: 5.769648e-03\n",
      "n_iter: 380, duality gap: 6.7143e-06, primal residual: 4.6653e-04, dual residual: 5.139781e-03\n",
      "n_iter: 390, duality gap: 6.9692e-06, primal residual: 4.7395e-04, dual residual: 4.589059e-03\n",
      "n_iter: 400, duality gap: 8.5649e-06, primal residual: 4.8301e-04, dual residual: 4.096388e-03\n",
      "n_iter: 410, duality gap: 1.2352e-05, primal residual: 4.7371e-04, dual residual: 3.662123e-03\n",
      "n_iter: 420, duality gap: 7.1634e-06, primal residual: 4.8350e-04, dual residual: 3.276530e-03\n",
      "n_iter: 430, duality gap: 1.0949e-05, primal residual: 4.5931e-04, dual residual: 2.925247e-03\n",
      "n_iter: 440, duality gap: 1.0547e-05, primal residual: 4.7166e-04, dual residual: 2.626061e-03\n",
      "n_iter: 450, duality gap: 8.7397e-06, primal residual: 4.7315e-04, dual residual: 2.349343e-03\n",
      "n_iter: 460, duality gap: 8.5517e-06, primal residual: 4.6377e-04, dual residual: 2.115783e-03\n",
      "n_iter: 470, duality gap: 7.9507e-06, primal residual: 4.6845e-04, dual residual: 1.893520e-03\n",
      "n_iter: 480, duality gap: 9.8134e-06, primal residual: 4.5804e-04, dual residual: 1.717186e-03\n",
      "n_iter: 490, duality gap: 6.5314e-06, primal residual: 4.4497e-04, dual residual: 1.546492e-03\n",
      "n_iter: 500, duality gap: 1.0115e-05, primal residual: 4.6982e-04, dual residual: 1.388632e-03\n",
      "Batch loss: loss1: -3476.74023, loss2: 276446.15625, loss3: 0.00000\n",
      "Finished running batch 1.\n",
      "start running batch 2\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 10, duality gap: 7.7126e-03, primal residual: 1.0099e-01, dual residual: 2.064806e+00\n",
      "n_iter: 20, duality gap: 1.2533e-03, primal residual: 3.8478e-02, dual residual: 1.111705e+00\n",
      "n_iter: 30, duality gap: 3.9537e-04, primal residual: 2.1343e-02, dual residual: 7.380334e-01\n",
      "n_iter: 40, duality gap: 3.9555e-04, primal residual: 1.0575e-02, dual residual: 5.337245e-01\n",
      "n_iter: 50, duality gap: 2.6804e-04, primal residual: 7.7473e-03, dual residual: 4.046552e-01\n",
      "n_iter: 60, duality gap: 1.9584e-04, primal residual: 6.2949e-03, dual residual: 3.159233e-01\n",
      "n_iter: 70, duality gap: 1.9550e-04, primal residual: 5.5020e-03, dual residual: 2.517129e-01\n",
      "n_iter: 80, duality gap: 1.5753e-04, primal residual: 5.3179e-03, dual residual: 2.035905e-01\n",
      "n_iter: 90, duality gap: 1.1861e-04, primal residual: 4.8251e-03, dual residual: 1.665719e-01\n",
      "n_iter: 100, duality gap: 9.6419e-05, primal residual: 4.7987e-03, dual residual: 1.374436e-01\n",
      "n_iter: 110, duality gap: 7.9190e-05, primal residual: 4.9906e-03, dual residual: 1.141106e-01\n",
      "n_iter: 120, duality gap: 1.1185e-04, primal residual: 5.1218e-03, dual residual: 9.522776e-02\n",
      "n_iter: 130, duality gap: 5.6901e-05, primal residual: 4.8487e-03, dual residual: 7.980086e-02\n",
      "n_iter: 140, duality gap: 8.3183e-05, primal residual: 4.9964e-03, dual residual: 6.718349e-02\n",
      "n_iter: 150, duality gap: 8.4275e-05, primal residual: 4.6487e-03, dual residual: 5.676047e-02\n",
      "n_iter: 160, duality gap: 9.7993e-05, primal residual: 5.0164e-03, dual residual: 4.808209e-02\n",
      "n_iter: 170, duality gap: 8.6371e-05, primal residual: 4.7709e-03, dual residual: 4.085933e-02\n",
      "n_iter: 180, duality gap: 6.4110e-05, primal residual: 4.7557e-03, dual residual: 3.479441e-02\n",
      "n_iter: 190, duality gap: 8.4087e-05, primal residual: 4.8439e-03, dual residual: 2.970179e-02\n",
      "n_iter: 200, duality gap: 6.0547e-05, primal residual: 4.6736e-03, dual residual: 2.538084e-02\n",
      "n_iter: 210, duality gap: 6.6135e-05, primal residual: 4.8248e-03, dual residual: 2.170238e-02\n",
      "n_iter: 220, duality gap: 8.7052e-05, primal residual: 4.7019e-03, dual residual: 1.859288e-02\n",
      "n_iter: 230, duality gap: 7.0904e-05, primal residual: 4.7904e-03, dual residual: 1.594928e-02\n",
      "n_iter: 240, duality gap: 5.5040e-05, primal residual: 4.7511e-03, dual residual: 1.369505e-02\n",
      "n_iter: 250, duality gap: 6.0273e-05, primal residual: 4.8245e-03, dual residual: 1.177042e-02\n",
      "n_iter: 260, duality gap: 6.0454e-05, primal residual: 4.9093e-03, dual residual: 1.013538e-02\n",
      "n_iter: 270, duality gap: 6.9574e-05, primal residual: 4.9780e-03, dual residual: 9.505769e-03\n",
      "n_iter: 280, duality gap: 6.6927e-05, primal residual: 4.7452e-03, dual residual: 8.800115e-03\n",
      "n_iter: 290, duality gap: 8.9339e-05, primal residual: 4.7448e-03, dual residual: 8.844207e-03\n",
      "n_iter: 300, duality gap: 8.1314e-05, primal residual: 4.8086e-03, dual residual: 8.607654e-03\n",
      "n_iter: 310, duality gap: 7.5227e-05, primal residual: 4.9862e-03, dual residual: 8.438525e-03\n",
      "n_iter: 320, duality gap: 6.7980e-05, primal residual: 4.6763e-03, dual residual: 7.589752e-03\n",
      "n_iter: 330, duality gap: 7.0619e-05, primal residual: 5.0234e-03, dual residual: 7.869363e-03\n",
      "n_iter: 340, duality gap: 8.5294e-05, primal residual: 4.9175e-03, dual residual: 7.821796e-03\n",
      "n_iter: 350, duality gap: 5.2280e-05, primal residual: 4.9350e-03, dual residual: 7.970392e-03\n",
      "n_iter: 360, duality gap: 8.4250e-05, primal residual: 5.1944e-03, dual residual: 7.918766e-03\n",
      "n_iter: 370, duality gap: 7.7871e-05, primal residual: 5.0698e-03, dual residual: 7.824203e-03\n",
      "n_iter: 380, duality gap: 6.8576e-05, primal residual: 4.8813e-03, dual residual: 7.981649e-03\n",
      "n_iter: 390, duality gap: 1.0351e-04, primal residual: 4.9326e-03, dual residual: 8.033097e-03\n",
      "n_iter: 400, duality gap: 1.0059e-04, primal residual: 4.8608e-03, dual residual: 7.539777e-03\n",
      "n_iter: 410, duality gap: 8.9300e-05, primal residual: 4.7999e-03, dual residual: 7.600127e-03\n",
      "n_iter: 420, duality gap: 9.9668e-05, primal residual: 4.6872e-03, dual residual: 7.224537e-03\n",
      "n_iter: 430, duality gap: 6.8971e-05, primal residual: 5.1953e-03, dual residual: 8.230017e-03\n",
      "n_iter: 440, duality gap: 6.2761e-05, primal residual: 4.8259e-03, dual residual: 7.686709e-03\n",
      "n_iter: 450, duality gap: 8.7660e-05, primal residual: 4.7055e-03, dual residual: 8.345481e-03\n",
      "n_iter: 460, duality gap: 6.0304e-05, primal residual: 4.7789e-03, dual residual: 7.999545e-03\n",
      "n_iter: 470, duality gap: 5.4397e-05, primal residual: 4.6835e-03, dual residual: 7.724983e-03\n",
      "n_iter: 480, duality gap: 5.8405e-05, primal residual: 4.8881e-03, dual residual: 7.653708e-03\n",
      "n_iter: 490, duality gap: 6.1656e-05, primal residual: 4.9288e-03, dual residual: 7.387846e-03\n",
      "n_iter: 500, duality gap: 7.5170e-05, primal residual: 4.8187e-03, dual residual: 7.493441e-03\n",
      "Batch loss: loss1: -2091.56567, loss2: 258797.14062, loss3: 0.00000\n",
      "Finished running batch 2.\n",
      "start running batch 3\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 10, duality gap: 6.0177e-03, primal residual: 9.3727e-02, dual residual: 1.996021e+00\n",
      "n_iter: 20, duality gap: 9.6120e-04, primal residual: 4.0948e-02, dual residual: 1.056689e+00\n",
      "n_iter: 30, duality gap: 2.7042e-04, primal residual: 2.0934e-02, dual residual: 6.888105e-01\n",
      "n_iter: 40, duality gap: 3.3814e-04, primal residual: 1.4191e-02, dual residual: 4.900002e-01\n",
      "n_iter: 50, duality gap: 1.9935e-04, primal residual: 1.3843e-02, dual residual: 3.653455e-01\n",
      "n_iter: 60, duality gap: 3.0602e-04, primal residual: 1.2539e-02, dual residual: 2.800996e-01\n",
      "n_iter: 70, duality gap: 2.2853e-04, primal residual: 1.2144e-02, dual residual: 2.194885e-01\n",
      "n_iter: 80, duality gap: 2.1950e-04, primal residual: 1.2258e-02, dual residual: 1.746607e-01\n",
      "n_iter: 90, duality gap: 2.9272e-04, primal residual: 1.2219e-02, dual residual: 1.405195e-01\n",
      "n_iter: 100, duality gap: 2.8554e-04, primal residual: 1.2596e-02, dual residual: 1.143026e-01\n",
      "n_iter: 110, duality gap: 3.4938e-04, primal residual: 1.2107e-02, dual residual: 9.350263e-02\n",
      "n_iter: 120, duality gap: 1.9411e-04, primal residual: 1.2471e-02, dual residual: 7.698668e-02\n",
      "n_iter: 130, duality gap: 2.8555e-04, primal residual: 1.2974e-02, dual residual: 6.369232e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter: 140, duality gap: 2.9197e-04, primal residual: 1.1871e-02, dual residual: 5.297456e-02\n",
      "n_iter: 150, duality gap: 3.1081e-04, primal residual: 1.2323e-02, dual residual: 4.432625e-02\n",
      "n_iter: 160, duality gap: 2.9320e-04, primal residual: 1.2913e-02, dual residual: 3.829688e-02\n",
      "n_iter: 170, duality gap: 2.5773e-04, primal residual: 1.2479e-02, dual residual: 3.419298e-02\n",
      "n_iter: 180, duality gap: 2.6678e-04, primal residual: 1.2478e-02, dual residual: 3.062530e-02\n",
      "n_iter: 190, duality gap: 3.0644e-04, primal residual: 1.2309e-02, dual residual: 2.758607e-02\n",
      "n_iter: 200, duality gap: 3.7345e-04, primal residual: 1.2535e-02, dual residual: 2.491666e-02\n",
      "n_iter: 210, duality gap: 2.8092e-04, primal residual: 1.2342e-02, dual residual: 2.427400e-02\n",
      "n_iter: 220, duality gap: 3.3995e-04, primal residual: 1.2368e-02, dual residual: 2.358635e-02\n",
      "n_iter: 230, duality gap: 2.7819e-04, primal residual: 1.2313e-02, dual residual: 2.246306e-02\n",
      "n_iter: 240, duality gap: 3.2942e-04, primal residual: 1.2033e-02, dual residual: 2.245708e-02\n",
      "n_iter: 250, duality gap: 2.9453e-04, primal residual: 1.1997e-02, dual residual: 2.160933e-02\n",
      "n_iter: 260, duality gap: 3.5350e-04, primal residual: 1.1922e-02, dual residual: 2.157025e-02\n",
      "n_iter: 270, duality gap: 3.2358e-04, primal residual: 1.2135e-02, dual residual: 2.127380e-02\n",
      "n_iter: 280, duality gap: 3.5546e-04, primal residual: 1.2014e-02, dual residual: 2.082401e-02\n",
      "n_iter: 290, duality gap: 3.2130e-04, primal residual: 1.2319e-02, dual residual: 2.328548e-02\n",
      "n_iter: 300, duality gap: 2.5617e-04, primal residual: 1.2100e-02, dual residual: 2.101982e-02\n",
      "n_iter: 310, duality gap: 3.5433e-04, primal residual: 1.2231e-02, dual residual: 2.126184e-02\n",
      "n_iter: 320, duality gap: 3.0479e-04, primal residual: 1.2521e-02, dual residual: 2.142041e-02\n",
      "n_iter: 330, duality gap: 2.9642e-04, primal residual: 1.2092e-02, dual residual: 2.227005e-02\n",
      "n_iter: 340, duality gap: 3.3263e-04, primal residual: 1.2132e-02, dual residual: 2.116610e-02\n",
      "n_iter: 350, duality gap: 2.7809e-04, primal residual: 1.2663e-02, dual residual: 2.381191e-02\n",
      "n_iter: 360, duality gap: 2.7672e-04, primal residual: 1.2321e-02, dual residual: 2.082299e-02\n",
      "n_iter: 370, duality gap: 3.4162e-04, primal residual: 1.2431e-02, dual residual: 2.048250e-02\n",
      "n_iter: 380, duality gap: 2.8354e-04, primal residual: 1.2707e-02, dual residual: 2.136890e-02\n",
      "n_iter: 390, duality gap: 3.2873e-04, primal residual: 1.2187e-02, dual residual: 2.124765e-02\n",
      "n_iter: 400, duality gap: 2.8289e-04, primal residual: 1.2207e-02, dual residual: 2.148068e-02\n",
      "n_iter: 410, duality gap: 3.2224e-04, primal residual: 1.2358e-02, dual residual: 2.270023e-02\n",
      "n_iter: 420, duality gap: 3.2659e-04, primal residual: 1.2503e-02, dual residual: 2.080432e-02\n",
      "n_iter: 430, duality gap: 2.9280e-04, primal residual: 1.2089e-02, dual residual: 2.125431e-02\n",
      "n_iter: 440, duality gap: 3.2030e-04, primal residual: 1.2209e-02, dual residual: 2.082907e-02\n",
      "n_iter: 450, duality gap: 3.7597e-04, primal residual: 1.2470e-02, dual residual: 2.139768e-02\n",
      "n_iter: 460, duality gap: 2.8965e-04, primal residual: 1.2535e-02, dual residual: 2.156522e-02\n",
      "n_iter: 470, duality gap: 2.8078e-04, primal residual: 1.2324e-02, dual residual: 2.114048e-02\n",
      "n_iter: 480, duality gap: 3.1275e-04, primal residual: 1.2640e-02, dual residual: 2.143794e-02\n",
      "n_iter: 490, duality gap: 2.9261e-04, primal residual: 1.2223e-02, dual residual: 2.087209e-02\n",
      "n_iter: 500, duality gap: 3.1041e-04, primal residual: 1.2554e-02, dual residual: 2.124108e-02\n",
      "Batch loss: loss1: nan, loss2: 249893.95312, loss3: 0.00000\n",
      "Finished running batch 3.\n",
      "start running batch 4\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 10, duality gap: 6.7697e-03, primal residual: 9.0213e-02, dual residual: 1.954085e+00\n",
      "n_iter: 20, duality gap: 8.3964e-04, primal residual: 3.5731e-02, dual residual: 1.023962e+00\n",
      "n_iter: 30, duality gap: 4.7272e-04, primal residual: 2.3422e-02, dual residual: 6.588389e-01\n",
      "n_iter: 40, duality gap: 2.9439e-04, primal residual: 1.4849e-02, dual residual: 4.633931e-01\n",
      "n_iter: 50, duality gap: 2.0557e-04, primal residual: 1.3220e-02, dual residual: 3.429181e-01\n",
      "n_iter: 60, duality gap: 2.2902e-04, primal residual: 1.2260e-02, dual residual: 2.611637e-01\n",
      "n_iter: 70, duality gap: 2.3297e-04, primal residual: 1.2561e-02, dual residual: 2.036266e-01\n",
      "n_iter: 80, duality gap: 1.8477e-04, primal residual: 1.2796e-02, dual residual: 1.609928e-01\n",
      "n_iter: 90, duality gap: 2.7658e-04, primal residual: 1.2520e-02, dual residual: 1.290225e-01\n",
      "n_iter: 100, duality gap: 2.8675e-04, primal residual: 1.2459e-02, dual residual: 1.045612e-01\n",
      "n_iter: 110, duality gap: 2.2710e-04, primal residual: 1.3016e-02, dual residual: 8.523266e-02\n",
      "n_iter: 120, duality gap: 2.7299e-04, primal residual: 1.2507e-02, dual residual: 7.012932e-02\n",
      "n_iter: 130, duality gap: 3.6063e-04, primal residual: 1.2474e-02, dual residual: 5.846637e-02\n",
      "n_iter: 140, duality gap: 3.1322e-04, primal residual: 1.2454e-02, dual residual: 4.930986e-02\n",
      "n_iter: 150, duality gap: 3.7457e-04, primal residual: 1.2585e-02, dual residual: 4.333853e-02\n",
      "n_iter: 160, duality gap: 2.7109e-04, primal residual: 1.2456e-02, dual residual: 3.735068e-02\n",
      "n_iter: 170, duality gap: 2.8555e-04, primal residual: 1.2483e-02, dual residual: 3.281517e-02\n",
      "n_iter: 180, duality gap: 3.0586e-04, primal residual: 1.2028e-02, dual residual: 2.996177e-02\n",
      "n_iter: 190, duality gap: 3.0306e-04, primal residual: 1.2302e-02, dual residual: 2.721671e-02\n",
      "n_iter: 200, duality gap: 3.0823e-04, primal residual: 1.1947e-02, dual residual: 2.543854e-02\n",
      "n_iter: 210, duality gap: 2.9761e-04, primal residual: 1.2564e-02, dual residual: 2.402249e-02\n",
      "n_iter: 220, duality gap: 2.8430e-04, primal residual: 1.2172e-02, dual residual: 2.409561e-02\n",
      "n_iter: 230, duality gap: 2.7470e-04, primal residual: 1.1814e-02, dual residual: 2.269225e-02\n",
      "n_iter: 240, duality gap: 2.6224e-04, primal residual: 1.1977e-02, dual residual: 2.202928e-02\n",
      "n_iter: 250, duality gap: 3.0629e-04, primal residual: 1.2124e-02, dual residual: 2.162270e-02\n",
      "n_iter: 260, duality gap: 2.3086e-04, primal residual: 1.2338e-02, dual residual: 2.153204e-02\n",
      "n_iter: 270, duality gap: 2.5045e-04, primal residual: 1.2152e-02, dual residual: 2.095281e-02\n",
      "n_iter: 280, duality gap: 3.4291e-04, primal residual: 1.2074e-02, dual residual: 2.318196e-02\n",
      "n_iter: 290, duality gap: 3.1239e-04, primal residual: 1.2491e-02, dual residual: 2.210092e-02\n",
      "n_iter: 300, duality gap: 3.4157e-04, primal residual: 1.2151e-02, dual residual: 2.041046e-02\n",
      "n_iter: 310, duality gap: 2.6092e-04, primal residual: 1.2731e-02, dual residual: 2.237530e-02\n",
      "n_iter: 320, duality gap: 3.1580e-04, primal residual: 1.2843e-02, dual residual: 2.122214e-02\n",
      "n_iter: 330, duality gap: 2.6947e-04, primal residual: 1.2378e-02, dual residual: 2.149170e-02\n",
      "n_iter: 340, duality gap: 2.9298e-04, primal residual: 1.2461e-02, dual residual: 2.137753e-02\n",
      "n_iter: 350, duality gap: 3.1314e-04, primal residual: 1.2205e-02, dual residual: 2.173635e-02\n",
      "n_iter: 360, duality gap: 2.4662e-04, primal residual: 1.2493e-02, dual residual: 2.193094e-02\n",
      "n_iter: 370, duality gap: 2.6289e-04, primal residual: 1.2243e-02, dual residual: 2.154244e-02\n",
      "n_iter: 380, duality gap: 3.1896e-04, primal residual: 1.2400e-02, dual residual: 2.072127e-02\n",
      "n_iter: 390, duality gap: 2.5287e-04, primal residual: 1.2325e-02, dual residual: 2.117516e-02\n",
      "n_iter: 400, duality gap: 3.0065e-04, primal residual: 1.2491e-02, dual residual: 2.102802e-02\n",
      "n_iter: 410, duality gap: 3.1419e-04, primal residual: 1.2299e-02, dual residual: 2.097664e-02\n",
      "n_iter: 420, duality gap: 3.9775e-04, primal residual: 1.2238e-02, dual residual: 2.084550e-02\n",
      "n_iter: 430, duality gap: 4.5230e-04, primal residual: 1.2230e-02, dual residual: 2.088663e-02\n",
      "n_iter: 440, duality gap: 2.6405e-04, primal residual: 1.3157e-02, dual residual: 2.055552e-02\n",
      "n_iter: 450, duality gap: 2.7343e-04, primal residual: 1.2608e-02, dual residual: 2.398889e-02\n",
      "n_iter: 460, duality gap: 3.0194e-04, primal residual: 1.3153e-02, dual residual: 2.079052e-02\n",
      "n_iter: 470, duality gap: 3.2057e-04, primal residual: 1.2185e-02, dual residual: 2.073560e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter: 480, duality gap: 3.8589e-04, primal residual: 1.1894e-02, dual residual: 2.105044e-02\n",
      "n_iter: 490, duality gap: 3.0601e-04, primal residual: 1.2807e-02, dual residual: 2.138796e-02\n",
      "n_iter: 500, duality gap: 3.4007e-04, primal residual: 1.2522e-02, dual residual: 2.088007e-02\n",
      "Batch loss: loss1: -1263.07397, loss2: 243252.09375, loss3: 0.00000\n",
      "Finished running batch 4.\n",
      "start running batch 5\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 10, duality gap: 5.9548e-03, primal residual: 9.0273e-02, dual residual: 1.929350e+00\n",
      "n_iter: 20, duality gap: 6.6550e-04, primal residual: 3.3372e-02, dual residual: 1.005389e+00\n",
      "n_iter: 30, duality gap: 4.4524e-04, primal residual: 1.5825e-02, dual residual: 6.484542e-01\n",
      "n_iter: 40, duality gap: 2.9073e-04, primal residual: 1.0807e-02, dual residual: 4.563893e-01\n",
      "n_iter: 50, duality gap: 2.5474e-04, primal residual: 7.3044e-03, dual residual: 3.362098e-01\n",
      "n_iter: 60, duality gap: 1.5513e-04, primal residual: 6.1714e-03, dual residual: 2.551921e-01\n",
      "n_iter: 70, duality gap: 1.4586e-04, primal residual: 6.0218e-03, dual residual: 1.977085e-01\n",
      "n_iter: 80, duality gap: 1.1936e-04, primal residual: 6.2635e-03, dual residual: 1.554230e-01\n",
      "n_iter: 90, duality gap: 1.0101e-04, primal residual: 5.9569e-03, dual residual: 1.235247e-01\n",
      "n_iter: 100, duality gap: 1.0008e-04, primal residual: 6.4026e-03, dual residual: 9.902889e-02\n",
      "n_iter: 110, duality gap: 9.5779e-05, primal residual: 6.1896e-03, dual residual: 8.006179e-02\n",
      "n_iter: 120, duality gap: 9.6648e-05, primal residual: 6.0627e-03, dual residual: 6.526904e-02\n",
      "n_iter: 130, duality gap: 1.0188e-04, primal residual: 5.8835e-03, dual residual: 5.345444e-02\n",
      "n_iter: 140, duality gap: 9.7484e-05, primal residual: 6.2055e-03, dual residual: 4.417936e-02\n",
      "n_iter: 150, duality gap: 1.6278e-04, primal residual: 6.1212e-03, dual residual: 3.669653e-02\n",
      "n_iter: 160, duality gap: 1.1784e-04, primal residual: 5.9438e-03, dual residual: 3.077289e-02\n",
      "n_iter: 170, duality gap: 1.1293e-04, primal residual: 6.2142e-03, dual residual: 2.615057e-02\n",
      "n_iter: 180, duality gap: 1.1014e-04, primal residual: 6.0586e-03, dual residual: 2.263349e-02\n",
      "n_iter: 190, duality gap: 1.0695e-04, primal residual: 6.0946e-03, dual residual: 1.948911e-02\n",
      "n_iter: 200, duality gap: 7.4119e-05, primal residual: 6.1594e-03, dual residual: 1.738841e-02\n",
      "n_iter: 210, duality gap: 1.0485e-04, primal residual: 6.2679e-03, dual residual: 1.526354e-02\n",
      "n_iter: 220, duality gap: 1.1911e-04, primal residual: 6.0598e-03, dual residual: 1.395657e-02\n",
      "n_iter: 230, duality gap: 1.3015e-04, primal residual: 6.1442e-03, dual residual: 1.275745e-02\n",
      "n_iter: 240, duality gap: 1.0769e-04, primal residual: 6.2325e-03, dual residual: 1.165314e-02\n",
      "n_iter: 250, duality gap: 9.8603e-05, primal residual: 5.9263e-03, dual residual: 1.135829e-02\n",
      "n_iter: 260, duality gap: 1.2512e-04, primal residual: 6.0117e-03, dual residual: 1.072227e-02\n",
      "n_iter: 270, duality gap: 7.6030e-05, primal residual: 5.9545e-03, dual residual: 1.060405e-02\n",
      "n_iter: 280, duality gap: 9.7633e-05, primal residual: 6.3659e-03, dual residual: 1.010496e-02\n",
      "n_iter: 290, duality gap: 1.2213e-04, primal residual: 5.9674e-03, dual residual: 9.820837e-03\n",
      "n_iter: 300, duality gap: 9.7579e-05, primal residual: 6.2085e-03, dual residual: 9.516102e-03\n",
      "n_iter: 310, duality gap: 7.7178e-05, primal residual: 5.8574e-03, dual residual: 1.011483e-02\n",
      "n_iter: 320, duality gap: 8.0629e-05, primal residual: 5.9715e-03, dual residual: 9.284205e-03\n",
      "n_iter: 330, duality gap: 1.4035e-04, primal residual: 6.2942e-03, dual residual: 9.623836e-03\n",
      "n_iter: 340, duality gap: 1.1868e-04, primal residual: 5.9741e-03, dual residual: 9.755964e-03\n",
      "n_iter: 350, duality gap: 1.2506e-04, primal residual: 5.8541e-03, dual residual: 1.018285e-02\n",
      "n_iter: 360, duality gap: 1.1051e-04, primal residual: 6.2750e-03, dual residual: 9.818847e-03\n",
      "n_iter: 370, duality gap: 1.1391e-04, primal residual: 5.8716e-03, dual residual: 9.599267e-03\n",
      "n_iter: 380, duality gap: 8.5075e-05, primal residual: 5.9051e-03, dual residual: 9.512767e-03\n",
      "n_iter: 390, duality gap: 1.2544e-04, primal residual: 5.7186e-03, dual residual: 9.386048e-03\n",
      "n_iter: 400, duality gap: 1.3107e-04, primal residual: 5.8905e-03, dual residual: 9.884432e-03\n",
      "n_iter: 410, duality gap: 8.0035e-05, primal residual: 5.8350e-03, dual residual: 9.514512e-03\n",
      "n_iter: 420, duality gap: 1.1660e-04, primal residual: 5.9998e-03, dual residual: 9.634495e-03\n",
      "n_iter: 430, duality gap: 1.2321e-04, primal residual: 6.0606e-03, dual residual: 9.655842e-03\n",
      "n_iter: 440, duality gap: 1.3260e-04, primal residual: 5.9196e-03, dual residual: 9.680795e-03\n",
      "n_iter: 450, duality gap: 1.1948e-04, primal residual: 5.7939e-03, dual residual: 9.689026e-03\n",
      "n_iter: 460, duality gap: 1.1351e-04, primal residual: 5.9137e-03, dual residual: 9.595234e-03\n",
      "n_iter: 470, duality gap: 1.7996e-04, primal residual: 5.8899e-03, dual residual: 1.062406e-02\n",
      "n_iter: 480, duality gap: 1.2227e-04, primal residual: 6.1239e-03, dual residual: 1.016379e-02\n",
      "n_iter: 490, duality gap: 9.7790e-05, primal residual: 5.7593e-03, dual residual: 9.482438e-03\n",
      "n_iter: 500, duality gap: 1.0241e-04, primal residual: 5.8669e-03, dual residual: 9.588990e-03\n",
      "Batch loss: loss1: -1198.62317, loss2: 243716.31250, loss3: 0.00000\n",
      "Finished running batch 5.\n",
      "start running batch 6\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 10, duality gap: 6.1671e-03, primal residual: 8.9151e-02, dual residual: 1.935686e+00\n",
      "n_iter: 20, duality gap: 5.9029e-04, primal residual: 3.0605e-02, dual residual: 1.019642e+00\n",
      "n_iter: 30, duality gap: 4.9135e-04, primal residual: 1.4227e-02, dual residual: 6.631221e-01\n",
      "n_iter: 40, duality gap: 3.1534e-04, primal residual: 8.2278e-03, dual residual: 4.689593e-01\n",
      "n_iter: 50, duality gap: 2.7606e-04, primal residual: 6.1319e-03, dual residual: 3.478456e-01\n",
      "n_iter: 60, duality gap: 1.6533e-04, primal residual: 4.7108e-03, dual residual: 2.654789e-01\n",
      "n_iter: 70, duality gap: 1.8264e-04, primal residual: 3.6236e-03, dual residual: 2.066110e-01\n",
      "n_iter: 80, duality gap: 1.2338e-04, primal residual: 2.6811e-03, dual residual: 1.633292e-01\n",
      "n_iter: 90, duality gap: 8.8405e-05, primal residual: 2.0726e-03, dual residual: 1.305289e-01\n",
      "n_iter: 100, duality gap: 6.9429e-05, primal residual: 1.6951e-03, dual residual: 1.053028e-01\n",
      "n_iter: 110, duality gap: 5.7599e-05, primal residual: 1.5740e-03, dual residual: 8.557879e-02\n",
      "n_iter: 120, duality gap: 4.0380e-05, primal residual: 1.5620e-03, dual residual: 6.992696e-02\n",
      "n_iter: 130, duality gap: 4.0150e-05, primal residual: 1.4415e-03, dual residual: 5.739244e-02\n",
      "n_iter: 140, duality gap: 3.2479e-05, primal residual: 1.4659e-03, dual residual: 4.730808e-02\n",
      "n_iter: 150, duality gap: 2.7417e-05, primal residual: 1.4930e-03, dual residual: 3.914054e-02\n",
      "n_iter: 160, duality gap: 2.9944e-05, primal residual: 1.5182e-03, dual residual: 3.249347e-02\n",
      "n_iter: 170, duality gap: 2.2200e-05, primal residual: 1.4543e-03, dual residual: 2.702397e-02\n",
      "n_iter: 180, duality gap: 2.4159e-05, primal residual: 1.4807e-03, dual residual: 2.252576e-02\n",
      "n_iter: 190, duality gap: 2.3385e-05, primal residual: 1.4385e-03, dual residual: 1.880353e-02\n",
      "n_iter: 200, duality gap: 2.9674e-05, primal residual: 1.4136e-03, dual residual: 1.573670e-02\n",
      "n_iter: 210, duality gap: 2.0855e-05, primal residual: 1.4825e-03, dual residual: 1.317394e-02\n",
      "n_iter: 220, duality gap: 1.7946e-05, primal residual: 1.4365e-03, dual residual: 1.104397e-02\n",
      "n_iter: 230, duality gap: 2.5838e-05, primal residual: 1.4525e-03, dual residual: 9.282451e-03\n",
      "n_iter: 240, duality gap: 1.7635e-05, primal residual: 1.4506e-03, dual residual: 7.803529e-03\n",
      "n_iter: 250, duality gap: 3.1582e-05, primal residual: 1.3727e-03, dual residual: 6.566443e-03\n",
      "n_iter: 260, duality gap: 2.3523e-05, primal residual: 1.4525e-03, dual residual: 5.538381e-03\n",
      "n_iter: 270, duality gap: 1.6930e-05, primal residual: 1.4075e-03, dual residual: 4.666558e-03\n",
      "n_iter: 280, duality gap: 3.1216e-05, primal residual: 1.4751e-03, dual residual: 3.970746e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter: 290, duality gap: 2.1868e-05, primal residual: 1.4488e-03, dual residual: 3.725830e-03\n",
      "n_iter: 300, duality gap: 3.2723e-05, primal residual: 1.5524e-03, dual residual: 3.328002e-03\n",
      "n_iter: 310, duality gap: 2.1943e-05, primal residual: 1.5263e-03, dual residual: 3.018615e-03\n",
      "n_iter: 320, duality gap: 2.9370e-05, primal residual: 1.3972e-03, dual residual: 2.768943e-03\n",
      "n_iter: 330, duality gap: 2.0153e-05, primal residual: 1.4698e-03, dual residual: 2.666474e-03\n",
      "n_iter: 340, duality gap: 1.8298e-05, primal residual: 1.4690e-03, dual residual: 2.540574e-03\n",
      "n_iter: 350, duality gap: 2.2687e-05, primal residual: 1.3883e-03, dual residual: 2.594542e-03\n",
      "n_iter: 360, duality gap: 2.2852e-05, primal residual: 1.4309e-03, dual residual: 2.447375e-03\n",
      "n_iter: 370, duality gap: 2.2776e-05, primal residual: 1.4551e-03, dual residual: 2.452725e-03\n",
      "n_iter: 380, duality gap: 2.3491e-05, primal residual: 1.4016e-03, dual residual: 2.443852e-03\n",
      "n_iter: 390, duality gap: 2.3201e-05, primal residual: 1.4265e-03, dual residual: 2.362852e-03\n",
      "n_iter: 400, duality gap: 1.3052e-05, primal residual: 1.4144e-03, dual residual: 2.327176e-03\n",
      "n_iter: 410, duality gap: 1.4934e-05, primal residual: 1.4123e-03, dual residual: 2.285089e-03\n",
      "n_iter: 420, duality gap: 2.2854e-05, primal residual: 1.3707e-03, dual residual: 2.258335e-03\n",
      "n_iter: 430, duality gap: 1.7021e-05, primal residual: 1.4144e-03, dual residual: 2.306145e-03\n",
      "n_iter: 440, duality gap: 2.5884e-05, primal residual: 1.3784e-03, dual residual: 2.250453e-03\n",
      "n_iter: 450, duality gap: 1.8416e-05, primal residual: 1.3582e-03, dual residual: 2.285637e-03\n",
      "n_iter: 460, duality gap: 2.0806e-05, primal residual: 1.3613e-03, dual residual: 2.303180e-03\n",
      "n_iter: 470, duality gap: 2.4040e-05, primal residual: 1.3766e-03, dual residual: 2.185489e-03\n",
      "n_iter: 480, duality gap: 2.6105e-05, primal residual: 1.4502e-03, dual residual: 2.322440e-03\n",
      "n_iter: 490, duality gap: 1.9514e-05, primal residual: 1.4215e-03, dual residual: 2.257973e-03\n",
      "n_iter: 500, duality gap: 1.5224e-05, primal residual: 1.4200e-03, dual residual: 2.275229e-03\n",
      "Batch loss: loss1: -1259.05164, loss2: 247601.06250, loss3: 0.00000\n",
      "Finished running batch 6.\n",
      "start running batch 7\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 10, duality gap: 6.7813e-03, primal residual: 1.0156e-01, dual residual: 2.016746e+00\n",
      "n_iter: 20, duality gap: 5.0008e-04, primal residual: 2.6998e-02, dual residual: 1.076226e+00\n",
      "n_iter: 30, duality gap: 3.8420e-04, primal residual: 1.2462e-02, dual residual: 7.084169e-01\n",
      "n_iter: 40, duality gap: 3.0247e-04, primal residual: 8.9414e-03, dual residual: 5.072368e-01\n",
      "n_iter: 50, duality gap: 2.2256e-04, primal residual: 5.9831e-03, dual residual: 3.808430e-01\n",
      "n_iter: 60, duality gap: 1.5684e-04, primal residual: 4.1461e-03, dual residual: 2.944850e-01\n",
      "n_iter: 70, duality gap: 1.4823e-04, primal residual: 4.0816e-03, dual residual: 2.323295e-01\n",
      "n_iter: 80, duality gap: 1.2412e-04, primal residual: 3.2738e-03, dual residual: 1.859961e-01\n",
      "n_iter: 90, duality gap: 8.1344e-05, primal residual: 2.3138e-03, dual residual: 1.504628e-01\n",
      "n_iter: 100, duality gap: 6.6651e-05, primal residual: 1.8567e-03, dual residual: 1.226999e-01\n",
      "n_iter: 110, duality gap: 5.1682e-05, primal residual: 1.4605e-03, dual residual: 1.009197e-01\n",
      "n_iter: 120, duality gap: 4.7008e-05, primal residual: 1.1461e-03, dual residual: 8.348019e-02\n",
      "n_iter: 130, duality gap: 3.8727e-05, primal residual: 1.0964e-03, dual residual: 6.943461e-02\n",
      "n_iter: 140, duality gap: 3.5164e-05, primal residual: 9.5172e-04, dual residual: 5.797094e-02\n",
      "n_iter: 150, duality gap: 2.3880e-05, primal residual: 7.9568e-04, dual residual: 4.857988e-02\n",
      "n_iter: 160, duality gap: 2.2868e-05, primal residual: 7.6328e-04, dual residual: 4.082741e-02\n",
      "n_iter: 170, duality gap: 1.9487e-05, primal residual: 7.1683e-04, dual residual: 3.441253e-02\n",
      "n_iter: 180, duality gap: 1.6410e-05, primal residual: 7.0931e-04, dual residual: 2.905498e-02\n",
      "n_iter: 190, duality gap: 1.7602e-05, primal residual: 7.1891e-04, dual residual: 2.458455e-02\n",
      "n_iter: 200, duality gap: 1.2577e-05, primal residual: 6.6023e-04, dual residual: 2.084754e-02\n",
      "n_iter: 210, duality gap: 1.4353e-05, primal residual: 6.7419e-04, dual residual: 1.768294e-02\n",
      "n_iter: 220, duality gap: 1.4450e-05, primal residual: 6.9253e-04, dual residual: 1.504554e-02\n",
      "n_iter: 230, duality gap: 1.5439e-05, primal residual: 7.0264e-04, dual residual: 1.282338e-02\n",
      "n_iter: 240, duality gap: 1.1853e-05, primal residual: 6.6762e-04, dual residual: 1.091164e-02\n",
      "n_iter: 250, duality gap: 9.2126e-06, primal residual: 6.8423e-04, dual residual: 9.329646e-03\n",
      "n_iter: 260, duality gap: 8.0573e-06, primal residual: 6.7500e-04, dual residual: 7.972576e-03\n",
      "n_iter: 270, duality gap: 9.6614e-06, primal residual: 7.1178e-04, dual residual: 6.840759e-03\n",
      "n_iter: 280, duality gap: 1.1591e-05, primal residual: 6.6516e-04, dual residual: 5.848173e-03\n",
      "n_iter: 290, duality gap: 1.8479e-05, primal residual: 6.3999e-04, dual residual: 5.025663e-03\n",
      "n_iter: 300, duality gap: 1.2123e-05, primal residual: 6.6790e-04, dual residual: 4.322237e-03\n",
      "n_iter: 310, duality gap: 1.0196e-05, primal residual: 6.6659e-04, dual residual: 3.747379e-03\n",
      "n_iter: 320, duality gap: 1.1828e-05, primal residual: 6.5380e-04, dual residual: 3.215932e-03\n",
      "n_iter: 330, duality gap: 9.5431e-06, primal residual: 6.4715e-04, dual residual: 2.798283e-03\n",
      "n_iter: 340, duality gap: 9.6396e-06, primal residual: 6.3107e-04, dual residual: 2.464332e-03\n",
      "n_iter: 350, duality gap: 7.8098e-06, primal residual: 6.3494e-04, dual residual: 2.157070e-03\n",
      "n_iter: 360, duality gap: 9.2671e-06, primal residual: 6.3786e-04, dual residual: 1.897560e-03\n",
      "n_iter: 370, duality gap: 9.1129e-06, primal residual: 6.4252e-04, dual residual: 1.690773e-03\n",
      "n_iter: 380, duality gap: 8.4381e-06, primal residual: 6.1846e-04, dual residual: 1.508795e-03\n",
      "n_iter: 390, duality gap: 8.3313e-06, primal residual: 6.9467e-04, dual residual: 1.382255e-03\n",
      "n_iter: 400, duality gap: 9.7201e-06, primal residual: 6.2529e-04, dual residual: 1.267161e-03\n",
      "n_iter: 410, duality gap: 1.0433e-05, primal residual: 6.3026e-04, dual residual: 1.176610e-03\n",
      "n_iter: 420, duality gap: 1.0719e-05, primal residual: 6.5481e-04, dual residual: 1.117902e-03\n",
      "n_iter: 430, duality gap: 1.3141e-05, primal residual: 6.6894e-04, dual residual: 1.058345e-03\n",
      "n_iter: 440, duality gap: 9.4359e-06, primal residual: 6.2452e-04, dual residual: 9.706559e-04\n",
      "n_iter: 450, duality gap: 1.3195e-05, primal residual: 6.6215e-04, dual residual: 9.670696e-04\n",
      "n_iter: 460, duality gap: 8.1104e-06, primal residual: 6.3977e-04, dual residual: 1.021427e-03\n",
      "n_iter: 470, duality gap: 7.0388e-06, primal residual: 6.5740e-04, dual residual: 9.264283e-04\n",
      "n_iter: 480, duality gap: 7.6757e-06, primal residual: 6.4456e-04, dual residual: 9.088897e-04\n",
      "n_iter: 490, duality gap: 8.6120e-06, primal residual: 6.6283e-04, dual residual: 9.357565e-04\n",
      "n_iter: 500, duality gap: 1.0127e-05, primal residual: 6.1294e-04, dual residual: 8.825398e-04\n",
      "Batch loss: loss1: -1628.43726, loss2: 253669.12500, loss3: 0.00000\n",
      "Finished running batch 7.\n",
      "start running batch 8\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 10, duality gap: 6.8072e-03, primal residual: 1.0034e-01, dual residual: 2.191566e+00\n",
      "n_iter: 20, duality gap: 5.2111e-04, primal residual: 3.6860e-02, dual residual: 1.220178e+00\n",
      "n_iter: 30, duality gap: 3.6516e-04, primal residual: 1.6156e-02, dual residual: 8.293695e-01\n",
      "n_iter: 40, duality gap: 2.9836e-04, primal residual: 9.9096e-03, dual residual: 6.126605e-01\n",
      "n_iter: 50, duality gap: 2.0864e-04, primal residual: 7.7282e-03, dual residual: 4.735346e-01\n",
      "n_iter: 60, duality gap: 2.0727e-04, primal residual: 5.6802e-03, dual residual: 3.768944e-01\n",
      "n_iter: 70, duality gap: 1.9682e-04, primal residual: 5.0988e-03, dual residual: 3.059010e-01\n",
      "n_iter: 80, duality gap: 1.2898e-04, primal residual: 3.8663e-03, dual residual: 2.520427e-01\n",
      "n_iter: 90, duality gap: 1.1788e-04, primal residual: 3.3706e-03, dual residual: 2.099871e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter: 100, duality gap: 1.0191e-04, primal residual: 3.1520e-03, dual residual: 1.764312e-01\n",
      "n_iter: 110, duality gap: 8.4485e-05, primal residual: 2.5654e-03, dual residual: 1.494065e-01\n",
      "n_iter: 120, duality gap: 7.6887e-05, primal residual: 2.2893e-03, dual residual: 1.270642e-01\n",
      "n_iter: 130, duality gap: 6.7886e-05, primal residual: 2.2761e-03, dual residual: 1.086237e-01\n",
      "n_iter: 140, duality gap: 5.1892e-05, primal residual: 1.9944e-03, dual residual: 9.321156e-02\n",
      "n_iter: 150, duality gap: 5.7527e-05, primal residual: 1.9712e-03, dual residual: 8.032921e-02\n",
      "n_iter: 160, duality gap: 4.4124e-05, primal residual: 1.9547e-03, dual residual: 6.939366e-02\n",
      "n_iter: 170, duality gap: 4.1880e-05, primal residual: 1.9193e-03, dual residual: 6.016036e-02\n",
      "n_iter: 180, duality gap: 4.6416e-05, primal residual: 1.7687e-03, dual residual: 5.225033e-02\n",
      "n_iter: 190, duality gap: 4.1196e-05, primal residual: 1.7706e-03, dual residual: 4.538929e-02\n",
      "n_iter: 200, duality gap: 4.1410e-05, primal residual: 1.7915e-03, dual residual: 3.958344e-02\n",
      "n_iter: 210, duality gap: 3.2445e-05, primal residual: 1.7887e-03, dual residual: 3.456260e-02\n",
      "n_iter: 220, duality gap: 2.7461e-05, primal residual: 1.7771e-03, dual residual: 3.023617e-02\n",
      "n_iter: 230, duality gap: 3.3469e-05, primal residual: 1.7109e-03, dual residual: 2.645876e-02\n",
      "n_iter: 240, duality gap: 2.8396e-05, primal residual: 1.7712e-03, dual residual: 2.321651e-02\n",
      "n_iter: 250, duality gap: 2.8268e-05, primal residual: 1.7652e-03, dual residual: 2.031748e-02\n",
      "n_iter: 260, duality gap: 3.6218e-05, primal residual: 1.6926e-03, dual residual: 1.791390e-02\n",
      "n_iter: 270, duality gap: 3.1235e-05, primal residual: 1.8265e-03, dual residual: 1.575205e-02\n",
      "n_iter: 280, duality gap: 3.5153e-05, primal residual: 1.8141e-03, dual residual: 1.389715e-02\n",
      "n_iter: 290, duality gap: 3.3669e-05, primal residual: 1.7804e-03, dual residual: 1.224298e-02\n",
      "n_iter: 300, duality gap: 2.2081e-05, primal residual: 1.7783e-03, dual residual: 1.084589e-02\n",
      "n_iter: 310, duality gap: 3.1388e-05, primal residual: 1.7379e-03, dual residual: 9.604924e-03\n",
      "n_iter: 320, duality gap: 2.6609e-05, primal residual: 1.8060e-03, dual residual: 8.482667e-03\n",
      "n_iter: 330, duality gap: 3.7217e-05, primal residual: 1.8237e-03, dual residual: 7.522232e-03\n",
      "n_iter: 340, duality gap: 2.0976e-05, primal residual: 1.7710e-03, dual residual: 6.756745e-03\n",
      "n_iter: 350, duality gap: 2.4393e-05, primal residual: 1.7257e-03, dual residual: 6.001667e-03\n",
      "n_iter: 360, duality gap: 3.4096e-05, primal residual: 1.8130e-03, dual residual: 5.351355e-03\n",
      "n_iter: 370, duality gap: 3.6680e-05, primal residual: 1.7397e-03, dual residual: 4.782178e-03\n",
      "n_iter: 380, duality gap: 2.6350e-05, primal residual: 1.8040e-03, dual residual: 4.378942e-03\n",
      "n_iter: 390, duality gap: 2.6824e-05, primal residual: 1.6568e-03, dual residual: 3.948810e-03\n",
      "n_iter: 400, duality gap: 2.1427e-05, primal residual: 1.7365e-03, dual residual: 3.658406e-03\n",
      "n_iter: 410, duality gap: 2.4782e-05, primal residual: 1.6755e-03, dual residual: 3.317799e-03\n",
      "n_iter: 420, duality gap: 2.4739e-05, primal residual: 1.7110e-03, dual residual: 3.161970e-03\n",
      "n_iter: 430, duality gap: 3.2659e-05, primal residual: 1.7067e-03, dual residual: 2.888741e-03\n",
      "n_iter: 440, duality gap: 2.7493e-05, primal residual: 1.6873e-03, dual residual: 2.691622e-03\n",
      "n_iter: 450, duality gap: 3.2348e-05, primal residual: 1.7202e-03, dual residual: 2.541360e-03\n",
      "n_iter: 460, duality gap: 3.0748e-05, primal residual: 1.7927e-03, dual residual: 2.469285e-03\n",
      "n_iter: 470, duality gap: 2.7947e-05, primal residual: 1.7264e-03, dual residual: 2.455745e-03\n",
      "n_iter: 480, duality gap: 2.7536e-05, primal residual: 1.7198e-03, dual residual: 2.297382e-03\n",
      "n_iter: 490, duality gap: 3.0691e-05, primal residual: 1.7063e-03, dual residual: 2.176931e-03\n",
      "n_iter: 500, duality gap: 2.4981e-05, primal residual: 1.7587e-03, dual residual: 2.193737e-03\n",
      "Batch loss: loss1: -2999.15576, loss2: 273534.03125, loss3: 0.00000\n",
      "Finished running batch 8.\n",
      "start running batch 9\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 10, duality gap: 8.3319e-03, primal residual: 1.0343e-01, dual residual: 2.396164e+00\n",
      "n_iter: 20, duality gap: 9.0489e-04, primal residual: 3.8014e-02, dual residual: 1.382071e+00\n",
      "n_iter: 30, duality gap: 3.6068e-04, primal residual: 2.0281e-02, dual residual: 9.681291e-01\n",
      "n_iter: 40, duality gap: 3.1811e-04, primal residual: 1.3664e-02, dual residual: 7.347541e-01\n",
      "n_iter: 50, duality gap: 2.4401e-04, primal residual: 1.0156e-02, dual residual: 5.831130e-01\n",
      "n_iter: 60, duality gap: 2.0728e-04, primal residual: 8.2715e-03, dual residual: 4.760205e-01\n",
      "n_iter: 70, duality gap: 1.8872e-04, primal residual: 7.0735e-03, dual residual: 3.961776e-01\n",
      "n_iter: 80, duality gap: 1.9699e-04, primal residual: 6.3585e-03, dual residual: 3.345974e-01\n",
      "n_iter: 90, duality gap: 1.3113e-04, primal residual: 4.5864e-03, dual residual: 2.858930e-01\n",
      "n_iter: 100, duality gap: 1.5571e-04, primal residual: 4.1398e-03, dual residual: 2.465222e-01\n",
      "n_iter: 110, duality gap: 1.1786e-04, primal residual: 3.9206e-03, dual residual: 2.140609e-01\n",
      "n_iter: 120, duality gap: 9.4263e-05, primal residual: 3.2458e-03, dual residual: 1.869894e-01\n",
      "n_iter: 130, duality gap: 7.9858e-05, primal residual: 3.4834e-03, dual residual: 1.640353e-01\n",
      "n_iter: 140, duality gap: 9.1489e-05, primal residual: 2.8199e-03, dual residual: 1.445528e-01\n",
      "n_iter: 150, duality gap: 6.0982e-05, primal residual: 2.4136e-03, dual residual: 1.279399e-01\n",
      "n_iter: 160, duality gap: 7.5445e-05, primal residual: 2.3799e-03, dual residual: 1.135009e-01\n",
      "n_iter: 170, duality gap: 5.2643e-05, primal residual: 2.1828e-03, dual residual: 1.010152e-01\n",
      "n_iter: 180, duality gap: 5.5861e-05, primal residual: 2.0770e-03, dual residual: 9.008469e-02\n",
      "n_iter: 190, duality gap: 4.3338e-05, primal residual: 2.0228e-03, dual residual: 8.049829e-02\n",
      "n_iter: 200, duality gap: 4.3496e-05, primal residual: 1.9291e-03, dual residual: 7.208218e-02\n",
      "n_iter: 210, duality gap: 4.5874e-05, primal residual: 1.9169e-03, dual residual: 6.465606e-02\n",
      "n_iter: 220, duality gap: 3.7009e-05, primal residual: 1.8656e-03, dual residual: 5.807204e-02\n",
      "n_iter: 230, duality gap: 4.2411e-05, primal residual: 1.8862e-03, dual residual: 5.218226e-02\n",
      "n_iter: 240, duality gap: 3.9020e-05, primal residual: 1.9165e-03, dual residual: 4.701990e-02\n",
      "n_iter: 250, duality gap: 3.2902e-05, primal residual: 1.8641e-03, dual residual: 4.236805e-02\n",
      "n_iter: 260, duality gap: 3.8779e-05, primal residual: 1.8972e-03, dual residual: 3.823984e-02\n",
      "n_iter: 270, duality gap: 4.6311e-05, primal residual: 2.0406e-03, dual residual: 3.451606e-02\n",
      "n_iter: 280, duality gap: 4.2568e-05, primal residual: 1.8462e-03, dual residual: 3.120446e-02\n",
      "n_iter: 290, duality gap: 3.6462e-05, primal residual: 1.8519e-03, dual residual: 2.820614e-02\n",
      "n_iter: 300, duality gap: 3.0198e-05, primal residual: 1.8851e-03, dual residual: 2.550481e-02\n",
      "n_iter: 310, duality gap: 3.0636e-05, primal residual: 1.9438e-03, dual residual: 2.308726e-02\n",
      "n_iter: 320, duality gap: 4.2585e-05, primal residual: 1.9253e-03, dual residual: 2.091948e-02\n",
      "n_iter: 330, duality gap: 3.5535e-05, primal residual: 1.9054e-03, dual residual: 1.900024e-02\n",
      "n_iter: 340, duality gap: 2.9857e-05, primal residual: 1.8664e-03, dual residual: 1.725253e-02\n",
      "n_iter: 350, duality gap: 3.7797e-05, primal residual: 1.8652e-03, dual residual: 1.566695e-02\n",
      "n_iter: 360, duality gap: 4.0890e-05, primal residual: 2.0071e-03, dual residual: 1.422454e-02\n",
      "n_iter: 370, duality gap: 3.6780e-05, primal residual: 1.8688e-03, dual residual: 1.292357e-02\n",
      "n_iter: 380, duality gap: 3.0859e-05, primal residual: 1.8710e-03, dual residual: 1.176011e-02\n",
      "n_iter: 390, duality gap: 5.0893e-05, primal residual: 1.8893e-03, dual residual: 1.072015e-02\n",
      "n_iter: 400, duality gap: 3.5884e-05, primal residual: 1.8142e-03, dual residual: 9.758534e-03\n",
      "n_iter: 410, duality gap: 3.9860e-05, primal residual: 1.8907e-03, dual residual: 8.896054e-03\n",
      "n_iter: 420, duality gap: 4.3134e-05, primal residual: 1.9056e-03, dual residual: 8.097539e-03\n",
      "n_iter: 430, duality gap: 3.7472e-05, primal residual: 1.9560e-03, dual residual: 7.412694e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter: 440, duality gap: 3.4984e-05, primal residual: 1.9312e-03, dual residual: 6.763692e-03\n",
      "n_iter: 450, duality gap: 4.4461e-05, primal residual: 1.8664e-03, dual residual: 6.158296e-03\n",
      "n_iter: 460, duality gap: 4.2384e-05, primal residual: 1.8340e-03, dual residual: 5.673961e-03\n",
      "n_iter: 470, duality gap: 4.0676e-05, primal residual: 1.9550e-03, dual residual: 5.164776e-03\n",
      "n_iter: 480, duality gap: 3.9091e-05, primal residual: 1.9380e-03, dual residual: 4.788827e-03\n",
      "n_iter: 490, duality gap: 3.1102e-05, primal residual: 1.8607e-03, dual residual: 4.373140e-03\n",
      "n_iter: 500, duality gap: 3.6561e-05, primal residual: 1.8475e-03, dual residual: 4.055968e-03\n",
      "Batch loss: loss1: -5579.67871, loss2: 307505.56250, loss3: 0.00000\n",
      "Finished running batch 9.\n",
      "time calculating thetas: 1616.96 sec\n",
      "test with TF information\n",
      "final number of nearest neighbor (make connected): 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/home/ziqi/.conda/envs/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:130: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time calculating the kernel function: 4.09 sec\n",
      "start running batch 0\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 1.2599e-01, primal residual: 2.3967e-03, dual residual: 9.939191e-02\n",
      "n_iter: 200, duality gap: 1.1095e-03, primal residual: 4.1233e-04, dual residual: 2.101974e-02\n",
      "n_iter: 300, duality gap: 6.0988e-04, primal residual: 3.6358e-04, dual residual: 5.516590e-03\n",
      "n_iter: 400, duality gap: 5.4317e-04, primal residual: 3.8461e-04, dual residual: 1.777138e-03\n",
      "n_iter: 500, duality gap: 5.4943e-04, primal residual: 3.6108e-04, dual residual: 1.111435e-03\n",
      "Batch loss: loss1: 12046.99805, loss2: 101166.68750, loss3: 49.08773\n",
      "Finished running batch 0.\n",
      "start running batch 1\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 1.2827e-01, primal residual: 2.2851e-03, dual residual: 6.222135e-02\n",
      "n_iter: 200, duality gap: 7.8114e-04, primal residual: 2.6465e-04, dual residual: 9.170610e-03\n",
      "n_iter: 300, duality gap: 5.3835e-04, primal residual: 2.5406e-04, dual residual: 1.813788e-03\n",
      "n_iter: 400, duality gap: 4.1581e-04, primal residual: 2.3582e-04, dual residual: 9.110076e-04\n",
      "n_iter: 500, duality gap: 3.7209e-04, primal residual: 2.4397e-04, dual residual: 9.517887e-04\n",
      "Batch loss: loss1: 13352.71387, loss2: 88418.50000, loss3: 48.89657\n",
      "Finished running batch 1.\n",
      "start running batch 2\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 1.2974e-01, primal residual: 3.8745e-03, dual residual: 4.447075e-02\n",
      "n_iter: 200, duality gap: 2.2504e-03, primal residual: 2.9759e-03, dual residual: 1.360623e-02\n",
      "n_iter: 300, duality gap: 2.3564e-03, primal residual: 2.9346e-03, dual residual: 1.167501e-02\n",
      "n_iter: 400, duality gap: 2.1066e-03, primal residual: 2.8403e-03, dual residual: 1.138204e-02\n",
      "n_iter: 500, duality gap: 2.1368e-03, primal residual: 3.2275e-03, dual residual: 1.091789e-02\n",
      "Batch loss: loss1: 14147.38086, loss2: 82061.92969, loss3: 48.79713\n",
      "Finished running batch 2.\n",
      "start running batch 3\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 1.3367e-01, primal residual: 7.7800e-03, dual residual: 5.687710e-02\n",
      "n_iter: 200, duality gap: 6.7932e-03, primal residual: 7.3670e-03, dual residual: 3.260783e-02\n",
      "n_iter: 300, duality gap: 6.9331e-03, primal residual: 7.5990e-03, dual residual: 3.077335e-02\n",
      "n_iter: 400, duality gap: 6.0773e-03, primal residual: 7.6900e-03, dual residual: 3.045809e-02\n",
      "n_iter: 500, duality gap: 6.7403e-03, primal residual: 7.7729e-03, dual residual: 2.972227e-02\n",
      "Batch loss: loss1: 14478.62012, loss2: 78907.99219, loss3: 48.74687\n",
      "Finished running batch 3.\n",
      "start running batch 4\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 1.3378e-01, primal residual: 7.7017e-03, dual residual: 6.692286e-02\n",
      "n_iter: 200, duality gap: 9.3482e-03, primal residual: 7.6621e-03, dual residual: 3.133696e-02\n",
      "n_iter: 300, duality gap: 6.6101e-03, primal residual: 7.2871e-03, dual residual: 3.150124e-02\n",
      "n_iter: 400, duality gap: 5.8520e-03, primal residual: 7.2749e-03, dual residual: 3.066746e-02\n",
      "n_iter: 500, duality gap: 6.7470e-03, primal residual: 6.9988e-03, dual residual: 2.909804e-02\n",
      "Batch loss: loss1: 14512.04688, loss2: 79056.25000, loss3: 48.71672\n",
      "Finished running batch 4.\n",
      "start running batch 5\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 1.3125e-01, primal residual: 4.8132e-03, dual residual: 6.247522e-02\n",
      "n_iter: 200, duality gap: 2.3410e-03, primal residual: 3.4706e-03, dual residual: 1.671239e-02\n",
      "n_iter: 300, duality gap: 2.1394e-03, primal residual: 3.3807e-03, dual residual: 1.371882e-02\n",
      "n_iter: 400, duality gap: 3.4100e-03, primal residual: 3.2854e-03, dual residual: 1.373936e-02\n",
      "n_iter: 500, duality gap: 2.8165e-03, primal residual: 3.4079e-03, dual residual: 1.365095e-02\n",
      "Batch loss: loss1: 14507.51562, loss2: 77649.25000, loss3: 48.67428\n",
      "Finished running batch 5.\n",
      "start running batch 6\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 1.2992e-01, primal residual: 2.1983e-03, dual residual: 3.699322e-02\n",
      "n_iter: 200, duality gap: 1.1763e-03, primal residual: 1.0078e-03, dual residual: 4.945843e-03\n",
      "n_iter: 300, duality gap: 6.4106e-04, primal residual: 9.6156e-04, dual residual: 3.534734e-03\n",
      "n_iter: 400, duality gap: 1.2990e-03, primal residual: 8.9326e-04, dual residual: 3.466241e-03\n",
      "n_iter: 500, duality gap: 5.9438e-04, primal residual: 9.0192e-04, dual residual: 3.466189e-03\n",
      "Batch loss: loss1: 14453.04004, loss2: 78138.02344, loss3: 48.65834\n",
      "Finished running batch 6.\n",
      "start running batch 7\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 1.3010e-01, primal residual: 2.4321e-03, dual residual: 4.285348e-02\n",
      "n_iter: 200, duality gap: 7.5966e-04, primal residual: 3.5938e-04, dual residual: 6.526402e-03\n",
      "n_iter: 300, duality gap: 5.2858e-04, primal residual: 3.1294e-04, dual residual: 2.121602e-03\n",
      "n_iter: 400, duality gap: 4.5695e-04, primal residual: 3.3001e-04, dual residual: 1.434178e-03\n",
      "n_iter: 500, duality gap: 3.0709e-04, primal residual: 3.1743e-04, dual residual: 1.329317e-03\n",
      "Batch loss: loss1: 14246.10547, loss2: 80253.77344, loss3: 48.67848\n",
      "Finished running batch 7.\n",
      "start running batch 8\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 1.3031e-01, primal residual: 2.5606e-03, dual residual: 5.522483e-02\n",
      "n_iter: 200, duality gap: 1.4986e-03, primal residual: 9.6474e-04, dual residual: 7.172389e-03\n",
      "n_iter: 300, duality gap: 9.9088e-04, primal residual: 9.2329e-04, dual residual: 3.066449e-03\n",
      "n_iter: 400, duality gap: 9.0717e-04, primal residual: 8.6565e-04, dual residual: 2.964003e-03\n",
      "n_iter: 500, duality gap: 8.9132e-04, primal residual: 9.1324e-04, dual residual: 2.901286e-03\n",
      "Batch loss: loss1: 13489.08789, loss2: 87398.34375, loss3: 48.79651\n",
      "Finished running batch 8.\n",
      "start running batch 9\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 1.2955e-01, primal residual: 2.6282e-03, dual residual: 9.284434e-02\n",
      "n_iter: 200, duality gap: 1.6901e-03, primal residual: 9.6526e-04, dual residual: 1.774205e-02\n",
      "n_iter: 300, duality gap: 1.3472e-03, primal residual: 9.9051e-04, dual residual: 4.415556e-03\n",
      "n_iter: 400, duality gap: 1.4289e-03, primal residual: 9.1288e-04, dual residual: 2.938784e-03\n",
      "n_iter: 500, duality gap: 8.9210e-04, primal residual: 9.9170e-04, dual residual: 3.016780e-03\n",
      "Batch loss: loss1: 12050.81641, loss2: 102215.17969, loss3: 49.02313\n",
      "Finished running batch 9.\n",
      "time calculating thetas: 1430.26 sec\n",
      "test without TF information\n",
      "final number of nearest neighbor (make connected): 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/home/ziqi/.conda/envs/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:174: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time calculating the kernel function: 3.86 sec\n",
      "start running batch 0\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 1.5600e-04, primal residual: 4.7703e-03, dual residual: 7.838767e-03\n",
      "n_iter: 200, duality gap: 9.5790e-05, primal residual: 4.5955e-03, dual residual: 1.269011e-03\n",
      "n_iter: 300, duality gap: 7.6509e-05, primal residual: 4.5075e-03, dual residual: 1.239651e-03\n",
      "n_iter: 400, duality gap: 8.1753e-05, primal residual: 4.5389e-03, dual residual: 1.220401e-03\n",
      "n_iter: 500, duality gap: 7.8495e-05, primal residual: 4.5147e-03, dual residual: 1.228512e-03\n",
      "Batch loss: loss1: -5772.77002, loss2: 305524.62500, loss3: 0.00000\n",
      "Finished running batch 0.\n",
      "start running batch 1\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 9.5392e-05, primal residual: 3.2976e-03, dual residual: 3.457118e-03\n",
      "n_iter: 200, duality gap: 5.7201e-05, primal residual: 3.0868e-03, dual residual: 1.048035e-03\n",
      "n_iter: 300, duality gap: 6.2910e-05, primal residual: 3.1181e-03, dual residual: 1.092705e-03\n",
      "n_iter: 400, duality gap: 6.2794e-05, primal residual: 2.9904e-03, dual residual: 1.089113e-03\n",
      "n_iter: 500, duality gap: 4.4466e-05, primal residual: 3.0577e-03, dual residual: 1.144170e-03\n",
      "Batch loss: loss1: -3477.64453, loss2: 276538.03125, loss3: 0.00000\n",
      "Finished running batch 1.\n",
      "start running batch 2\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 2.7909e-04, primal residual: 2.1908e-02, dual residual: 1.315824e-02\n",
      "n_iter: 200, duality gap: 3.6053e-04, primal residual: 2.2495e-02, dual residual: 8.741699e-03\n",
      "n_iter: 300, duality gap: 3.0541e-04, primal residual: 2.2600e-02, dual residual: 8.752703e-03\n",
      "n_iter: 400, duality gap: 3.0981e-04, primal residual: 2.2717e-02, dual residual: 8.208782e-03\n",
      "n_iter: 500, duality gap: 3.1614e-04, primal residual: 2.0956e-02, dual residual: 8.543908e-03\n",
      "Batch loss: loss1: -2090.42554, loss2: 258816.98438, loss3: 0.00000\n",
      "Finished running batch 2.\n",
      "start running batch 3\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 6.2020e-04, primal residual: 3.7457e-02, dual residual: 2.262394e-02\n",
      "n_iter: 200, duality gap: 5.0264e-04, primal residual: 3.3183e-02, dual residual: 2.086260e-02\n",
      "n_iter: 300, duality gap: 5.5767e-04, primal residual: 3.6441e-02, dual residual: 2.123423e-02\n",
      "n_iter: 400, duality gap: 4.1833e-04, primal residual: 3.2675e-02, dual residual: 2.017960e-02\n",
      "n_iter: 500, duality gap: 4.5762e-04, primal residual: 3.3922e-02, dual residual: 2.105636e-02\n",
      "Batch loss: loss1: nan, loss2: 249894.03125, loss3: 0.00000\n",
      "Finished running batch 3.\n",
      "start running batch 4\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 6.4744e-04, primal residual: 2.8950e-02, dual residual: 2.240077e-02\n",
      "n_iter: 200, duality gap: 6.2452e-04, primal residual: 2.9461e-02, dual residual: 2.062053e-02\n",
      "n_iter: 300, duality gap: 7.2291e-04, primal residual: 3.0873e-02, dual residual: 2.035864e-02\n",
      "n_iter: 400, duality gap: 4.9492e-04, primal residual: 2.7629e-02, dual residual: 2.037913e-02\n",
      "n_iter: 500, duality gap: 4.3771e-04, primal residual: 3.0573e-02, dual residual: 2.173085e-02\n",
      "Batch loss: loss1: nan, loss2: 243249.68750, loss3: 0.00000\n",
      "Finished running batch 4.\n",
      "start running batch 5\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 2.3670e-04, primal residual: 1.8988e-02, dual residual: 1.227436e-02\n",
      "n_iter: 200, duality gap: 2.2806e-04, primal residual: 1.7597e-02, dual residual: 9.570763e-03\n",
      "n_iter: 300, duality gap: 2.4785e-04, primal residual: 1.7720e-02, dual residual: 1.011563e-02\n",
      "n_iter: 400, duality gap: 3.1628e-04, primal residual: 1.8096e-02, dual residual: 9.089016e-03\n",
      "n_iter: 500, duality gap: 3.2178e-04, primal residual: 1.7767e-02, dual residual: 9.468030e-03\n",
      "Batch loss: loss1: -1195.85547, loss2: 243723.03125, loss3: 0.00000\n",
      "Finished running batch 5.\n",
      "start running batch 6\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 1.4575e-04, primal residual: 1.0283e-02, dual residual: 3.897522e-03\n",
      "n_iter: 200, duality gap: 1.1661e-04, primal residual: 1.0207e-02, dual residual: 3.661371e-03\n",
      "n_iter: 300, duality gap: 1.8636e-04, primal residual: 1.0201e-02, dual residual: 3.881368e-03\n",
      "n_iter: 400, duality gap: 1.4488e-04, primal residual: 1.0350e-02, dual residual: 3.716008e-03\n",
      "n_iter: 500, duality gap: 2.1149e-04, primal residual: 1.0397e-02, dual residual: 3.630249e-03\n",
      "Batch loss: loss1: -1258.99097, loss2: 247610.29688, loss3: 0.00000\n",
      "Finished running batch 6.\n",
      "start running batch 7\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 8.9969e-05, primal residual: 4.8001e-03, dual residual: 1.959723e-03\n",
      "n_iter: 200, duality gap: 5.0865e-05, primal residual: 4.4218e-03, dual residual: 1.515899e-03\n",
      "n_iter: 300, duality gap: 8.3730e-05, primal residual: 4.5003e-03, dual residual: 1.521530e-03\n",
      "n_iter: 400, duality gap: 5.7449e-05, primal residual: 4.7209e-03, dual residual: 1.582362e-03\n",
      "n_iter: 500, duality gap: 6.3747e-05, primal residual: 4.4274e-03, dual residual: 1.577832e-03\n",
      "Batch loss: loss1: -1628.54858, loss2: 253683.75000, loss3: 0.00000\n",
      "Finished running batch 7.\n",
      "start running batch 8\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 2.3294e-04, primal residual: 1.1193e-02, dual residual: 4.415044e-03\n",
      "n_iter: 200, duality gap: 2.1593e-04, primal residual: 1.1394e-02, dual residual: 3.633026e-03\n",
      "n_iter: 300, duality gap: 1.3442e-04, primal residual: 1.1142e-02, dual residual: 3.560440e-03\n",
      "n_iter: 400, duality gap: 2.9501e-04, primal residual: 1.0959e-02, dual residual: 3.503540e-03\n",
      "n_iter: 500, duality gap: 1.8324e-04, primal residual: 1.1702e-02, dual residual: 3.491920e-03\n",
      "Batch loss: loss1: -2999.15479, loss2: 273592.71875, loss3: 0.00000\n",
      "Finished running batch 8.\n",
      "start running batch 9\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 2.8835e-04, primal residual: 1.2149e-02, dual residual: 7.189914e-03\n",
      "n_iter: 200, duality gap: 1.9754e-04, primal residual: 1.1563e-02, dual residual: 3.637056e-03\n",
      "n_iter: 300, duality gap: 2.4788e-04, primal residual: 1.1799e-02, dual residual: 3.625388e-03\n",
      "n_iter: 400, duality gap: 2.5653e-04, primal residual: 1.1538e-02, dual residual: 3.655679e-03\n",
      "n_iter: 500, duality gap: 2.0047e-04, primal residual: 1.1849e-02, dual residual: 3.574111e-03\n",
      "Batch loss: loss1: -5582.47510, loss2: 307886.50000, loss3: 0.00000\n",
      "Finished running batch 9.\n",
      "time calculating thetas: 1589.29 sec\n",
      "test with TF information\n",
      "final number of nearest neighbor (make connected): 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/home/ziqi/.conda/envs/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:216: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time calculating the kernel function: 3.29 sec\n",
      "start running batch 0\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 1.8854e+00, primal residual: 2.7553e-02, dual residual: 1.420030e-01\n",
      "n_iter: 200, duality gap: 1.2106e+01, primal residual: 1.9894e-01, dual residual: 4.408873e-02\n",
      "n_iter: 300, duality gap: 4.7345e+00, primal residual: 6.4520e-02, dual residual: 1.852087e-02\n",
      "n_iter: 400, duality gap: 4.2983e-01, primal residual: 6.1582e-03, dual residual: 8.670169e-03\n",
      "n_iter: 500, duality gap: 5.6701e+01, primal residual: 5.5035e-01, dual residual: 7.080243e-02\n",
      "Batch loss: loss1: 11782.24023, loss2: 100692.50781, loss3: 60.51441\n",
      "Finished running batch 0.\n",
      "start running batch 1\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 1.9040e+00, primal residual: 2.7844e-02, dual residual: 1.062797e-01\n",
      "n_iter: 200, duality gap: 2.7461e+00, primal residual: 3.8201e-02, dual residual: 3.037164e-02\n",
      "n_iter: 300, duality gap: 6.8175e+01, primal residual: 1.0830e+00, dual residual: 9.143224e-01\n",
      "n_iter: 400, duality gap: 1.9627e+01, primal residual: 2.3672e-01, dual residual: 3.586750e-02\n",
      "n_iter: 500, duality gap: 1.5441e+02, primal residual: 1.1075e+00, dual residual: 2.460089e+00\n",
      "Batch loss: loss1: nan, loss2: 88289.50781, loss3: 61.38264\n",
      "Finished running batch 1.\n",
      "start running batch 2\n",
      "torch.Size([100, 100, 100])\n",
      "start cholesky decomposition...\n",
      "finished cholesky decomposition\n",
      "torch.Size([100, 100, 100])\n",
      "torch.Size([100, 100, 100])\n",
      "n_iter: 100, duality gap: 1.9097e+00, primal residual: 2.7972e-02, dual residual: 7.866814e-02\n",
      "n_iter: 200, duality gap: 5.3642e+00, primal residual: 7.3072e-02, dual residual: 2.671446e-02\n",
      "n_iter: 300, duality gap: 1.9633e-01, primal residual: 2.9153e-03, dual residual: 5.245550e-03\n",
      "n_iter: 400, duality gap: 1.4252e+02, primal residual: 1.0283e+00, dual residual: 5.776010e-01\n"
     ]
    }
   ],
   "source": [
    "# In[0]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys, os\n",
    "sys.path.append('../../src/')\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "import bmk_beeline as bmk\n",
    "import genie3, g_admm\n",
    "import kernel\n",
    "import time\n",
    "import gc\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "\n",
    "def preprocess(counts): \n",
    "    \"\"\"\\\n",
    "    Input:\n",
    "    counts = (ntimes, ngenes)\n",
    "    \n",
    "    Description:\n",
    "    ------------\n",
    "    Preprocess the dataset\n",
    "    \"\"\"\n",
    "    # normalize according to the library size\n",
    "    \n",
    "    libsize = np.median(np.sum(counts, axis = 1))\n",
    "    counts = counts / np.sum(counts, axis = 1)[:,None] * libsize\n",
    "        \n",
    "    counts = np.log1p(counts)\n",
    "    return counts\n",
    "\n",
    "# In[1] test with the first set of hyper-parameters\n",
    "ntimes = 1000\n",
    "path = \"../../data/GGM_changing_mean/\"\n",
    "max_iters = 500\n",
    "truncate_param = 7\n",
    "for interval in [50]:\n",
    "    # for (ngenes, ntfs) in [(20, 5), (30, 10), (50, 20), (100, 50)]:\n",
    "    for (ngenes, ntfs) in [(100, 50)]:\n",
    "        result_dir = \"../results/GGM_changing_mean_\" + str(ntimes) + \"_\" + str(interval) + \"_\" + str(ngenes) + \"/\"\n",
    "        if not os.path.exists(result_dir):\n",
    "            os.makedirs(result_dir)\n",
    "        # the data smapled from GGM is zero-mean\n",
    "        X = np.load(path + \"ntimes_\" + str(ntimes) + \"_interval_\" + str(interval) + \"_ngenes_\" + str(ngenes) + \"/expr.npy\")\n",
    "        # gt_adj = np.load(path + \"ntimes_\" + str(ntimes) + \"_interval_\" + str(interval) + \"_ngenes_\" + str(ngenes) + \"/Gs.npy\")\n",
    "\n",
    "        # sort the genes\n",
    "        print(\"Raw TimePoints: {}, no.Genes: {}\".format(X.shape[0],X.shape[1]))\n",
    "        # X = StandardScaler().fit_transform(X)\n",
    "\n",
    "        # make sure the dimensions are correct\n",
    "        assert X.shape[0] == ntimes\n",
    "        assert X.shape[1] == ngenes\n",
    "\n",
    "        sample = torch.FloatTensor(X).to(device)\n",
    "        ###############################################\n",
    "        #\n",
    "        # test with the first set of hyper-parameters, without TF information\n",
    "        #\n",
    "        ###############################################\n",
    "        if ngenes != 50:\n",
    "            print(\"test without TF information\")\n",
    "            for bandwidth in [0.1]:\n",
    "                start_time = time.time()\n",
    "                empir_cov = torch.zeros(ntimes, ngenes, ngenes)\n",
    "                # calculate the kernel function\n",
    "                K, K_trun = kernel.calc_kernel(X, k = 5, bandwidth = bandwidth, truncate = True, truncate_param = truncate_param)\n",
    "\n",
    "                # plot kernel function\n",
    "                fig = plt.figure(figsize = (20, 7))\n",
    "                axs = fig.subplots(1, 2)\n",
    "                axs[0].plot(K[int(ntimes/2), :])\n",
    "                axs[1].plot(K_trun[int(ntimes/2), :])\n",
    "                fig.savefig(result_dir + \"kernel_\" + str(bandwidth) + \".png\", bbox_inches = \"tight\")\n",
    "\n",
    "                # building weighted covariance matrix, output is empir_cov of the shape (ntimes, ngenes, ngenes)\n",
    "                for t in range(ntimes):\n",
    "                    weight = torch.FloatTensor(K_trun[t, :]).to(device)\n",
    "                    # assert torch.sum(weight) == 1\n",
    "\n",
    "                    bin_weight = torch.FloatTensor((K_trun[t, :] > 0).astype(np.int))\n",
    "                    sample_mean = torch.sum(sample * weight[:, None], dim = 0)\n",
    "                    # sample_mean = torch.sum(sample * (bin_weight/torch.sum(bin_weight))[:, None], dim = 0)\n",
    "\n",
    "                    norm_sample = sample - sample_mean[None, :]\n",
    "                    empir_cov[t] = torch.sum(torch.bmm(norm_sample[:,:,None], norm_sample[:,None,:]) * weight[:,None, None], dim=0)\n",
    "                print(\"time calculating the kernel function: {:.2f} sec\".format(time.time() - start_time))\n",
    "                \n",
    "                start_time = time.time()                    \n",
    "                # run the model\n",
    "                for lamb in [0.01]:\n",
    "                    # test model without TF\n",
    "                    thetas = np.zeros((ntimes,ngenes,ngenes))\n",
    "\n",
    "                    # setting from the paper over-relaxation model\n",
    "                    alpha = 2\n",
    "                    rho = 1.7\n",
    "                    # gadmm_batch = g_admm.G_admm_batch(X=X[:, None, :], K=K, pre_cov=empir_cov)\n",
    "                    gadmm_batch = g_admm.G_admm_minibatch(X=X[:, None, :], K=K, pre_cov=empir_cov, batchsize = 100)\n",
    "                    thetas = gadmm_batch.train(max_iters=max_iters, n_intervals=10, alpha=alpha, lamb=lamb, rho=rho, theta_init_offset=0.1)\n",
    "                    np.save(file = result_dir + \"thetas_\" + str(bandwidth) + \"_\" + str(alpha) + \"_\" + str(lamb) + \"_\" + str(rho) + \".npy\", arr = thetas) \n",
    "                    print(\"time calculating thetas: {:.2f} sec\".format(time.time() - start_time))\n",
    "                del thetas\n",
    "                gadmm_batch = None\n",
    "                gc.collect()\n",
    "\n",
    "            ###############################################\n",
    "            #\n",
    "            # test with TF information\n",
    "            #\n",
    "            ###############################################\n",
    "            print(\"test with TF information\")\n",
    "            for bandwidth in [0.1]:\n",
    "                start_time = time.time()\n",
    "                empir_cov = torch.zeros(ntimes, ngenes, ngenes)\n",
    "                K, K_trun = kernel.calc_kernel(X, k = 5, bandwidth = bandwidth, truncate = True, truncate_param = truncate_param)\n",
    "\n",
    "                # building weighted covariance matrix, output is empir_cov of the shape (ntimes, ngenes, ngenes)\n",
    "                for t in range(ntimes):\n",
    "                    weight = torch.FloatTensor(K_trun[t, :]).to(device)\n",
    "                    # assert torch.sum(weight) == 1\n",
    "\n",
    "                    bin_weight = torch.FloatTensor((K_trun[t, :] > 0).astype(np.int))\n",
    "                    sample_mean = torch.sum(sample * weight[:, None], dim = 0)\n",
    "                    # sample_mean = torch.sum(sample * (bin_weight/torch.sum(bin_weight))[:, None], dim = 0)\n",
    "\n",
    "                    norm_sample = sample - sample_mean[None, :]\n",
    "                    empir_cov[t] = torch.sum(torch.bmm(norm_sample[:,:,None], norm_sample[:,None,:]) * weight[:,None, None], dim=0)\n",
    "                print(\"time calculating the kernel function: {:.2f} sec\".format(time.time() - start_time))\n",
    "                \n",
    "                start_time = time.time()                                  \n",
    "                # run the model\n",
    "                for lamb in [0.01]:\n",
    "                    # test model without TF\n",
    "                    thetas = np.zeros((ntimes,ngenes,ngenes))\n",
    "\n",
    "                    # setting from the paper over-relaxation model\n",
    "                    alpha = 2\n",
    "                    rho = 1.7\n",
    "                    # gadmm_batch = g_admm.G_admm_batch(X=X[:, None, :], K=K, pre_cov=empir_cov, TF=np.arange(ntfs))\n",
    "                    gadmm_batch = g_admm.G_admm_minibatch(X=X[:, None, :], K=K, pre_cov=empir_cov, batchsize = 100, TF=np.arange(ntfs))\n",
    "                    thetas = gadmm_batch.train(max_iters=max_iters, n_intervals=100, alpha=alpha, lamb=lamb, rho=rho, beta=100, theta_init_offset=0.1)\n",
    "                    np.save(file = result_dir + \"thetas_\" + str(bandwidth) + \"_\" + str(alpha) + \"_\" + str(lamb) + \"_\" + str(rho) + \"_tfs.npy\", arr = thetas) \n",
    "                    print(\"time calculating thetas: {:.2f} sec\".format(time.time() - start_time))\n",
    "                del thetas\n",
    "                gadmm_batch = None\n",
    "                gc.collect()\n",
    "\n",
    "\n",
    "        ###############################################\n",
    "        #\n",
    "        # test with the second set of hyper-parameters, without TF information\n",
    "        #\n",
    "        ###############################################\n",
    "        print(\"test without TF information\")\n",
    "        for bandwidth in [0.1]:\n",
    "            start_time = time.time()\n",
    "            empir_cov = torch.zeros(ntimes, ngenes, ngenes)\n",
    "            # calculate the kernel function\n",
    "            K, K_trun = kernel.calc_kernel(X, k = 5, bandwidth = bandwidth, truncate = True, truncate_param = truncate_param)\n",
    "\n",
    "            # building weighted covariance matrix, output is empir_cov of the shape (ntimes, ngenes, ngenes)\n",
    "            for t in range(ntimes):\n",
    "                weight = torch.FloatTensor(K_trun[t, :]).to(device)\n",
    "                # assert torch.sum(weight) == 1\n",
    "\n",
    "                bin_weight = torch.FloatTensor((K_trun[t, :] > 0).astype(np.int))\n",
    "                sample_mean = torch.sum(sample * weight[:, None], dim = 0)\n",
    "                # sample_mean = torch.sum(sample * (bin_weight/torch.sum(bin_weight))[:, None], dim = 0)\n",
    "\n",
    "                norm_sample = sample - sample_mean[None, :]\n",
    "                empir_cov[t] = torch.sum(torch.bmm(norm_sample[:,:,None], norm_sample[:,None,:]) * weight[:,None, None], dim=0)\n",
    "            print(\"time calculating the kernel function: {:.2f} sec\".format(time.time() - start_time))\n",
    "            \n",
    "            start_time = time.time()                    \n",
    "            # run the model\n",
    "            for lamb in [0.01]:\n",
    "                # test model without TF\n",
    "                thetas = np.zeros((ntimes,ngenes,ngenes))\n",
    "\n",
    "                # setting from the paper over-relaxation model\n",
    "                alpha = 1\n",
    "                rho = None\n",
    "                # gadmm_batch = g_admm.G_admm_batch(X=X[:, None, :], K=K, pre_cov=empir_cov)\n",
    "                gadmm_batch = g_admm.G_admm_minibatch(X=X[:, None, :], K=K, pre_cov=empir_cov, batchsize = 100)\n",
    "                thetas = gadmm_batch.train(max_iters=max_iters, n_intervals=100, alpha=alpha, lamb=lamb, rho=rho, theta_init_offset=0.1)\n",
    "                np.save(file = result_dir + \"thetas_\" + str(bandwidth) + \"_\" + str(alpha) + \"_\" + str(lamb) + \"_\" + str(rho) + \".npy\", arr = thetas) \n",
    "                print(\"time calculating thetas: {:.2f} sec\".format(time.time() - start_time))\n",
    "            del thetas\n",
    "            gadmm_batch = None\n",
    "            gc.collect()\n",
    "\n",
    "        ###############################################\n",
    "        #\n",
    "        # test with TF information\n",
    "        #\n",
    "        ###############################################\n",
    "        print(\"test with TF information\")\n",
    "        for bandwidth in [0.1]:\n",
    "            start_time = time.time()\n",
    "            empir_cov = torch.zeros(ntimes, ngenes, ngenes)\n",
    "            K, K_trun = kernel.calc_kernel(X, k = 5, bandwidth = bandwidth, truncate = True, truncate_param = truncate_param)\n",
    "\n",
    "            # building weighted covariance matrix, output is empir_cov of the shape (ntimes, ngenes, ngenes)\n",
    "            for t in range(ntimes):\n",
    "                weight = torch.FloatTensor(K_trun[t, :]).to(device)\n",
    "                # assert torch.sum(weight) == 1\n",
    "\n",
    "                bin_weight = torch.FloatTensor((K_trun[t, :] > 0).astype(np.int))\n",
    "                sample_mean = torch.sum(sample * weight[:, None], dim = 0)\n",
    "                # sample_mean = torch.sum(sample * (bin_weight/torch.sum(bin_weight))[:, None], dim = 0)\n",
    "\n",
    "                norm_sample = sample - sample_mean[None, :]\n",
    "                empir_cov[t] = torch.sum(torch.bmm(norm_sample[:,:,None], norm_sample[:,None,:]) * weight[:,None, None], dim=0)\n",
    "            print(\"time calculating the kernel function: {:.2f} sec\".format(time.time() - start_time))\n",
    "            \n",
    "            start_time = time.time()                                  \n",
    "            # run the model\n",
    "            for lamb in [0.01]:\n",
    "                # test model without TF\n",
    "                thetas = np.zeros((ntimes,ngenes,ngenes))\n",
    "\n",
    "                # setting from the paper over-relaxation model\n",
    "                alpha = 1\n",
    "                rho = None\n",
    "                # gadmm_batch = g_admm.G_admm_batch(X=X[:, None, :], K=K, pre_cov=empir_cov, TF=np.arange(ntfs))\n",
    "                gadmm_batch = g_admm.G_admm_minibatch(X=X[:, None, :], K=K, pre_cov=empir_cov, batchsize = 100, TF=np.arange(ntfs))\n",
    "                thetas = gadmm_batch.train(max_iters=max_iters, n_intervals=100, alpha=alpha, lamb=lamb, rho=rho, beta=100, theta_init_offset=0.1)\n",
    "                np.save(file = result_dir + \"thetas_\" + str(bandwidth) + \"_\" + str(alpha) + \"_\" + str(lamb) + \"_\" + str(rho) + \"_tfs.npy\", arr = thetas) \n",
    "                print(\"time calculating thetas: {:.2f} sec\".format(time.time() - start_time))\n",
    "            del thetas\n",
    "            gadmm_batch = None\n",
    "            gc.collect()\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_sqrtm import MatrixSquareRoot\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "torch_sqrtm = MatrixSquareRoot.apply\n",
    "\n",
    "class G_admm_minibatch():\n",
    "    def __init__(self, X, K, TF = None, seed = 0, pre_cov = None, batchsize = None):\n",
    "        super(G_admm_minibatch, self).__init__()\n",
    "        # set random seed\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "\n",
    "        # shape (ntimes, nsamples, ngenes)\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.ntimes, self.nsamples, self.ngenes = self.X.shape\n",
    "        \n",
    "        # calculate batchsize\n",
    "        if batchsize is None:\n",
    "            self.batchsize = int(self.ntimes/10)\n",
    "        else:\n",
    "            self.batchsize = batchsize\n",
    "        # calculate empirical covariance matrix\n",
    "        if pre_cov is None:\n",
    "            # shape (ntimes, nsamples, ngenes)\n",
    "            self.epir_mean = self.X.mean(dim = 1, keepdim = True)\n",
    "            X = self.X - self.epir_mean\n",
    "            # (ntimes * nsamples, ngenes, ngenes)\n",
    "            self.empir_cov = torch.bmm(X.reshape((self.ntimes * self.nsamples, self.ngenes, 1)), X.reshape((self.ntimes * self.nsamples, 1, self.ngenes)))\n",
    "            # (ntimes, ngenes, ngenes)\n",
    "            self.empir_cov = torch.sum(self.empir_cov.reshape((self.ntimes, self.nsamples, self.ngenes, self.ngenes)), dim = 1)/(self.nsamples - 1)\n",
    "        else:\n",
    "            self.empir_cov = pre_cov\n",
    "\n",
    "        # weight kernel function, shape (ntimes, ntimes)\n",
    "        self.weights = torch.FloatTensor(K)\n",
    "        # weighted average of empricial covariance matrix\n",
    "        assert torch.all(torch.sum(self.weights,dim=1) - 1 < 1e-6)\n",
    "        self.w_empir_cov = torch.sum((self.weights[:,:,None,None]*self.empir_cov[None,:,:,:]),dim=1) \n",
    "        # store the result\n",
    "        self.thetas = np.zeros((self.ntimes, self.ngenes, self.ngenes))\n",
    "        \n",
    "        # mask matrix (ntimes, ngenes, ngenes)\n",
    "        if TF is not None:\n",
    "            self.mask = torch.zeros(self.ngenes, self.ngenes)\n",
    "            # mark probable interactions\n",
    "            self.mask[TF, :] = 1\n",
    "            self.mask[:, TF] = 1\n",
    "            # element-wise reverse\n",
    "            self.mask = 1 - self.mask\n",
    "            self.mask = self.mask.expand(self.ntimes, self.ngenes, self.ngenes) \n",
    "        else:\n",
    "            self.mask = torch.FloatTensor([0])  \n",
    "\n",
    "    @staticmethod\n",
    "    def neg_lkl_loss(thetas, S):\n",
    "        \"\"\"\\\n",
    "        Description:\n",
    "        --------------\n",
    "            The negative log likelihood function\n",
    "        Parameters:\n",
    "        --------------\n",
    "            theta:\n",
    "                The estimated theta\n",
    "            S:\n",
    "                The empirical covariance matrix\n",
    "        Return:\n",
    "        --------------\n",
    "            The negative log likelihood value\n",
    "        \"\"\"\n",
    "        # logdet works for batches of matrices, give a high dimensional data\n",
    "        t1 = -1*torch.logdet(thetas)\n",
    "        t2 = torch.stack([torch.trace(mat) for mat in torch.bmm(S, thetas)])\n",
    "        return t1 + t2\n",
    "\n",
    "\n",
    "    def train(self, max_iters = 50, n_intervals = 1, lamb = 2.1e-4, alpha = 1, rho = 1, beta = 0, theta_init_offset = 0.1):\n",
    "        n_batches = int(np.ceil(self.ntimes/self.batchsize))\n",
    "        for batch in range(n_batches):\n",
    "            # select a minibatch, and load to cuda\n",
    "            start_idx = batch * self.batchsize\n",
    "            if batch < n_batches - 1:\n",
    "                end_idx = (batch + 1) * self.batchsize\n",
    "                w_empir_cov = self.w_empir_cov[start_idx:end_idx, :, :].to(device)\n",
    "                if self.mask.shape[0] == self.ntimes:\n",
    "                    mask = self.mask[start_idx:end_idx, :, :].to(device)\n",
    "                else:\n",
    "                    mask = self.mask.to(device)\n",
    "            else:\n",
    "                w_empir_cov = self.w_empir_cov[start_idx:, :, :].to(device)\n",
    "                if self.mask.shape[0] == self.ntimes:\n",
    "                    mask = self.mask[start_idx:, :, :].to(device)\n",
    "                else:\n",
    "                    mask = self.mask.to(device)\n",
    "            # initialize mini-batch, Z of the shape (batch_size, ngenes, ngenes)\n",
    "            Z = torch.diag_embed(1/(torch.diagonal(w_empir_cov, offset=0, dim1=-2, dim2=-1) + theta_init_offset))\n",
    "            # make Z positive definite matrix\n",
    "            ll = torch.cholesky(Z)\n",
    "            Z = torch.matmul(ll, ll.transpose(-1, -2))\n",
    "            U = torch.zeros(Z.shape).to(device)\n",
    "            I = torch.eye(self.ngenes).expand(Z.shape).to(device)\n",
    "\n",
    "            it = 0\n",
    "            # hyper-parameter for batches\n",
    "            if rho is None:\n",
    "                updating_rho = True\n",
    "                # rho of the shape (ntimes, 1, 1)\n",
    "                b_rho = torch.ones((Z.shape[0], 1, 1)).to(device) * 1.7\n",
    "            else:\n",
    "                b_rho = torch.FloatTensor([rho] * Z.shape[0])[:, None, None].to(device)\n",
    "                updating_rho = False\n",
    "            b_alpha = alpha \n",
    "            b_beta = beta\n",
    "            b_lamb = lamb\n",
    "            while(it < max_iters): \n",
    "                # Primal \n",
    "                Y = U - Z + w_empir_cov/b_rho    # (ntimes, ngenes, ngenes)\n",
    "                thetas = - 0.5 * Y + torch.stack([torch_sqrtm(mat) for mat in (torch.transpose(Y,1,2) @ Y * 0.25 + I/b_rho)])\n",
    "                Z_pre = Z.detach().clone()\n",
    "                # over-relaxation\n",
    "                thetas = b_alpha * thetas + (1 - b_alpha) * Z_pre            \n",
    "                Z = torch.sign(thetas + U) * torch.max((b_rho * (thetas + U).abs() - b_lamb)/(b_rho + b_beta * mask), torch.Tensor([0]).to(device))\n",
    "\n",
    "                # Dual\n",
    "                U = U + thetas - Z\n",
    "\n",
    "                # calculate residual\n",
    "                # primal_residual and dual_residual of the shape (ntimes, 1, 1)\n",
    "                primal_residual = torch.sqrt((thetas - Z).pow(2).sum(1).sum(1))\n",
    "                dual_residual = b_rho.squeeze() * torch.sqrt((Z - Z_pre).pow(2).sum(1).sum(1))\n",
    "\n",
    "                # updating rho, rho should be of shape (ntimes, 1, 1)\n",
    "                if updating_rho:\n",
    "                    mask_inc = (primal_residual > 10 * dual_residual)\n",
    "                    b_rho[mask_inc, :, :] = b_rho[mask_inc, :, :] * 2\n",
    "                    mask_dec = (dual_residual > 10 * primal_residual)\n",
    "                    b_rho[mask_dec, :, :] = b_rho[mask_dec, :, :] / 2\n",
    "                \n",
    "                # print(rho.squeeze())\n",
    "                # free-up memory\n",
    "                del Z_pre\n",
    "                \n",
    "                # Stopping criteria\n",
    "                if (it + 1) % n_intervals == 0:\n",
    "                    print(\"Current GPU memory: \") \n",
    "                    print(get_gpu_memory())\n",
    "                    # calculate sum of all duality gap\n",
    "                    # loss = self.neg_lkl_loss(thetas, w_empir_cov).sum() + b_lamb * Z.abs().sum() + b_beta * (self.mask * Z).pow(2).sum()\n",
    "                    # primal_val = loss  + rho/2 * (thetas - Z).pow(2).sum()\n",
    "                    # dual_val = loss + rho/2 * (thetas - Z + U).pow(2).sum() - rho/2 * U.pow(2).sum()\n",
    "                    # duality_gap = primal_val - dual_val\n",
    "\n",
    "                    # simplify min of all duality gap\n",
    "                    duality_gap = b_rho.squeeze() * torch.stack([torch.trace(mat) for mat in torch.bmm(U.permute(0,2,1), Z - thetas)])\n",
    "                    duality_gap = duality_gap.abs()\n",
    "                    print(\"n_iter: {}, duality gap: {:.4e}, primal residual: {:.4e}, dual residual: {:4e}\".format(it+1, duality_gap.max().item(), primal_residual.max().item(), dual_residual.max().item()))\n",
    "                    \n",
    "                    # if duality_gap < 1e-8:\n",
    "                    #     break\n",
    "                    primal_eps = 1e-6\n",
    "                    dual_eps = 1e-6\n",
    "                    if (primal_residual.max() < primal_eps) and (dual_residual.max() < dual_eps):\n",
    "                        break                \n",
    "                it += 1\n",
    "            \n",
    "            loss1 = self.neg_lkl_loss(Z, w_empir_cov).sum()\n",
    "            loss2 = Z.abs().sum()\n",
    "            loss3 = (mask * Z).pow(2).sum()\n",
    "            print(\"Batche loss: loss1: {:.5f}, loss2: {:.5f}, loss3: {:.5f}\".format(loss1.item(), loss2.item(), loss3.item()))  \n",
    "            # store values\n",
    "            if batch < n_batches - 1:\n",
    "                self.thetas[start_idx:end_idx] = Z.detach().cpu().numpy()\n",
    "            else:\n",
    "                self.thetas[start_idx:] = Z.detach().cpu().numpy()\n",
    "            del thetas, U, I, Y, ll, Z\n",
    "\n",
    "\n",
    "        return self.thetas\n",
    "\n",
    "\n",
    "def preprocess(counts): \n",
    "    \"\"\"\\\n",
    "    Input:\n",
    "    counts = (ntimes, ngenes)\n",
    "    \n",
    "    Description:\n",
    "    ------------\n",
    "    Preprocess the dataset\n",
    "    \"\"\"\n",
    "    # normalize according to the library size\n",
    "    \n",
    "    libsize = np.median(np.sum(counts, axis = 1))\n",
    "    counts = counts / np.sum(counts, axis = 1)[:,None] * libsize\n",
    "        \n",
    "    counts = np.log1p(counts)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'kernel' from '../../src/kernel.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib \n",
    "importlib.reload(g_admm)\n",
    "importlib.reload(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw TimePoints: 1000, no.Genes: 20\n",
      "number of nearest neighbor: 6\n",
      "number of nearest neighbor: 7\n",
      "final number of nearest neighbor (make connected): 7\n",
      "time calculating the kernel function: 3.18 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1856a6c51983>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mgadmm_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_admm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_admm_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_cov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mempir_cov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;31m# gadmm_batch = G_admm_minibatch(X=X[:, None, :], K=K, pre_cov=empir_cov, batchsize = 1000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mthetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgadmm_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_intervals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_init_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"thetas_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbandwidth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time calculating thetas: {:.2f} sec\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/hive/project/cse-vuduc/zzhang834/DynGRN/src/g_admm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, max_iters, n_intervals, lamb, alpha, rho, beta, theta_init_offset)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;31m# Primal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_empir_cov\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mrho\u001b[0m    \u001b[0;31m# (ntimes, ngenes, ngenes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mthetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch_sqrtm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.25\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mZ_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;31m# over-relaxation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/hive/project/cse-vuduc/zzhang834/DynGRN/src/g_admm.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;31m# Primal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_empir_cov\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mrho\u001b[0m    \u001b[0;31m# (ntimes, ngenes, ngenes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mthetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch_sqrtm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.25\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mZ_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;31m# over-relaxation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/hive/project/cse-vuduc/zzhang834/DynGRN/src/torch_sqrtm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#m = input.numpy().astype(np.float_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msqrtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrtm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.type_as(input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqrtm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# save in cpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msqrtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/scipy/linalg/_matfuncs_sqrtm.py\u001b[0m in \u001b[0;36msqrtm\u001b[0;34m(A, disp, blocksize)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mfailflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sqrtm_triu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mZH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/scipy/linalg/_matfuncs_sqrtm.py\u001b[0m in \u001b[0;36m_sqrtm_triu\u001b[0;34m(T, blocksize)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ntimes = 1000\n",
    "path = \"../../data/GGM_changing_mean/\"\n",
    "for interval in [50, 100, 200]:\n",
    "    for (ngenes, ntfs) in [(30, 5)]:\n",
    "        result_dir = \"../results/GGM_changing_mean_\" + str(ntimes) + \"_\" + str(interval) + \"_\" + str(ngenes) + \"/\"\n",
    "        if not os.path.exists(result_dir):\n",
    "            os.makedirs(result_dir)\n",
    "        # the data smapled from GGM is zero-mean\n",
    "        X = np.load(path + \"ntimes_\" + str(ntimes) + \"_interval_\" + str(interval) + \"_ngenes_\" + str(ngenes) + \"/expr.npy\")\n",
    "        print(\"Raw TimePoints: {}, no.Genes: {}\".format(X.shape[0],X.shape[1]))\n",
    "        # X = StandardScaler().fit_transform(X)\n",
    "\n",
    "        # make sure the dimensions are correct\n",
    "        assert X.shape[0] == ntimes\n",
    "        assert X.shape[1] == ngenes\n",
    "\n",
    "        sample = torch.FloatTensor(X).to(device)\n",
    "        max_iters = 20\n",
    "        ###############################################\n",
    "        #\n",
    "        # test without TF information\n",
    "        #\n",
    "        ###############################################\n",
    "\n",
    "        for bandwidth in [0.1]:\n",
    "            start_time = time.time()\n",
    "            empir_cov = torch.zeros(ntimes, ngenes, ngenes)\n",
    "            # calculate the kernel function\n",
    "            K, K_trun = kernel.calc_kernel(X, k = 5, bandwidth = bandwidth, truncate = True)\n",
    "            \n",
    "            # building weighted covariance matrix, output is empir_cov of the shape (ntimes, ngenes, ngenes)\n",
    "            for t in range(ntimes):\n",
    "                weight = torch.FloatTensor(K_trun[t, :]).to(device)\n",
    "                # assert torch.sum(weight) == 1\n",
    "\n",
    "                bin_weight = torch.FloatTensor((K_trun[t, :] > 0).astype(np.int))\n",
    "                sample_mean = torch.sum(sample * weight[:, None], dim = 0)\n",
    "                # sample_mean = torch.sum(sample * (bin_weight/torch.sum(bin_weight))[:, None], dim = 0)\n",
    "\n",
    "                norm_sample = sample - sample_mean[None, :]\n",
    "                empir_cov[t] = torch.sum(torch.bmm(norm_sample[:,:,None], norm_sample[:,None,:]) * weight[:,None, None], dim=0)\n",
    "            print(\"time calculating the kernel function: {:.2f} sec\".format(time.time() - start_time))\n",
    "            \n",
    "            start_time = time.time()                    \n",
    "            # run the model\n",
    "            for lamb in [0.01]:\n",
    "                # test model without TF\n",
    "                thetas = np.zeros((ntimes,ngenes,ngenes))\n",
    "\n",
    "                # setting from the paper over-relaxation model\n",
    "                alpha = 2\n",
    "                rho = 1.7\n",
    "                gadmm_batch = g_admm.G_admm_batch(X=X[:, None, :], K=K, pre_cov=empir_cov)\n",
    "                # gadmm_batch = G_admm_minibatch(X=X[:, None, :], K=K, pre_cov=empir_cov, batchsize = 1000)\n",
    "                thetas = gadmm_batch.train(max_iters=max_iters, n_intervals=10, alpha=alpha, lamb=lamb, rho=rho, theta_init_offset=0.1)\n",
    "                np.save(file = result_dir + \"thetas_\" + str(bandwidth) + \"_\" + str(alpha) + \"_\" + str(lamb) + \"_\" + str(rho) + \".npy\", arr = thetas) \n",
    "                print(\"time calculating thetas: {:.2f} sec\".format(time.time() - start_time))\n",
    "            del thetas\n",
    "            gadmm_batch = None\n",
    "            gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw TimePoints: 1000, no.Genes: 20\n",
      "test without TF information\n",
      "number of nearest neighbor: 6\n",
      "number of nearest neighbor: 7\n",
      "final number of nearest neighbor (make connected): 7\n",
      "time calculating the kernel function: 3.69 sec\n",
      "n_iter: 100, duality gap: 1.5150e-05, primal residual: 1.2197e-03, dual residual: 1.630644e-01\n",
      "n_iter: 200, duality gap: 9.3371e-06, primal residual: 6.8934e-04, dual residual: 1.306090e-01\n",
      "n_iter: 300, duality gap: 7.1960e-06, primal residual: 4.9921e-04, dual residual: 1.086170e-01\n",
      "n_iter: 400, duality gap: 5.4585e-06, primal residual: 3.8609e-04, dual residual: 9.634646e-02\n",
      "n_iter: 500, duality gap: 4.2434e-06, primal residual: 3.1611e-04, dual residual: 8.762145e-02\n",
      "n_iter: 600, duality gap: 3.3450e-06, primal residual: 2.8188e-04, dual residual: 8.060444e-02\n",
      "n_iter: 700, duality gap: 2.9418e-06, primal residual: 2.4579e-04, dual residual: 7.465711e-02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6ac19e1fedcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0;31m# gadmm_batch = g_admm.G_admm_batch(X=X[:, None, :], K=K, pre_cov=empir_cov)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mgadmm_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_admm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_admm_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_cov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mempir_cov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0mthetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgadmm_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_intervals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_init_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"thetas_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbandwidth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time calculating thetas: {:.2f} sec\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/hive/project/cse-vuduc/zzhang834/DynGRN/src/g_admm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, max_iters, n_intervals, lamb, alpha, rho, beta, theta_init_offset)\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;31m# Primal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw_empir_cov\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mb_rho\u001b[0m    \u001b[0;31m# (ntimes, ngenes, ngenes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                 \u001b[0mthetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch_sqrtm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.25\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mb_rho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0mZ_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                 \u001b[0;31m# over-relaxation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/hive/project/cse-vuduc/zzhang834/DynGRN/src/g_admm.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;31m# Primal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw_empir_cov\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mb_rho\u001b[0m    \u001b[0;31m# (ntimes, ngenes, ngenes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                 \u001b[0mthetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch_sqrtm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.25\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mb_rho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0mZ_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                 \u001b[0;31m# over-relaxation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/hive/project/cse-vuduc/zzhang834/DynGRN/src/torch_sqrtm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#m = input.numpy().astype(np.float_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msqrtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrtm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.type_as(input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqrtm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# save in cpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msqrtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/scipy/linalg/_matfuncs_sqrtm.py\u001b[0m in \u001b[0;36msqrtm\u001b[0;34m(A, disp, blocksize)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mfailflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sqrtm_triu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mZH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/scipy/linalg/_matfuncs_sqrtm.py\u001b[0m in \u001b[0;36m_sqrtm_triu\u001b[0;34m(T, blocksize)\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdenom\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In[0]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys, os\n",
    "sys.path.append('../../src/')\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "import bmk_beeline as bmk\n",
    "import genie3, g_admm\n",
    "import kernel\n",
    "import time\n",
    "import gc\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "\n",
    "def preprocess(counts): \n",
    "    \"\"\"\\\n",
    "    Input:\n",
    "    counts = (ntimes, ngenes)\n",
    "    \n",
    "    Description:\n",
    "    ------------\n",
    "    Preprocess the dataset\n",
    "    \"\"\"\n",
    "    # normalize according to the library size\n",
    "    \n",
    "    libsize = np.median(np.sum(counts, axis = 1))\n",
    "    counts = counts / np.sum(counts, axis = 1)[:,None] * libsize\n",
    "        \n",
    "    counts = np.log1p(counts)\n",
    "    return counts\n",
    "\n",
    "# In[1] test with the first set of hyper-parameters\n",
    "ntimes = 1000\n",
    "path = \"../../data/GGM_changing_mean/\"\n",
    "max_iters = 2000\n",
    "truncate_param = 7\n",
    "for interval in [50]:\n",
    "    for (ngenes, ntfs) in [(20, 5), (30, 10), (50, 20), (100, 50)]:\n",
    "        result_dir = \"../results/GGM_changing_mean_\" + str(ntimes) + \"_\" + str(interval) + \"_\" + str(ngenes) + \"/\"\n",
    "        if not os.path.exists(result_dir):\n",
    "            os.makedirs(result_dir)\n",
    "        # the data smapled from GGM is zero-mean\n",
    "        X = np.load(path + \"ntimes_\" + str(ntimes) + \"_interval_\" + str(interval) + \"_ngenes_\" + str(ngenes) + \"/expr.npy\")\n",
    "        # gt_adj = np.load(path + \"ntimes_\" + str(ntimes) + \"_interval_\" + str(interval) + \"_ngenes_\" + str(ngenes) + \"/Gs.npy\")\n",
    "\n",
    "        # sort the genes\n",
    "        print(\"Raw TimePoints: {}, no.Genes: {}\".format(X.shape[0],X.shape[1]))\n",
    "        # X = StandardScaler().fit_transform(X)\n",
    "\n",
    "        # make sure the dimensions are correct\n",
    "        assert X.shape[0] == ntimes\n",
    "        assert X.shape[1] == ngenes\n",
    "\n",
    "        sample = torch.FloatTensor(X).to(device)\n",
    "        ###############################################\n",
    "        #\n",
    "        # test with the first set of hyper-parameters, without TF information\n",
    "        #\n",
    "        ###############################################\n",
    "        print(\"test without TF information\")\n",
    "        for bandwidth in [0.1]:\n",
    "            start_time = time.time()\n",
    "            empir_cov = torch.zeros(ntimes, ngenes, ngenes)\n",
    "            # calculate the kernel function\n",
    "            K, K_trun = kernel.calc_kernel(X, k = 5, bandwidth = bandwidth, truncate = True, truncate_param = truncate_param)\n",
    "\n",
    "            # plot kernel function\n",
    "            fig = plt.figure(figsize = (20, 7))\n",
    "            axs = fig.subplots(1, 2)\n",
    "            axs[0].plot(K[int(ntimes/2), :])\n",
    "            axs[1].plot(K_trun[int(ntimes/2), :])\n",
    "            fig.savefig(result_dir + \"kernel_\" + str(bandwidth) + \".png\", bbox_inches = \"tight\")\n",
    "\n",
    "            # building weighted covariance matrix, output is empir_cov of the shape (ntimes, ngenes, ngenes)\n",
    "            for t in range(ntimes):\n",
    "                weight = torch.FloatTensor(K_trun[t, :]).to(device)\n",
    "                # assert torch.sum(weight) == 1\n",
    "\n",
    "                bin_weight = torch.FloatTensor((K_trun[t, :] > 0).astype(np.int))\n",
    "                sample_mean = torch.sum(sample * weight[:, None], dim = 0)\n",
    "                # sample_mean = torch.sum(sample * (bin_weight/torch.sum(bin_weight))[:, None], dim = 0)\n",
    "\n",
    "                norm_sample = sample - sample_mean[None, :]\n",
    "                empir_cov[t] = torch.sum(torch.bmm(norm_sample[:,:,None], norm_sample[:,None,:]) * weight[:,None, None], dim=0)\n",
    "            print(\"time calculating the kernel function: {:.2f} sec\".format(time.time() - start_time))\n",
    "            \n",
    "            start_time = time.time()                    \n",
    "            # run the model\n",
    "            for lamb in [0.01]:\n",
    "                # test model without TF\n",
    "                thetas = np.zeros((ntimes,ngenes,ngenes))\n",
    "\n",
    "                # setting from the paper over-relaxation model\n",
    "                alpha = 2\n",
    "                rho = 1.7\n",
    "                # gadmm_batch = g_admm.G_admm_batch(X=X[:, None, :], K=K, pre_cov=empir_cov)\n",
    "                gadmm_batch = g_admm.G_admm_minibatch(X=X[:, None, :], K=K, pre_cov=empir_cov, batchsize = 100)\n",
    "                thetas = gadmm_batch.train(max_iters=max_iters, n_intervals=100, alpha=alpha, lamb=lamb, rho=rho, theta_init_offset=0.1)\n",
    "                np.save(file = result_dir + \"thetas_\" + str(bandwidth) + \"_\" + str(alpha) + \"_\" + str(lamb) + \"_\" + str(rho) + \".npy\", arr = thetas) \n",
    "                print(\"time calculating thetas: {:.2f} sec\".format(time.time() - start_time))\n",
    "            del thetas\n",
    "            gadmm_batch = None\n",
    "            gc.collect()\n",
    "\n",
    "        ###############################################\n",
    "        #\n",
    "        # test with TF information\n",
    "        #\n",
    "        ###############################################\n",
    "        print(\"test with TF information\")\n",
    "        for bandwidth in [0.1]:\n",
    "            start_time = time.time()\n",
    "            empir_cov = torch.zeros(ntimes, ngenes, ngenes)\n",
    "            K, K_trun = kernel.calc_kernel(X, k = 5, bandwidth = bandwidth, truncate = True, truncate_param = truncate_param)\n",
    "\n",
    "            # building weighted covariance matrix, output is empir_cov of the shape (ntimes, ngenes, ngenes)\n",
    "            for t in range(ntimes):\n",
    "                weight = torch.FloatTensor(K_trun[t, :]).to(device)\n",
    "                # assert torch.sum(weight) == 1\n",
    "\n",
    "                bin_weight = torch.FloatTensor((K_trun[t, :] > 0).astype(np.int))\n",
    "                sample_mean = torch.sum(sample * weight[:, None], dim = 0)\n",
    "                # sample_mean = torch.sum(sample * (bin_weight/torch.sum(bin_weight))[:, None], dim = 0)\n",
    "\n",
    "                norm_sample = sample - sample_mean[None, :]\n",
    "                empir_cov[t] = torch.sum(torch.bmm(norm_sample[:,:,None], norm_sample[:,None,:]) * weight[:,None, None], dim=0)\n",
    "            print(\"time calculating the kernel function: {:.2f} sec\".format(time.time() - start_time))\n",
    "            \n",
    "            start_time = time.time()                                  \n",
    "            # run the model\n",
    "            for lamb in [0.01]:\n",
    "                # test model without TF\n",
    "                thetas = np.zeros((ntimes,ngenes,ngenes))\n",
    "\n",
    "                # setting from the paper over-relaxation model\n",
    "                alpha = 2\n",
    "                rho = 1.7\n",
    "                # gadmm_batch = g_admm.G_admm_batch(X=X[:, None, :], K=K, pre_cov=empir_cov, TF=np.arange(ntfs))\n",
    "                gadmm_batch = g_admm.G_admm_minibatch(X=X[:, None, :], K=K, pre_cov=empir_cov, batchsize = 100, TF=np.arange(ntfs))\n",
    "                thetas = gadmm_batch.train(max_iters=max_iters, n_intervals=100, alpha=alpha, lamb=lamb, rho=rho, beta=100, theta_init_offset=0.1)\n",
    "                np.save(file = result_dir + \"thetas_\" + str(bandwidth) + \"_\" + str(alpha) + \"_\" + str(lamb) + \"_\" + str(rho) + \"_tfs.npy\", arr = thetas) \n",
    "                print(\"time calculating thetas: {:.2f} sec\".format(time.time() - start_time))\n",
    "            del thetas\n",
    "            gadmm_batch = None\n",
    "            gc.collect()\n",
    "\n",
    "\n",
    "        ###############################################\n",
    "        #\n",
    "        # test with the second set of hyper-parameters, without TF information\n",
    "        #\n",
    "        ###############################################\n",
    "        print(\"test without TF information\")\n",
    "        for bandwidth in [0.1]:\n",
    "            start_time = time.time()\n",
    "            empir_cov = torch.zeros(ntimes, ngenes, ngenes)\n",
    "            # calculate the kernel function\n",
    "            K, K_trun = kernel.calc_kernel(X, k = 5, bandwidth = bandwidth, truncate = True, truncate_param = truncate_param)\n",
    "\n",
    "            # building weighted covariance matrix, output is empir_cov of the shape (ntimes, ngenes, ngenes)\n",
    "            for t in range(ntimes):\n",
    "                weight = torch.FloatTensor(K_trun[t, :]).to(device)\n",
    "                # assert torch.sum(weight) == 1\n",
    "\n",
    "                bin_weight = torch.FloatTensor((K_trun[t, :] > 0).astype(np.int))\n",
    "                sample_mean = torch.sum(sample * weight[:, None], dim = 0)\n",
    "                # sample_mean = torch.sum(sample * (bin_weight/torch.sum(bin_weight))[:, None], dim = 0)\n",
    "\n",
    "                norm_sample = sample - sample_mean[None, :]\n",
    "                empir_cov[t] = torch.sum(torch.bmm(norm_sample[:,:,None], norm_sample[:,None,:]) * weight[:,None, None], dim=0)\n",
    "            print(\"time calculating the kernel function: {:.2f} sec\".format(time.time() - start_time))\n",
    "            \n",
    "            start_time = time.time()                    \n",
    "            # run the model\n",
    "            for lamb in [0.01]:\n",
    "                # test model without TF\n",
    "                thetas = np.zeros((ntimes,ngenes,ngenes))\n",
    "\n",
    "                # setting from the paper over-relaxation model\n",
    "                alpha = 1\n",
    "                rho = None\n",
    "                # gadmm_batch = g_admm.G_admm_batch(X=X[:, None, :], K=K, pre_cov=empir_cov)\n",
    "                gadmm_batch = g_admm.G_admm_minibatch(X=X[:, None, :], K=K, pre_cov=empir_cov, batchsize = 100)\n",
    "                thetas = gadmm_batch.train(max_iters=max_iters, n_intervals=100, alpha=alpha, lamb=lamb, rho=rho, theta_init_offset=0.1)\n",
    "                np.save(file = result_dir + \"thetas_\" + str(bandwidth) + \"_\" + str(alpha) + \"_\" + str(lamb) + \"_\" + str(rho) + \".npy\", arr = thetas) \n",
    "                print(\"time calculating thetas: {:.2f} sec\".format(time.time() - start_time))\n",
    "            del thetas\n",
    "            gadmm_batch = None\n",
    "            gc.collect()\n",
    "\n",
    "        ###############################################\n",
    "        #\n",
    "        # test with TF information\n",
    "        #\n",
    "        ###############################################\n",
    "        print(\"test with TF information\")\n",
    "        for bandwidth in [0.1]:\n",
    "            start_time = time.time()\n",
    "            empir_cov = torch.zeros(ntimes, ngenes, ngenes)\n",
    "            K, K_trun = kernel.calc_kernel(X, k = 5, bandwidth = bandwidth, truncate = True, truncate_param = truncate_param)\n",
    "\n",
    "            # building weighted covariance matrix, output is empir_cov of the shape (ntimes, ngenes, ngenes)\n",
    "            for t in range(ntimes):\n",
    "                weight = torch.FloatTensor(K_trun[t, :]).to(device)\n",
    "                # assert torch.sum(weight) == 1\n",
    "\n",
    "                bin_weight = torch.FloatTensor((K_trun[t, :] > 0).astype(np.int))\n",
    "                sample_mean = torch.sum(sample * weight[:, None], dim = 0)\n",
    "                # sample_mean = torch.sum(sample * (bin_weight/torch.sum(bin_weight))[:, None], dim = 0)\n",
    "\n",
    "                norm_sample = sample - sample_mean[None, :]\n",
    "                empir_cov[t] = torch.sum(torch.bmm(norm_sample[:,:,None], norm_sample[:,None,:]) * weight[:,None, None], dim=0)\n",
    "            print(\"time calculating the kernel function: {:.2f} sec\".format(time.time() - start_time))\n",
    "            \n",
    "            start_time = time.time()                                  \n",
    "            # run the model\n",
    "            for lamb in [0.01]:\n",
    "                # test model without TF\n",
    "                thetas = np.zeros((ntimes,ngenes,ngenes))\n",
    "\n",
    "                # setting from the paper over-relaxation model\n",
    "                alpha = 1\n",
    "                rho = None\n",
    "                # gadmm_batch = g_admm.G_admm_batch(X=X[:, None, :], K=K, pre_cov=empir_cov, TF=np.arange(ntfs))\n",
    "                gadmm_batch = g_admm.G_admm_minibatch(X=X[:, None, :], K=K, pre_cov=empir_cov, batchsize = 100, TF=np.arange(ntfs))\n",
    "                thetas = gadmm_batch.train(max_iters=max_iters, n_intervals=100, alpha=alpha, lamb=lamb, rho=rho, beta=100, theta_init_offset=0.1)\n",
    "                np.save(file = result_dir + \"thetas_\" + str(bandwidth) + \"_\" + str(alpha) + \"_\" + str(lamb) + \"_\" + str(rho) + \"_tfs.npy\", arr = thetas) \n",
    "                print(\"time calculating thetas: {:.2f} sec\".format(time.time() - start_time))\n",
    "            del thetas\n",
    "            gadmm_batch = None\n",
    "            gc.collect()\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
