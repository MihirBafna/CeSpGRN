{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys, os\n",
    "sys.path.append('../../src/')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "import bmk_beeline as bmk\n",
    "import genie3, g_admm\n",
    "import kernel\n",
    "import time\n",
    "import gc\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "import os\n",
    "\n",
    "def get_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct  6 16:11:33 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA Tesla V1...  Off  | 00000000:3B:00.0 Off |                    0 |\r\n",
      "| N/A   34C    P0    24W / 250W |      4MiB / 16160MiB |      0%   E. Process |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16156]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_sqrtm import MatrixSquareRoot\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "torch_sqrtm = MatrixSquareRoot.apply\n",
    "\n",
    "class G_admm_minibatch():\n",
    "    def __init__(self, X, K, TF = None, seed = 0, pre_cov = None, batchsize = None):\n",
    "        super(G_admm_minibatch, self).__init__()\n",
    "        # set random seed\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "\n",
    "        # shape (ntimes, nsamples, ngenes)\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.ntimes, self.nsamples, self.ngenes = self.X.shape\n",
    "        \n",
    "        # calculate batchsize\n",
    "        if batchsize is None:\n",
    "            self.batchsize = int(self.ntimes/10)\n",
    "        else:\n",
    "            self.batchsize = batchsize\n",
    "        # calculate empirical covariance matrix\n",
    "        if pre_cov is None:\n",
    "            # shape (ntimes, nsamples, ngenes)\n",
    "            self.epir_mean = self.X.mean(dim = 1, keepdim = True)\n",
    "            X = self.X - self.epir_mean\n",
    "            # (ntimes * nsamples, ngenes, ngenes)\n",
    "            self.empir_cov = torch.bmm(X.reshape((self.ntimes * self.nsamples, self.ngenes, 1)), X.reshape((self.ntimes * self.nsamples, 1, self.ngenes)))\n",
    "            # (ntimes, ngenes, ngenes)\n",
    "            self.empir_cov = torch.sum(self.empir_cov.reshape((self.ntimes, self.nsamples, self.ngenes, self.ngenes)), dim = 1)/(self.nsamples - 1)\n",
    "        else:\n",
    "            self.empir_cov = pre_cov\n",
    "\n",
    "        # weight kernel function, shape (ntimes, ntimes)\n",
    "        self.weights = torch.FloatTensor(K)\n",
    "        # weighted average of empricial covariance matrix\n",
    "        assert torch.all(torch.sum(self.weights,dim=1) - 1 < 1e-6)\n",
    "        self.w_empir_cov = torch.sum((self.weights[:,:,None,None]*self.empir_cov[None,:,:,:]),dim=1) \n",
    "        # store the result\n",
    "        self.thetas = np.zeros((self.ntimes, self.ngenes, self.ngenes))\n",
    "        \n",
    "        # mask matrix (ntimes, ngenes, ngenes)\n",
    "        if TF is not None:\n",
    "            self.mask = torch.zeros(self.ngenes, self.ngenes)\n",
    "            # mark probable interactions\n",
    "            self.mask[TF, :] = 1\n",
    "            self.mask[:, TF] = 1\n",
    "            # element-wise reverse\n",
    "            self.mask = 1 - self.mask\n",
    "            self.mask = self.mask.expand(self.ntimes, self.ngenes, self.ngenes) \n",
    "        else:\n",
    "            self.mask = torch.FloatTensor([0])  \n",
    "\n",
    "    @staticmethod\n",
    "    def neg_lkl_loss(thetas, S):\n",
    "        \"\"\"\\\n",
    "        Description:\n",
    "        --------------\n",
    "            The negative log likelihood function\n",
    "        Parameters:\n",
    "        --------------\n",
    "            theta:\n",
    "                The estimated theta\n",
    "            S:\n",
    "                The empirical covariance matrix\n",
    "        Return:\n",
    "        --------------\n",
    "            The negative log likelihood value\n",
    "        \"\"\"\n",
    "        # logdet works for batches of matrices, give a high dimensional data\n",
    "        t1 = -1*torch.logdet(thetas)\n",
    "        t2 = torch.stack([torch.trace(mat) for mat in torch.bmm(S, thetas)])\n",
    "        return t1 + t2\n",
    "\n",
    "\n",
    "    def train(self, max_iters = 50, n_intervals = 1, lamb = 2.1e-4, alpha = 1, rho = 1, beta = 0, theta_init_offset = 0.1):\n",
    "        n_batches = int(np.ceil(self.ntimes/self.batchsize))\n",
    "        for batch in range(n_batches):\n",
    "            # select a minibatch, and load to cuda\n",
    "            start_idx = batch * self.batchsize\n",
    "            if batch < n_batches - 1:\n",
    "                end_idx = (batch + 1) * self.batchsize\n",
    "                w_empir_cov = self.w_empir_cov[start_idx:end_idx, :, :].to(device)\n",
    "                if self.mask.shape[0] == self.ntimes:\n",
    "                    mask = self.mask[start_idx:end_idx, :, :].to(device)\n",
    "                else:\n",
    "                    mask = self.mask.to(device)\n",
    "            else:\n",
    "                w_empir_cov = self.w_empir_cov[start_idx:, :, :].to(device)\n",
    "                if self.mask.shape[0] == self.ntimes:\n",
    "                    mask = self.mask[start_idx:, :, :].to(device)\n",
    "                else:\n",
    "                    mask = self.mask.to(device)\n",
    "            # initialize mini-batch, Z of the shape (batch_size, ngenes, ngenes)\n",
    "            Z = torch.diag_embed(1/(torch.diagonal(w_empir_cov, offset=0, dim1=-2, dim2=-1) + theta_init_offset))\n",
    "            # make Z positive definite matrix\n",
    "            ll = torch.cholesky(Z)\n",
    "            Z = torch.matmul(ll, ll.transpose(-1, -2))\n",
    "            U = torch.zeros(Z.shape).to(device)\n",
    "            I = torch.eye(self.ngenes).expand(Z.shape).to(device)\n",
    "\n",
    "            it = 0\n",
    "            # hyper-parameter for batches\n",
    "            if rho is None:\n",
    "                updating_rho = True\n",
    "                # rho of the shape (ntimes, 1, 1)\n",
    "                b_rho = torch.ones((Z.shape[0], 1, 1)).to(device) * 1.7\n",
    "            else:\n",
    "                b_rho = torch.FloatTensor([rho] * Z.shape[0])[:, None, None].to(device)\n",
    "                updating_rho = False\n",
    "            b_alpha = alpha \n",
    "            b_beta = beta\n",
    "            b_lamb = lamb\n",
    "            while(it < max_iters): \n",
    "                # Primal \n",
    "                Y = U - Z + w_empir_cov/b_rho    # (ntimes, ngenes, ngenes)\n",
    "                thetas = - 0.5 * Y + torch.stack([torch_sqrtm(mat) for mat in (torch.transpose(Y,1,2) @ Y * 0.25 + I/b_rho)])\n",
    "                Z_pre = Z.detach().clone()\n",
    "                # over-relaxation\n",
    "                thetas = b_alpha * thetas + (1 - b_alpha) * Z_pre            \n",
    "                Z = torch.sign(thetas + U) * torch.max((b_rho * (thetas + U).abs() - b_lamb)/(b_rho + b_beta * mask), torch.Tensor([0]).to(device))\n",
    "\n",
    "                # Dual\n",
    "                U = U + thetas - Z\n",
    "\n",
    "                # calculate residual\n",
    "                # primal_residual and dual_residual of the shape (ntimes, 1, 1)\n",
    "                primal_residual = torch.sqrt((thetas - Z).pow(2).sum(1).sum(1))\n",
    "                dual_residual = b_rho.squeeze() * torch.sqrt((Z - Z_pre).pow(2).sum(1).sum(1))\n",
    "\n",
    "                # updating rho, rho should be of shape (ntimes, 1, 1)\n",
    "                if updating_rho:\n",
    "                    mask_inc = (primal_residual > 10 * dual_residual)\n",
    "                    b_rho[mask_inc, :, :] = b_rho[mask_inc, :, :] * 2\n",
    "                    mask_dec = (dual_residual > 10 * primal_residual)\n",
    "                    b_rho[mask_dec, :, :] = b_rho[mask_dec, :, :] / 2\n",
    "                \n",
    "                # print(rho.squeeze())\n",
    "                # free-up memory\n",
    "                del Z_pre\n",
    "                \n",
    "                # Stopping criteria\n",
    "                if (it + 1) % n_intervals == 0:\n",
    "                    print(\"Current GPU memory: \") \n",
    "                    print(get_gpu_memory())\n",
    "                    # calculate sum of all duality gap\n",
    "                    # loss = self.neg_lkl_loss(thetas, w_empir_cov).sum() + b_lamb * Z.abs().sum() + b_beta * (self.mask * Z).pow(2).sum()\n",
    "                    # primal_val = loss  + rho/2 * (thetas - Z).pow(2).sum()\n",
    "                    # dual_val = loss + rho/2 * (thetas - Z + U).pow(2).sum() - rho/2 * U.pow(2).sum()\n",
    "                    # duality_gap = primal_val - dual_val\n",
    "\n",
    "                    # simplify min of all duality gap\n",
    "                    duality_gap = b_rho.squeeze() * torch.stack([torch.trace(mat) for mat in torch.bmm(U.permute(0,2,1), Z - thetas)])\n",
    "                    duality_gap = duality_gap.abs()\n",
    "                    print(\"n_iter: {}, duality gap: {:.4e}, primal residual: {:.4e}, dual residual: {:4e}\".format(it+1, duality_gap.max().item(), primal_residual.max().item(), dual_residual.max().item()))\n",
    "                    \n",
    "                    # if duality_gap < 1e-8:\n",
    "                    #     break\n",
    "                    primal_eps = 1e-6\n",
    "                    dual_eps = 1e-6\n",
    "                    if (primal_residual.max() < primal_eps) and (dual_residual.max() < dual_eps):\n",
    "                        break                \n",
    "                it += 1\n",
    "            \n",
    "            loss1 = self.neg_lkl_loss(Z, w_empir_cov).sum()\n",
    "            loss2 = Z.abs().sum()\n",
    "            loss3 = (mask * Z).pow(2).sum()\n",
    "            print(\"Batche loss: loss1: {:.5f}, loss2: {:.5f}, loss3: {:.5f}\".format(loss1.item(), loss2.item(), loss3.item()))  \n",
    "            # store values\n",
    "            if batch < n_batches - 1:\n",
    "                self.thetas[start_idx:end_idx] = Z.detach().cpu().numpy()\n",
    "            else:\n",
    "                self.thetas[start_idx:] = Z.detach().cpu().numpy()\n",
    "            del thetas, U, I, Y, ll, Z\n",
    "\n",
    "\n",
    "        return self.thetas\n",
    "\n",
    "\n",
    "def preprocess(counts): \n",
    "    \"\"\"\\\n",
    "    Input:\n",
    "    counts = (ntimes, ngenes)\n",
    "    \n",
    "    Description:\n",
    "    ------------\n",
    "    Preprocess the dataset\n",
    "    \"\"\"\n",
    "    # normalize according to the library size\n",
    "    \n",
    "    libsize = np.median(np.sum(counts, axis = 1))\n",
    "    counts = counts / np.sum(counts, axis = 1)[:,None] * libsize\n",
    "        \n",
    "    counts = np.log1p(counts)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'kernel' from '../../src/kernel.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib \n",
    "importlib.reload(g_admm)\n",
    "importlib.reload(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw TimePoints: 1000, no.Genes: 20\n",
      "number of nearest neighbor: 6\n",
      "number of nearest neighbor: 7\n",
      "final number of nearest neighbor (make connected): 7\n",
      "time calculating the kernel function: 3.18 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1856a6c51983>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mgadmm_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_admm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_admm_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_cov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mempir_cov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;31m# gadmm_batch = G_admm_minibatch(X=X[:, None, :], K=K, pre_cov=empir_cov, batchsize = 1000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mthetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgadmm_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_intervals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_init_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"thetas_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbandwidth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time calculating thetas: {:.2f} sec\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/hive/project/cse-vuduc/zzhang834/DynGRN/src/g_admm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, max_iters, n_intervals, lamb, alpha, rho, beta, theta_init_offset)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;31m# Primal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_empir_cov\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mrho\u001b[0m    \u001b[0;31m# (ntimes, ngenes, ngenes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mthetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch_sqrtm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.25\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mZ_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;31m# over-relaxation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/hive/project/cse-vuduc/zzhang834/DynGRN/src/g_admm.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;31m# Primal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_empir_cov\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mrho\u001b[0m    \u001b[0;31m# (ntimes, ngenes, ngenes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mthetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch_sqrtm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.25\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mZ_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;31m# over-relaxation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/hive/project/cse-vuduc/zzhang834/DynGRN/src/torch_sqrtm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#m = input.numpy().astype(np.float_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msqrtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrtm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.type_as(input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqrtm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# save in cpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msqrtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/scipy/linalg/_matfuncs_sqrtm.py\u001b[0m in \u001b[0;36msqrtm\u001b[0;34m(A, disp, blocksize)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mfailflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sqrtm_triu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mZH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/scipy/linalg/_matfuncs_sqrtm.py\u001b[0m in \u001b[0;36m_sqrtm_triu\u001b[0;34m(T, blocksize)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ntimes = 1000\n",
    "path = \"../../data/GGM_changing_mean/\"\n",
    "for interval in [50, 100, 200]:\n",
    "    for (ngenes, ntfs) in [(30, 5)]:\n",
    "        result_dir = \"../results/GGM_changing_mean_\" + str(ntimes) + \"_\" + str(interval) + \"_\" + str(ngenes) + \"/\"\n",
    "        if not os.path.exists(result_dir):\n",
    "            os.makedirs(result_dir)\n",
    "        # the data smapled from GGM is zero-mean\n",
    "        X = np.load(path + \"ntimes_\" + str(ntimes) + \"_interval_\" + str(interval) + \"_ngenes_\" + str(ngenes) + \"/expr.npy\")\n",
    "        print(\"Raw TimePoints: {}, no.Genes: {}\".format(X.shape[0],X.shape[1]))\n",
    "        # X = StandardScaler().fit_transform(X)\n",
    "\n",
    "        # make sure the dimensions are correct\n",
    "        assert X.shape[0] == ntimes\n",
    "        assert X.shape[1] == ngenes\n",
    "\n",
    "        sample = torch.FloatTensor(X).to(device)\n",
    "        max_iters = 20\n",
    "        ###############################################\n",
    "        #\n",
    "        # test without TF information\n",
    "        #\n",
    "        ###############################################\n",
    "\n",
    "        for bandwidth in [0.1]:\n",
    "            start_time = time.time()\n",
    "            empir_cov = torch.zeros(ntimes, ngenes, ngenes)\n",
    "            # calculate the kernel function\n",
    "            K, K_trun = kernel.calc_kernel(X, k = 5, bandwidth = bandwidth, truncate = True)\n",
    "            \n",
    "            # building weighted covariance matrix, output is empir_cov of the shape (ntimes, ngenes, ngenes)\n",
    "            for t in range(ntimes):\n",
    "                weight = torch.FloatTensor(K_trun[t, :]).to(device)\n",
    "                # assert torch.sum(weight) == 1\n",
    "\n",
    "                bin_weight = torch.FloatTensor((K_trun[t, :] > 0).astype(np.int))\n",
    "                sample_mean = torch.sum(sample * weight[:, None], dim = 0)\n",
    "                # sample_mean = torch.sum(sample * (bin_weight/torch.sum(bin_weight))[:, None], dim = 0)\n",
    "\n",
    "                norm_sample = sample - sample_mean[None, :]\n",
    "                empir_cov[t] = torch.sum(torch.bmm(norm_sample[:,:,None], norm_sample[:,None,:]) * weight[:,None, None], dim=0)\n",
    "            print(\"time calculating the kernel function: {:.2f} sec\".format(time.time() - start_time))\n",
    "            \n",
    "            start_time = time.time()                    \n",
    "            # run the model\n",
    "            for lamb in [0.01]:\n",
    "                # test model without TF\n",
    "                thetas = np.zeros((ntimes,ngenes,ngenes))\n",
    "\n",
    "                # setting from the paper over-relaxation model\n",
    "                alpha = 2\n",
    "                rho = 1.7\n",
    "                gadmm_batch = g_admm.G_admm_batch(X=X[:, None, :], K=K, pre_cov=empir_cov)\n",
    "                # gadmm_batch = G_admm_minibatch(X=X[:, None, :], K=K, pre_cov=empir_cov, batchsize = 1000)\n",
    "                thetas = gadmm_batch.train(max_iters=max_iters, n_intervals=10, alpha=alpha, lamb=lamb, rho=rho, theta_init_offset=0.1)\n",
    "                np.save(file = result_dir + \"thetas_\" + str(bandwidth) + \"_\" + str(alpha) + \"_\" + str(lamb) + \"_\" + str(rho) + \".npy\", arr = thetas) \n",
    "                print(\"time calculating thetas: {:.2f} sec\".format(time.time() - start_time))\n",
    "            del thetas\n",
    "            gadmm_batch = None\n",
    "            gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw TimePoints: 1000, no.Genes: 20\n",
      "test without TF information\n",
      "number of nearest neighbor: 6\n",
      "number of nearest neighbor: 7\n",
      "final number of nearest neighbor (make connected): 7\n",
      "time calculating the kernel function: 3.69 sec\n",
      "n_iter: 100, duality gap: 1.5150e-05, primal residual: 1.2197e-03, dual residual: 1.630644e-01\n",
      "n_iter: 200, duality gap: 9.3371e-06, primal residual: 6.8934e-04, dual residual: 1.306090e-01\n",
      "n_iter: 300, duality gap: 7.1960e-06, primal residual: 4.9921e-04, dual residual: 1.086170e-01\n",
      "n_iter: 400, duality gap: 5.4585e-06, primal residual: 3.8609e-04, dual residual: 9.634646e-02\n",
      "n_iter: 500, duality gap: 4.2434e-06, primal residual: 3.1611e-04, dual residual: 8.762145e-02\n",
      "n_iter: 600, duality gap: 3.3450e-06, primal residual: 2.8188e-04, dual residual: 8.060444e-02\n",
      "n_iter: 700, duality gap: 2.9418e-06, primal residual: 2.4579e-04, dual residual: 7.465711e-02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6ac19e1fedcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0;31m# gadmm_batch = g_admm.G_admm_batch(X=X[:, None, :], K=K, pre_cov=empir_cov)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mgadmm_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_admm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_admm_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_cov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mempir_cov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0mthetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgadmm_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_intervals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_init_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"thetas_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbandwidth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time calculating thetas: {:.2f} sec\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/hive/project/cse-vuduc/zzhang834/DynGRN/src/g_admm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, max_iters, n_intervals, lamb, alpha, rho, beta, theta_init_offset)\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;31m# Primal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw_empir_cov\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mb_rho\u001b[0m    \u001b[0;31m# (ntimes, ngenes, ngenes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                 \u001b[0mthetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch_sqrtm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.25\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mb_rho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0mZ_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                 \u001b[0;31m# over-relaxation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/hive/project/cse-vuduc/zzhang834/DynGRN/src/g_admm.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;31m# Primal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw_empir_cov\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mb_rho\u001b[0m    \u001b[0;31m# (ntimes, ngenes, ngenes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                 \u001b[0mthetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch_sqrtm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.25\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mb_rho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0mZ_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                 \u001b[0;31m# over-relaxation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/hive/project/cse-vuduc/zzhang834/DynGRN/src/torch_sqrtm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#m = input.numpy().astype(np.float_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msqrtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrtm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.type_as(input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqrtm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# save in cpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msqrtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/scipy/linalg/_matfuncs_sqrtm.py\u001b[0m in \u001b[0;36msqrtm\u001b[0;34m(A, disp, blocksize)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mfailflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sqrtm_triu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mZH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.8/site-packages/scipy/linalg/_matfuncs_sqrtm.py\u001b[0m in \u001b[0;36m_sqrtm_triu\u001b[0;34m(T, blocksize)\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdenom\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In[0]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys, os\n",
    "sys.path.append('../../src/')\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "import bmk_beeline as bmk\n",
    "import genie3, g_admm\n",
    "import kernel\n",
    "import time\n",
    "import gc\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "\n",
    "def preprocess(counts): \n",
    "    \"\"\"\\\n",
    "    Input:\n",
    "    counts = (ntimes, ngenes)\n",
    "    \n",
    "    Description:\n",
    "    ------------\n",
    "    Preprocess the dataset\n",
    "    \"\"\"\n",
    "    # normalize according to the library size\n",
    "    \n",
    "    libsize = np.median(np.sum(counts, axis = 1))\n",
    "    counts = counts / np.sum(counts, axis = 1)[:,None] * libsize\n",
    "        \n",
    "    counts = np.log1p(counts)\n",
    "    return counts\n",
    "\n",
    "# In[1] test with the first set of hyper-parameters\n",
    "ntimes = 1000\n",
    "path = \"../../data/GGM_changing_mean/\"\n",
    "max_iters = 2000\n",
    "truncate_param = 7\n",
    "for interval in [50]:\n",
    "    for (ngenes, ntfs) in [(20, 5), (30, 10), (50, 20), (100, 50)]:\n",
    "        result_dir = \"../results/GGM_changing_mean_\" + str(ntimes) + \"_\" + str(interval) + \"_\" + str(ngenes) + \"/\"\n",
    "        if not os.path.exists(result_dir):\n",
    "            os.makedirs(result_dir)\n",
    "        # the data smapled from GGM is zero-mean\n",
    "        X = np.load(path + \"ntimes_\" + str(ntimes) + \"_interval_\" + str(interval) + \"_ngenes_\" + str(ngenes) + \"/expr.npy\")\n",
    "        # gt_adj = np.load(path + \"ntimes_\" + str(ntimes) + \"_interval_\" + str(interval) + \"_ngenes_\" + str(ngenes) + \"/Gs.npy\")\n",
    "\n",
    "        # sort the genes\n",
    "        print(\"Raw TimePoints: {}, no.Genes: {}\".format(X.shape[0],X.shape[1]))\n",
    "        # X = StandardScaler().fit_transform(X)\n",
    "\n",
    "        # make sure the dimensions are correct\n",
    "        assert X.shape[0] == ntimes\n",
    "        assert X.shape[1] == ngenes\n",
    "\n",
    "        sample = torch.FloatTensor(X).to(device)\n",
    "        ###############################################\n",
    "        #\n",
    "        # test with the first set of hyper-parameters, without TF information\n",
    "        #\n",
    "        ###############################################\n",
    "        print(\"test without TF information\")\n",
    "        for bandwidth in [0.1]:\n",
    "            start_time = time.time()\n",
    "            empir_cov = torch.zeros(ntimes, ngenes, ngenes)\n",
    "            # calculate the kernel function\n",
    "            K, K_trun = kernel.calc_kernel(X, k = 5, bandwidth = bandwidth, truncate = True, truncate_param = truncate_param)\n",
    "\n",
    "            # plot kernel function\n",
    "            fig = plt.figure(figsize = (20, 7))\n",
    "            axs = fig.subplots(1, 2)\n",
    "            axs[0].plot(K[int(ntimes/2), :])\n",
    "            axs[1].plot(K_trun[int(ntimes/2), :])\n",
    "            fig.savefig(result_dir + \"kernel_\" + str(bandwidth) + \".png\", bbox_inches = \"tight\")\n",
    "\n",
    "            # building weighted covariance matrix, output is empir_cov of the shape (ntimes, ngenes, ngenes)\n",
    "            for t in range(ntimes):\n",
    "                weight = torch.FloatTensor(K_trun[t, :]).to(device)\n",
    "                # assert torch.sum(weight) == 1\n",
    "\n",
    "                bin_weight = torch.FloatTensor((K_trun[t, :] > 0).astype(np.int))\n",
    "                sample_mean = torch.sum(sample * weight[:, None], dim = 0)\n",
    "                # sample_mean = torch.sum(sample * (bin_weight/torch.sum(bin_weight))[:, None], dim = 0)\n",
    "\n",
    "                norm_sample = sample - sample_mean[None, :]\n",
    "                empir_cov[t] = torch.sum(torch.bmm(norm_sample[:,:,None], norm_sample[:,None,:]) * weight[:,None, None], dim=0)\n",
    "            print(\"time calculating the kernel function: {:.2f} sec\".format(time.time() - start_time))\n",
    "            \n",
    "            start_time = time.time()                    \n",
    "            # run the model\n",
    "            for lamb in [0.01]:\n",
    "                # test model without TF\n",
    "                thetas = np.zeros((ntimes,ngenes,ngenes))\n",
    "\n",
    "                # setting from the paper over-relaxation model\n",
    "                alpha = 2\n",
    "                rho = 1.7\n",
    "                # gadmm_batch = g_admm.G_admm_batch(X=X[:, None, :], K=K, pre_cov=empir_cov)\n",
    "                gadmm_batch = g_admm.G_admm_minibatch(X=X[:, None, :], K=K, pre_cov=empir_cov, batchsize = 100)\n",
    "                thetas = gadmm_batch.train(max_iters=max_iters, n_intervals=100, alpha=alpha, lamb=lamb, rho=rho, theta_init_offset=0.1)\n",
    "                np.save(file = result_dir + \"thetas_\" + str(bandwidth) + \"_\" + str(alpha) + \"_\" + str(lamb) + \"_\" + str(rho) + \".npy\", arr = thetas) \n",
    "                print(\"time calculating thetas: {:.2f} sec\".format(time.time() - start_time))\n",
    "            del thetas\n",
    "            gadmm_batch = None\n",
    "            gc.collect()\n",
    "\n",
    "        ###############################################\n",
    "        #\n",
    "        # test with TF information\n",
    "        #\n",
    "        ###############################################\n",
    "        print(\"test with TF information\")\n",
    "        for bandwidth in [0.1]:\n",
    "            start_time = time.time()\n",
    "            empir_cov = torch.zeros(ntimes, ngenes, ngenes)\n",
    "            K, K_trun = kernel.calc_kernel(X, k = 5, bandwidth = bandwidth, truncate = True, truncate_param = truncate_param)\n",
    "\n",
    "            # building weighted covariance matrix, output is empir_cov of the shape (ntimes, ngenes, ngenes)\n",
    "            for t in range(ntimes):\n",
    "                weight = torch.FloatTensor(K_trun[t, :]).to(device)\n",
    "                # assert torch.sum(weight) == 1\n",
    "\n",
    "                bin_weight = torch.FloatTensor((K_trun[t, :] > 0).astype(np.int))\n",
    "                sample_mean = torch.sum(sample * weight[:, None], dim = 0)\n",
    "                # sample_mean = torch.sum(sample * (bin_weight/torch.sum(bin_weight))[:, None], dim = 0)\n",
    "\n",
    "                norm_sample = sample - sample_mean[None, :]\n",
    "                empir_cov[t] = torch.sum(torch.bmm(norm_sample[:,:,None], norm_sample[:,None,:]) * weight[:,None, None], dim=0)\n",
    "            print(\"time calculating the kernel function: {:.2f} sec\".format(time.time() - start_time))\n",
    "            \n",
    "            start_time = time.time()                                  \n",
    "            # run the model\n",
    "            for lamb in [0.01]:\n",
    "                # test model without TF\n",
    "                thetas = np.zeros((ntimes,ngenes,ngenes))\n",
    "\n",
    "                # setting from the paper over-relaxation model\n",
    "                alpha = 2\n",
    "                rho = 1.7\n",
    "                # gadmm_batch = g_admm.G_admm_batch(X=X[:, None, :], K=K, pre_cov=empir_cov, TF=np.arange(ntfs))\n",
    "                gadmm_batch = g_admm.G_admm_minibatch(X=X[:, None, :], K=K, pre_cov=empir_cov, batchsize = 100, TF=np.arange(ntfs))\n",
    "                thetas = gadmm_batch.train(max_iters=max_iters, n_intervals=100, alpha=alpha, lamb=lamb, rho=rho, beta=100, theta_init_offset=0.1)\n",
    "                np.save(file = result_dir + \"thetas_\" + str(bandwidth) + \"_\" + str(alpha) + \"_\" + str(lamb) + \"_\" + str(rho) + \"_tfs.npy\", arr = thetas) \n",
    "                print(\"time calculating thetas: {:.2f} sec\".format(time.time() - start_time))\n",
    "            del thetas\n",
    "            gadmm_batch = None\n",
    "            gc.collect()\n",
    "\n",
    "\n",
    "        ###############################################\n",
    "        #\n",
    "        # test with the second set of hyper-parameters, without TF information\n",
    "        #\n",
    "        ###############################################\n",
    "        print(\"test without TF information\")\n",
    "        for bandwidth in [0.1]:\n",
    "            start_time = time.time()\n",
    "            empir_cov = torch.zeros(ntimes, ngenes, ngenes)\n",
    "            # calculate the kernel function\n",
    "            K, K_trun = kernel.calc_kernel(X, k = 5, bandwidth = bandwidth, truncate = True, truncate_param = truncate_param)\n",
    "\n",
    "            # building weighted covariance matrix, output is empir_cov of the shape (ntimes, ngenes, ngenes)\n",
    "            for t in range(ntimes):\n",
    "                weight = torch.FloatTensor(K_trun[t, :]).to(device)\n",
    "                # assert torch.sum(weight) == 1\n",
    "\n",
    "                bin_weight = torch.FloatTensor((K_trun[t, :] > 0).astype(np.int))\n",
    "                sample_mean = torch.sum(sample * weight[:, None], dim = 0)\n",
    "                # sample_mean = torch.sum(sample * (bin_weight/torch.sum(bin_weight))[:, None], dim = 0)\n",
    "\n",
    "                norm_sample = sample - sample_mean[None, :]\n",
    "                empir_cov[t] = torch.sum(torch.bmm(norm_sample[:,:,None], norm_sample[:,None,:]) * weight[:,None, None], dim=0)\n",
    "            print(\"time calculating the kernel function: {:.2f} sec\".format(time.time() - start_time))\n",
    "            \n",
    "            start_time = time.time()                    \n",
    "            # run the model\n",
    "            for lamb in [0.01]:\n",
    "                # test model without TF\n",
    "                thetas = np.zeros((ntimes,ngenes,ngenes))\n",
    "\n",
    "                # setting from the paper over-relaxation model\n",
    "                alpha = 1\n",
    "                rho = None\n",
    "                # gadmm_batch = g_admm.G_admm_batch(X=X[:, None, :], K=K, pre_cov=empir_cov)\n",
    "                gadmm_batch = g_admm.G_admm_minibatch(X=X[:, None, :], K=K, pre_cov=empir_cov, batchsize = 100)\n",
    "                thetas = gadmm_batch.train(max_iters=max_iters, n_intervals=100, alpha=alpha, lamb=lamb, rho=rho, theta_init_offset=0.1)\n",
    "                np.save(file = result_dir + \"thetas_\" + str(bandwidth) + \"_\" + str(alpha) + \"_\" + str(lamb) + \"_\" + str(rho) + \".npy\", arr = thetas) \n",
    "                print(\"time calculating thetas: {:.2f} sec\".format(time.time() - start_time))\n",
    "            del thetas\n",
    "            gadmm_batch = None\n",
    "            gc.collect()\n",
    "\n",
    "        ###############################################\n",
    "        #\n",
    "        # test with TF information\n",
    "        #\n",
    "        ###############################################\n",
    "        print(\"test with TF information\")\n",
    "        for bandwidth in [0.1]:\n",
    "            start_time = time.time()\n",
    "            empir_cov = torch.zeros(ntimes, ngenes, ngenes)\n",
    "            K, K_trun = kernel.calc_kernel(X, k = 5, bandwidth = bandwidth, truncate = True, truncate_param = truncate_param)\n",
    "\n",
    "            # building weighted covariance matrix, output is empir_cov of the shape (ntimes, ngenes, ngenes)\n",
    "            for t in range(ntimes):\n",
    "                weight = torch.FloatTensor(K_trun[t, :]).to(device)\n",
    "                # assert torch.sum(weight) == 1\n",
    "\n",
    "                bin_weight = torch.FloatTensor((K_trun[t, :] > 0).astype(np.int))\n",
    "                sample_mean = torch.sum(sample * weight[:, None], dim = 0)\n",
    "                # sample_mean = torch.sum(sample * (bin_weight/torch.sum(bin_weight))[:, None], dim = 0)\n",
    "\n",
    "                norm_sample = sample - sample_mean[None, :]\n",
    "                empir_cov[t] = torch.sum(torch.bmm(norm_sample[:,:,None], norm_sample[:,None,:]) * weight[:,None, None], dim=0)\n",
    "            print(\"time calculating the kernel function: {:.2f} sec\".format(time.time() - start_time))\n",
    "            \n",
    "            start_time = time.time()                                  \n",
    "            # run the model\n",
    "            for lamb in [0.01]:\n",
    "                # test model without TF\n",
    "                thetas = np.zeros((ntimes,ngenes,ngenes))\n",
    "\n",
    "                # setting from the paper over-relaxation model\n",
    "                alpha = 1\n",
    "                rho = None\n",
    "                # gadmm_batch = g_admm.G_admm_batch(X=X[:, None, :], K=K, pre_cov=empir_cov, TF=np.arange(ntfs))\n",
    "                gadmm_batch = g_admm.G_admm_minibatch(X=X[:, None, :], K=K, pre_cov=empir_cov, batchsize = 100, TF=np.arange(ntfs))\n",
    "                thetas = gadmm_batch.train(max_iters=max_iters, n_intervals=100, alpha=alpha, lamb=lamb, rho=rho, beta=100, theta_init_offset=0.1)\n",
    "                np.save(file = result_dir + \"thetas_\" + str(bandwidth) + \"_\" + str(alpha) + \"_\" + str(lamb) + \"_\" + str(rho) + \"_tfs.npy\", arr = thetas) \n",
    "                print(\"time calculating thetas: {:.2f} sec\".format(time.time() - start_time))\n",
    "            del thetas\n",
    "            gadmm_batch = None\n",
    "            gc.collect()\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
